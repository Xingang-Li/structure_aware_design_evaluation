{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate_autogluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_10232</th>\n",
       "      <th>dim_10233</th>\n",
       "      <th>dim_10234</th>\n",
       "      <th>dim_10235</th>\n",
       "      <th>dim_10236</th>\n",
       "      <th>dim_10237</th>\n",
       "      <th>dim_10238</th>\n",
       "      <th>dim_10239</th>\n",
       "      <th>dim_10240</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "61     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     1.0   \n",
       "354    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "358    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "275    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "18     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_10232  dim_10233  dim_10234  dim_10235  dim_10236  dim_10237  \\\n",
       "61   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "354  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "358  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "275  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "18   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     dim_10238  dim_10239  dim_10240   drag  \n",
       "61         0.0        0.0        0.0  0.375  \n",
       "354        0.0        0.0        0.0  0.374  \n",
       "358        0.0        0.0        0.0  0.435  \n",
       "275        0.0        0.0        0.0  0.437  \n",
       "18         0.0        0.0        0.0  0.367  \n",
       "\n",
       "[5 rows x 10241 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = '../../../../data_repo/part_aware_data/10240_vectors_drags_sdf.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-10240_sdf\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-10240_sdf/learner.pkl\n",
      "Saving ./agModels-10240_sdf/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-10240_sdf/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 10240\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    256693.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 28.75 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8082 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t40.3s = Fit runtime\n",
      "\t\t\t8082 features in original data used to generate 8082 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t3.3s = Fit runtime\n",
      "\t\t\t8082 features in original data used to generate 8082 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t3.2s = Fit runtime\n",
      "\t\t\t8082 features in original data used to generate 8082 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t4.1s = Fit runtime\n",
      "\t\t\t8082 features in original data used to generate 8082 features in processed data.\n",
      "\tUseless Original Features (Count: 2158): ['dim_38', 'dim_54', 'dim_56', 'dim_57', 'dim_70', 'dim_71', 'dim_86', 'dim_88', 'dim_89', 'dim_106', 'dim_119', 'dim_120', 'dim_135', 'dim_136', 'dim_151', 'dim_152', 'dim_155', 'dim_171', 'dim_172', 'dim_183', 'dim_184', 'dim_187', 'dim_190', 'dim_203', 'dim_204', 'dim_205', 'dim_206', 'dim_219', 'dim_220', 'dim_234', 'dim_235', 'dim_236', 'dim_247', 'dim_248', 'dim_250', 'dim_251', 'dim_263', 'dim_264', 'dim_266', 'dim_267', 'dim_268', 'dim_279', 'dim_280', 'dim_281', 'dim_282', 'dim_283', 'dim_284', 'dim_287', 'dim_288', 'dim_295', 'dim_296', 'dim_297', 'dim_298', 'dim_302', 'dim_311', 'dim_312', 'dim_313', 'dim_316', 'dim_327', 'dim_328', 'dim_329', 'dim_335', 'dim_343', 'dim_344', 'dim_345', 'dim_359', 'dim_360', 'dim_361', 'dim_362', 'dim_375', 'dim_376', 'dim_377', 'dim_378', 'dim_391', 'dim_392', 'dim_393', 'dim_407', 'dim_408', 'dim_409', 'dim_423', 'dim_424', 'dim_425', 'dim_439', 'dim_440', 'dim_442', 'dim_457', 'dim_458', 'dim_474', 'dim_475', 'dim_491', 'dim_492', 'dim_493', 'dim_503', 'dim_504', 'dim_505', 'dim_507', 'dim_508', 'dim_509', 'dim_510', 'dim_511', 'dim_519', 'dim_520', 'dim_521', 'dim_522', 'dim_523', 'dim_524', 'dim_525', 'dim_526', 'dim_527', 'dim_528', 'dim_535', 'dim_536', 'dim_537', 'dim_538', 'dim_539', 'dim_540', 'dim_541', 'dim_543', 'dim_544', 'dim_551', 'dim_552', 'dim_553', 'dim_554', 'dim_555', 'dim_567', 'dim_568', 'dim_569', 'dim_618', 'dim_620', 'dim_621', 'dim_622', 'dim_697', 'dim_828', 'dim_844', 'dim_860', 'dim_876', 'dim_892', 'dim_908', 'dim_924', 'dim_928', 'dim_940', 'dim_942', 'dim_960', 'dim_972', 'dim_988', 'dim_1023', 'dim_1115', 'dim_1116', 'dim_1131', 'dim_1132', 'dim_1133', 'dim_1134', 'dim_1135', 'dim_1147', 'dim_1148', 'dim_1149', 'dim_1150', 'dim_1151', 'dim_1152', 'dim_1163', 'dim_1164', 'dim_1166', 'dim_1167', 'dim_1179', 'dim_1180', 'dim_1181', 'dim_1182', 'dim_1184', 'dim_1195', 'dim_1245', 'dim_1259', 'dim_1280', 'dim_1535', 'dim_1551', 'dim_1552', 'dim_1566', 'dim_1568', 'dim_1598', 'dim_1600', 'dim_1630', 'dim_1632', 'dim_1647', 'dim_1648', 'dim_1661', 'dim_1662', 'dim_1663', 'dim_1664', 'dim_1678', 'dim_1679', 'dim_1680', 'dim_1693', 'dim_1694', 'dim_1695', 'dim_1696', 'dim_1711', 'dim_1712', 'dim_1727', 'dim_1728', 'dim_1740', 'dim_1741', 'dim_1743', 'dim_1744', 'dim_1756', 'dim_1757', 'dim_1759', 'dim_1760', 'dim_1771', 'dim_1772', 'dim_1773', 'dim_1774', 'dim_1775', 'dim_1776', 'dim_1787', 'dim_1788', 'dim_1789', 'dim_1790', 'dim_1791', 'dim_1792', 'dim_1803', 'dim_1804', 'dim_1805', 'dim_1808', 'dim_1819', 'dim_1820', 'dim_1821', 'dim_1822', 'dim_1823', 'dim_1824', 'dim_1835', 'dim_1836', 'dim_1871', 'dim_1872', 'dim_1883', 'dim_1884', 'dim_1901', 'dim_1902', 'dim_2057', 'dim_2073', 'dim_2089', 'dim_2105', 'dim_2112', 'dim_2137', 'dim_2145', 'dim_2146', 'dim_2153', 'dim_2159', 'dim_2160', 'dim_2167', 'dim_2168', 'dim_2169', 'dim_2183', 'dim_2184', 'dim_2185', 'dim_2191', 'dim_2199', 'dim_2200', 'dim_2201', 'dim_2215', 'dim_2216', 'dim_2217', 'dim_2231', 'dim_2232', 'dim_2233', 'dim_2239', 'dim_2247', 'dim_2248', 'dim_2249', 'dim_2256', 'dim_2263', 'dim_2264', 'dim_2265', 'dim_2271', 'dim_2272', 'dim_2279', 'dim_2280', 'dim_2281', 'dim_2287', 'dim_2288', 'dim_2295', 'dim_2296', 'dim_2297', 'dim_2303', 'dim_2304', 'dim_2311', 'dim_2312', 'dim_2313', 'dim_2319', 'dim_2320', 'dim_2327', 'dim_2328', 'dim_2329', 'dim_2335', 'dim_2336', 'dim_2343', 'dim_2344', 'dim_2351', 'dim_2352', 'dim_2359', 'dim_2360', 'dim_2367', 'dim_2368', 'dim_2375', 'dim_2376', 'dim_2377', 'dim_2382', 'dim_2392', 'dim_2393', 'dim_2397', 'dim_2408', 'dim_2409', 'dim_2413', 'dim_2414', 'dim_2415', 'dim_2416', 'dim_2424', 'dim_2425', 'dim_2427', 'dim_2428', 'dim_2429', 'dim_2430', 'dim_2431', 'dim_2432', 'dim_2440', 'dim_2441', 'dim_2443', 'dim_2444', 'dim_2455', 'dim_2456', 'dim_2464', 'dim_2471', 'dim_2472', 'dim_2475', 'dim_2524', 'dim_2525', 'dim_2526', 'dim_2527', 'dim_2528', 'dim_2567', 'dim_2583', 'dim_2696', 'dim_2697', 'dim_2705', 'dim_2712', 'dim_2713', 'dim_2727', 'dim_2728', 'dim_2729', 'dim_2730', 'dim_2738', 'dim_2743', 'dim_2744', 'dim_2745', 'dim_2746', 'dim_2752', 'dim_2754', 'dim_2759', 'dim_2760', 'dim_2761', 'dim_2762', 'dim_2768', 'dim_2769', 'dim_2770', 'dim_2775', 'dim_2776', 'dim_2777', 'dim_2778', 'dim_2785', 'dim_2786', 'dim_2791', 'dim_2792', 'dim_2793', 'dim_2794', 'dim_2807', 'dim_2808', 'dim_2809', 'dim_2810', 'dim_2823', 'dim_2824', 'dim_2825', 'dim_2826', 'dim_2839', 'dim_2840', 'dim_2841', 'dim_2842', 'dim_2843', 'dim_2848', 'dim_2855', 'dim_2856', 'dim_2857', 'dim_2858', 'dim_2859', 'dim_2871', 'dim_2872', 'dim_2873', 'dim_2874', 'dim_2875', 'dim_2880', 'dim_2887', 'dim_2888', 'dim_2889', 'dim_2890', 'dim_2891', 'dim_2896', 'dim_2903', 'dim_2904', 'dim_2905', 'dim_2906', 'dim_2919', 'dim_2920', 'dim_2921', 'dim_2922', 'dim_2927', 'dim_2928', 'dim_2936', 'dim_2937', 'dim_2938', 'dim_2943', 'dim_2944', 'dim_2951', 'dim_2952', 'dim_2953', 'dim_2959', 'dim_2960', 'dim_2967', 'dim_2968', 'dim_2969', 'dim_2975', 'dim_2976', 'dim_2983', 'dim_2984', 'dim_2985', 'dim_2991', 'dim_2992', 'dim_2999', 'dim_3000', 'dim_3001', 'dim_3007', 'dim_3008', 'dim_3011', 'dim_3015', 'dim_3016', 'dim_3017', 'dim_3022', 'dim_3023', 'dim_3024', 'dim_3025', 'dim_3032', 'dim_3033', 'dim_3038', 'dim_3039', 'dim_3040', 'dim_3041', 'dim_3042', 'dim_3047', 'dim_3048', 'dim_3049', 'dim_3053', 'dim_3054', 'dim_3055', 'dim_3056', 'dim_3057', 'dim_3063', 'dim_3064', 'dim_3065', 'dim_3068', 'dim_3069', 'dim_3070', 'dim_3071', 'dim_3072', 'dim_3079', 'dim_3080', 'dim_3083', 'dim_3084', 'dim_3085', 'dim_3086', 'dim_3087', 'dim_3088', 'dim_3090', 'dim_3091', 'dim_3095', 'dim_3096', 'dim_3099', 'dim_3100', 'dim_3101', 'dim_3106', 'dim_3107', 'dim_3111', 'dim_3131', 'dim_3132', 'dim_3148', 'dim_3149', 'dim_3152', 'dim_3168', 'dim_3175', 'dim_3176', 'dim_3207', 'dim_3223', 'dim_3240', 'dim_3314', 'dim_3315', 'dim_3321', 'dim_3336', 'dim_3337', 'dim_3347', 'dim_3352', 'dim_3353', 'dim_3361', 'dim_3363', 'dim_3368', 'dim_3369', 'dim_3370', 'dim_3377', 'dim_3378', 'dim_3384', 'dim_3385', 'dim_3386', 'dim_3393', 'dim_3394', 'dim_3400', 'dim_3401', 'dim_3402', 'dim_3410', 'dim_3411', 'dim_3416', 'dim_3417', 'dim_3418', 'dim_3426', 'dim_3427', 'dim_3431', 'dim_3432', 'dim_3433', 'dim_3434', 'dim_3443', 'dim_3447', 'dim_3448', 'dim_3449', 'dim_3450', 'dim_3459', 'dim_3463', 'dim_3464', 'dim_3465', 'dim_3466', 'dim_3472', 'dim_3475', 'dim_3479', 'dim_3480', 'dim_3481', 'dim_3482', 'dim_3483', 'dim_3488', 'dim_3491', 'dim_3495', 'dim_3496', 'dim_3497', 'dim_3498', 'dim_3499', 'dim_3504', 'dim_3507', 'dim_3511', 'dim_3512', 'dim_3513', 'dim_3514', 'dim_3515', 'dim_3520', 'dim_3523', 'dim_3527', 'dim_3528', 'dim_3529', 'dim_3530', 'dim_3531', 'dim_3536', 'dim_3543', 'dim_3544', 'dim_3545', 'dim_3546', 'dim_3547', 'dim_3552', 'dim_3555', 'dim_3559', 'dim_3560', 'dim_3561', 'dim_3562', 'dim_3563', 'dim_3571', 'dim_3576', 'dim_3577', 'dim_3578', 'dim_3583', 'dim_3584', 'dim_3587', 'dim_3591', 'dim_3592', 'dim_3593', 'dim_3599', 'dim_3600', 'dim_3603', 'dim_3607', 'dim_3608', 'dim_3609', 'dim_3615', 'dim_3616', 'dim_3619', 'dim_3623', 'dim_3624', 'dim_3625', 'dim_3631', 'dim_3632', 'dim_3639', 'dim_3640', 'dim_3641', 'dim_3647', 'dim_3648', 'dim_3649', 'dim_3650', 'dim_3651', 'dim_3655', 'dim_3656', 'dim_3657', 'dim_3662', 'dim_3663', 'dim_3664', 'dim_3671', 'dim_3672', 'dim_3673', 'dim_3678', 'dim_3679', 'dim_3680', 'dim_3687', 'dim_3688', 'dim_3689', 'dim_3693', 'dim_3694', 'dim_3695', 'dim_3696', 'dim_3697', 'dim_3698', 'dim_3699', 'dim_3703', 'dim_3704', 'dim_3705', 'dim_3708', 'dim_3709', 'dim_3710', 'dim_3711', 'dim_3712', 'dim_3713', 'dim_3719', 'dim_3720', 'dim_3724', 'dim_3725', 'dim_3726', 'dim_3727', 'dim_3728', 'dim_3730', 'dim_3731', 'dim_3735', 'dim_3736', 'dim_3740', 'dim_3741', 'dim_3742', 'dim_3743', 'dim_3744', 'dim_3745', 'dim_3747', 'dim_3751', 'dim_3752', 'dim_3755', 'dim_3756', 'dim_3760', 'dim_3774', 'dim_3775', 'dim_3776', 'dim_3790', 'dim_3791', 'dim_3792', 'dim_3802', 'dim_3805', 'dim_3807', 'dim_3815', 'dim_3816', 'dim_3818', 'dim_3832', 'dim_3880', 'dim_3953', 'dim_3955', 'dim_3960', 'dim_3961', 'dim_3971', 'dim_3976', 'dim_3977', 'dim_3986', 'dim_3987', 'dim_3993', 'dim_4001', 'dim_4002', 'dim_4003', 'dim_4008', 'dim_4009', 'dim_4010', 'dim_4017', 'dim_4018', 'dim_4019', 'dim_4024', 'dim_4025', 'dim_4026', 'dim_4034', 'dim_4035', 'dim_4040', 'dim_4041', 'dim_4042', 'dim_4050', 'dim_4051', 'dim_4056', 'dim_4057', 'dim_4058', 'dim_4064', 'dim_4066', 'dim_4067', 'dim_4071', 'dim_4072', 'dim_4073', 'dim_4074', 'dim_4080', 'dim_4081', 'dim_4082', 'dim_4083', 'dim_4087', 'dim_4088', 'dim_4089', 'dim_4090', 'dim_4096', 'dim_4097', 'dim_4099', 'dim_4103', 'dim_4104', 'dim_4105', 'dim_4106', 'dim_4112', 'dim_4113', 'dim_4114', 'dim_4115', 'dim_4119', 'dim_4120', 'dim_4121', 'dim_4122', 'dim_4128', 'dim_4130', 'dim_4131', 'dim_4135', 'dim_4136', 'dim_4137', 'dim_4138', 'dim_4144', 'dim_4146', 'dim_4147', 'dim_4151', 'dim_4152', 'dim_4153', 'dim_4154', 'dim_4155', 'dim_4162', 'dim_4163', 'dim_4167', 'dim_4168', 'dim_4169', 'dim_4170', 'dim_4171', 'dim_4176', 'dim_4178', 'dim_4179', 'dim_4183', 'dim_4184', 'dim_4185', 'dim_4186', 'dim_4187', 'dim_4192', 'dim_4199', 'dim_4200', 'dim_4201', 'dim_4202', 'dim_4203', 'dim_4208', 'dim_4210', 'dim_4211', 'dim_4216', 'dim_4217', 'dim_4218', 'dim_4223', 'dim_4224', 'dim_4226', 'dim_4227', 'dim_4231', 'dim_4232', 'dim_4233', 'dim_4234', 'dim_4239', 'dim_4240', 'dim_4241', 'dim_4242', 'dim_4243', 'dim_4247', 'dim_4248', 'dim_4249', 'dim_4255', 'dim_4256', 'dim_4257', 'dim_4258', 'dim_4259', 'dim_4263', 'dim_4264', 'dim_4265', 'dim_4271', 'dim_4272', 'dim_4273', 'dim_4274', 'dim_4275', 'dim_4279', 'dim_4280', 'dim_4281', 'dim_4287', 'dim_4288', 'dim_4289', 'dim_4290', 'dim_4291', 'dim_4295', 'dim_4296', 'dim_4297', 'dim_4302', 'dim_4303', 'dim_4304', 'dim_4311', 'dim_4313', 'dim_4318', 'dim_4319', 'dim_4320', 'dim_4321', 'dim_4322', 'dim_4323', 'dim_4327', 'dim_4328', 'dim_4329', 'dim_4333', 'dim_4334', 'dim_4335', 'dim_4336', 'dim_4338', 'dim_4339', 'dim_4343', 'dim_4344', 'dim_4345', 'dim_4348', 'dim_4349', 'dim_4350', 'dim_4351', 'dim_4352', 'dim_4353', 'dim_4354', 'dim_4355', 'dim_4359', 'dim_4360', 'dim_4364', 'dim_4365', 'dim_4366', 'dim_4367', 'dim_4368', 'dim_4370', 'dim_4371', 'dim_4375', 'dim_4376', 'dim_4380', 'dim_4381', 'dim_4382', 'dim_4383', 'dim_4384', 'dim_4385', 'dim_4386', 'dim_4387', 'dim_4391', 'dim_4392', 'dim_4395', 'dim_4397', 'dim_4398', 'dim_4411', 'dim_4427', 'dim_4471', 'dim_4503', 'dim_4583', 'dim_4594', 'dim_4595', 'dim_4600', 'dim_4601', 'dim_4609', 'dim_4610', 'dim_4611', 'dim_4616', 'dim_4617', 'dim_4626', 'dim_4627', 'dim_4633', 'dim_4641', 'dim_4642', 'dim_4643', 'dim_4649', 'dim_4650', 'dim_4656', 'dim_4657', 'dim_4658', 'dim_4659', 'dim_4665', 'dim_4666', 'dim_4673', 'dim_4674', 'dim_4675', 'dim_4680', 'dim_4681', 'dim_4682', 'dim_4689', 'dim_4690', 'dim_4691', 'dim_4696', 'dim_4697', 'dim_4705', 'dim_4706', 'dim_4707', 'dim_4711', 'dim_4712', 'dim_4713', 'dim_4720', 'dim_4721', 'dim_4722', 'dim_4723', 'dim_4727', 'dim_4728', 'dim_4729', 'dim_4730', 'dim_4736', 'dim_4737', 'dim_4738', 'dim_4739', 'dim_4743', 'dim_4744', 'dim_4745', 'dim_4746', 'dim_4752', 'dim_4753', 'dim_4754', 'dim_4755', 'dim_4759', 'dim_4760', 'dim_4761', 'dim_4762', 'dim_4768', 'dim_4769', 'dim_4770', 'dim_4771', 'dim_4775', 'dim_4776', 'dim_4777', 'dim_4778', 'dim_4784', 'dim_4785', 'dim_4786', 'dim_4787', 'dim_4791', 'dim_4792', 'dim_4793', 'dim_4794', 'dim_4803', 'dim_4807', 'dim_4808', 'dim_4809', 'dim_4810', 'dim_4811', 'dim_4816', 'dim_4823', 'dim_4824', 'dim_4825', 'dim_4826', 'dim_4827', 'dim_4832', 'dim_4834', 'dim_4835', 'dim_4839', 'dim_4840', 'dim_4841', 'dim_4842', 'dim_4843', 'dim_4848', 'dim_4849', 'dim_4851', 'dim_4856', 'dim_4857', 'dim_4858', 'dim_4863', 'dim_4864', 'dim_4865', 'dim_4866', 'dim_4867', 'dim_4871', 'dim_4872', 'dim_4873', 'dim_4874', 'dim_4879', 'dim_4880', 'dim_4883', 'dim_4887', 'dim_4888', 'dim_4889', 'dim_4890', 'dim_4895', 'dim_4896', 'dim_4897', 'dim_4898', 'dim_4899', 'dim_4903', 'dim_4904', 'dim_4905', 'dim_4906', 'dim_4911', 'dim_4912', 'dim_4913', 'dim_4914', 'dim_4915', 'dim_4919', 'dim_4920', 'dim_4921', 'dim_4927', 'dim_4928', 'dim_4929', 'dim_4930', 'dim_4931', 'dim_4935', 'dim_4936', 'dim_4937', 'dim_4942', 'dim_4943', 'dim_4944', 'dim_4945', 'dim_4946', 'dim_4947', 'dim_4951', 'dim_4952', 'dim_4953', 'dim_4958', 'dim_4959', 'dim_4960', 'dim_4961', 'dim_4962', 'dim_4963', 'dim_4967', 'dim_4968', 'dim_4969', 'dim_4973', 'dim_4974', 'dim_4975', 'dim_4976', 'dim_4977', 'dim_4978', 'dim_4979', 'dim_4983', 'dim_4984', 'dim_4985', 'dim_4988', 'dim_4989', 'dim_4990', 'dim_4991', 'dim_4992', 'dim_4993', 'dim_4994', 'dim_4995', 'dim_4999', 'dim_5000', 'dim_5004', 'dim_5005', 'dim_5006', 'dim_5007', 'dim_5008', 'dim_5009', 'dim_5010', 'dim_5011', 'dim_5015', 'dim_5016', 'dim_5020', 'dim_5021', 'dim_5022', 'dim_5023', 'dim_5024', 'dim_5025', 'dim_5026', 'dim_5027', 'dim_5031', 'dim_5032', 'dim_5035', 'dim_5036', 'dim_5037', 'dim_5038', 'dim_5039', 'dim_5040', 'dim_5051', 'dim_5052', 'dim_5053', 'dim_5067', 'dim_5111', 'dim_5112', 'dim_5113', 'dim_5161', 'dim_5234', 'dim_5235', 'dim_5240', 'dim_5241', 'dim_5249', 'dim_5250', 'dim_5251', 'dim_5256', 'dim_5257', 'dim_5266', 'dim_5267', 'dim_5273', 'dim_5281', 'dim_5282', 'dim_5283', 'dim_5289', 'dim_5290', 'dim_5297', 'dim_5298', 'dim_5299', 'dim_5305', 'dim_5306', 'dim_5313', 'dim_5314', 'dim_5315', 'dim_5320', 'dim_5321', 'dim_5322', 'dim_5329', 'dim_5330', 'dim_5331', 'dim_5336', 'dim_5337', 'dim_5344', 'dim_5345', 'dim_5346', 'dim_5347', 'dim_5351', 'dim_5352', 'dim_5353', 'dim_5360', 'dim_5361', 'dim_5362', 'dim_5363', 'dim_5367', 'dim_5368', 'dim_5369', 'dim_5370', 'dim_5376', 'dim_5377', 'dim_5378', 'dim_5379', 'dim_5383', 'dim_5384', 'dim_5385', 'dim_5386', 'dim_5392', 'dim_5393', 'dim_5394', 'dim_5395', 'dim_5399', 'dim_5400', 'dim_5401', 'dim_5402', 'dim_5408', 'dim_5409', 'dim_5410', 'dim_5411', 'dim_5415', 'dim_5416', 'dim_5417', 'dim_5418', 'dim_5424', 'dim_5425', 'dim_5426', 'dim_5427', 'dim_5431', 'dim_5432', 'dim_5433', 'dim_5434', 'dim_5440', 'dim_5447', 'dim_5448', 'dim_5449', 'dim_5450', 'dim_5451', 'dim_5456', 'dim_5463', 'dim_5464', 'dim_5465', 'dim_5466', 'dim_5467', 'dim_5472', 'dim_5473', 'dim_5474', 'dim_5475', 'dim_5479', 'dim_5480', 'dim_5481', 'dim_5482', 'dim_5483', 'dim_5488', 'dim_5489', 'dim_5490', 'dim_5491', 'dim_5496', 'dim_5497', 'dim_5498', 'dim_5503', 'dim_5504', 'dim_5505', 'dim_5506', 'dim_5507', 'dim_5511', 'dim_5512', 'dim_5513', 'dim_5514', 'dim_5519', 'dim_5520', 'dim_5522', 'dim_5523', 'dim_5527', 'dim_5528', 'dim_5529', 'dim_5530', 'dim_5535', 'dim_5536', 'dim_5537', 'dim_5538', 'dim_5539', 'dim_5543', 'dim_5544', 'dim_5545', 'dim_5546', 'dim_5551', 'dim_5552', 'dim_5553', 'dim_5554', 'dim_5555', 'dim_5559', 'dim_5560', 'dim_5561', 'dim_5567', 'dim_5568', 'dim_5569', 'dim_5570', 'dim_5571', 'dim_5575', 'dim_5576', 'dim_5577', 'dim_5582', 'dim_5583', 'dim_5584', 'dim_5585', 'dim_5586', 'dim_5587', 'dim_5591', 'dim_5592', 'dim_5593', 'dim_5598', 'dim_5599', 'dim_5600', 'dim_5601', 'dim_5602', 'dim_5603', 'dim_5607', 'dim_5608', 'dim_5609', 'dim_5613', 'dim_5615', 'dim_5616', 'dim_5617', 'dim_5618', 'dim_5619', 'dim_5623', 'dim_5624', 'dim_5625', 'dim_5628', 'dim_5629', 'dim_5630', 'dim_5631', 'dim_5632', 'dim_5633', 'dim_5634', 'dim_5635', 'dim_5639', 'dim_5640', 'dim_5644', 'dim_5645', 'dim_5646', 'dim_5647', 'dim_5648', 'dim_5649', 'dim_5650', 'dim_5651', 'dim_5655', 'dim_5656', 'dim_5660', 'dim_5661', 'dim_5662', 'dim_5663', 'dim_5664', 'dim_5665', 'dim_5666', 'dim_5667', 'dim_5671', 'dim_5672', 'dim_5675', 'dim_5676', 'dim_5677', 'dim_5678', 'dim_5679', 'dim_5680', 'dim_5691', 'dim_5692', 'dim_5752', 'dim_5753', 'dim_5768', 'dim_5783', 'dim_5784', 'dim_5800', 'dim_5801', 'dim_5875', 'dim_5881', 'dim_5889', 'dim_5891', 'dim_5896', 'dim_5897', 'dim_5905', 'dim_5906', 'dim_5907', 'dim_5913', 'dim_5921', 'dim_5922', 'dim_5923', 'dim_5929', 'dim_5930', 'dim_5937', 'dim_5939', 'dim_5944', 'dim_5945', 'dim_5946', 'dim_5953', 'dim_5954', 'dim_5960', 'dim_5961', 'dim_5962', 'dim_5969', 'dim_5970', 'dim_5971', 'dim_5976', 'dim_5977', 'dim_5978', 'dim_5984', 'dim_5985', 'dim_5986', 'dim_5987', 'dim_5991', 'dim_5992', 'dim_5993', 'dim_5994', 'dim_6001', 'dim_6002', 'dim_6003', 'dim_6007', 'dim_6008', 'dim_6009', 'dim_6010', 'dim_6017', 'dim_6018', 'dim_6019', 'dim_6023', 'dim_6024', 'dim_6025', 'dim_6026', 'dim_6032', 'dim_6033', 'dim_6034', 'dim_6035', 'dim_6039', 'dim_6040', 'dim_6041', 'dim_6042', 'dim_6048', 'dim_6055', 'dim_6056', 'dim_6057', 'dim_6058', 'dim_6065', 'dim_6066', 'dim_6067', 'dim_6071', 'dim_6072', 'dim_6073', 'dim_6074', 'dim_6075', 'dim_6080', 'dim_6081', 'dim_6082', 'dim_6083', 'dim_6087', 'dim_6088', 'dim_6089', 'dim_6090', 'dim_6091', 'dim_6096', 'dim_6098', 'dim_6099', 'dim_6103', 'dim_6104', 'dim_6105', 'dim_6106', 'dim_6107', 'dim_6112', 'dim_6119', 'dim_6120', 'dim_6121', 'dim_6122', 'dim_6123', 'dim_6128', 'dim_6135', 'dim_6136', 'dim_6137', 'dim_6138', 'dim_6143', 'dim_6144', 'dim_6151', 'dim_6152', 'dim_6153', 'dim_6154', 'dim_6159', 'dim_6160', 'dim_6167', 'dim_6168', 'dim_6169', 'dim_6175', 'dim_6176', 'dim_6183', 'dim_6184', 'dim_6185', 'dim_6191', 'dim_6192', 'dim_6193', 'dim_6194', 'dim_6195', 'dim_6199', 'dim_6200', 'dim_6201', 'dim_6207', 'dim_6208', 'dim_6209', 'dim_6210', 'dim_6211', 'dim_6215', 'dim_6216', 'dim_6217', 'dim_6223', 'dim_6224', 'dim_6225', 'dim_6226', 'dim_6227', 'dim_6231', 'dim_6232', 'dim_6233', 'dim_6239', 'dim_6240', 'dim_6242', 'dim_6243', 'dim_6247', 'dim_6248', 'dim_6249', 'dim_6253', 'dim_6255', 'dim_6256', 'dim_6257', 'dim_6258', 'dim_6259', 'dim_6263', 'dim_6264', 'dim_6265', 'dim_6268', 'dim_6269', 'dim_6271', 'dim_6272', 'dim_6273', 'dim_6274', 'dim_6275', 'dim_6279', 'dim_6280', 'dim_6284', 'dim_6285', 'dim_6286', 'dim_6287', 'dim_6288', 'dim_6289', 'dim_6290', 'dim_6291', 'dim_6295', 'dim_6296', 'dim_6300', 'dim_6301', 'dim_6302', 'dim_6303', 'dim_6304', 'dim_6305', 'dim_6306', 'dim_6307', 'dim_6311', 'dim_6312', 'dim_6316', 'dim_6317', 'dim_6379', 'dim_6381', 'dim_6391', 'dim_6392', 'dim_6393', 'dim_6423', 'dim_6424', 'dim_6440', 'dim_6514', 'dim_6521', 'dim_6536', 'dim_6537', 'dim_6547', 'dim_6552', 'dim_6553', 'dim_6563', 'dim_6568', 'dim_6569', 'dim_6570', 'dim_6578', 'dim_6584', 'dim_6585', 'dim_6586', 'dim_6593', 'dim_6594', 'dim_6595', 'dim_6601', 'dim_6602', 'dim_6609', 'dim_6610', 'dim_6611', 'dim_6616', 'dim_6617', 'dim_6618', 'dim_6625', 'dim_6626', 'dim_6627', 'dim_6631', 'dim_6632', 'dim_6633', 'dim_6634', 'dim_6647', 'dim_6648', 'dim_6649', 'dim_6650', 'dim_6659', 'dim_6663', 'dim_6664', 'dim_6665', 'dim_6666', 'dim_6672', 'dim_6675', 'dim_6679', 'dim_6680', 'dim_6681', 'dim_6682', 'dim_6683', 'dim_6688', 'dim_6691', 'dim_6695', 'dim_6696', 'dim_6697', 'dim_6698', 'dim_6699', 'dim_6704', 'dim_6707', 'dim_6711', 'dim_6712', 'dim_6713', 'dim_6714', 'dim_6715', 'dim_6720', 'dim_6723', 'dim_6727', 'dim_6728', 'dim_6729', 'dim_6730', 'dim_6731', 'dim_6736', 'dim_6739', 'dim_6743', 'dim_6744', 'dim_6745', 'dim_6746', 'dim_6747', 'dim_6752', 'dim_6755', 'dim_6759', 'dim_6760', 'dim_6761', 'dim_6762', 'dim_6763', 'dim_6768', 'dim_6771', 'dim_6775', 'dim_6776', 'dim_6777', 'dim_6778', 'dim_6783', 'dim_6784', 'dim_6787', 'dim_6791', 'dim_6792', 'dim_6793', 'dim_6799', 'dim_6800', 'dim_6803', 'dim_6807', 'dim_6808', 'dim_6809', 'dim_6815', 'dim_6816', 'dim_6819', 'dim_6823', 'dim_6824', 'dim_6825', 'dim_6831', 'dim_6832', 'dim_6833', 'dim_6834', 'dim_6835', 'dim_6839', 'dim_6840', 'dim_6841', 'dim_6847', 'dim_6848', 'dim_6849', 'dim_6851', 'dim_6855', 'dim_6856', 'dim_6857', 'dim_6863', 'dim_6864', 'dim_6866', 'dim_6871', 'dim_6872', 'dim_6873', 'dim_6882', 'dim_6883', 'dim_6887', 'dim_6889', 'dim_6897', 'dim_6898', 'dim_6899', 'dim_6903', 'dim_6904', 'dim_6905', 'dim_6908', 'dim_6909', 'dim_6910', 'dim_6913', 'dim_6915', 'dim_6919', 'dim_6920', 'dim_6924', 'dim_6925', 'dim_6926', 'dim_6927', 'dim_6929', 'dim_6930', 'dim_6931', 'dim_6935', 'dim_6936', 'dim_6940', 'dim_6941', 'dim_6942', 'dim_6943', 'dim_6944', 'dim_6951', 'dim_6952', 'dim_6955', 'dim_7003', 'dim_7005', 'dim_7006', 'dim_7015', 'dim_7016', 'dim_7031', 'dim_7032', 'dim_7033', 'dim_7048', 'dim_7064', 'dim_7080', 'dim_7138', 'dim_7176', 'dim_7177', 'dim_7186', 'dim_7187', 'dim_7192', 'dim_7193', 'dim_7207', 'dim_7208', 'dim_7209', 'dim_7210', 'dim_7215', 'dim_7223', 'dim_7225', 'dim_7226', 'dim_7231', 'dim_7234', 'dim_7239', 'dim_7240', 'dim_7241', 'dim_7242', 'dim_7248', 'dim_7249', 'dim_7255', 'dim_7256', 'dim_7257', 'dim_7258', 'dim_7264', 'dim_7265', 'dim_7271', 'dim_7272', 'dim_7273', 'dim_7274', 'dim_7280', 'dim_7287', 'dim_7288', 'dim_7289', 'dim_7290', 'dim_7296', 'dim_7303', 'dim_7304', 'dim_7305', 'dim_7306', 'dim_7319', 'dim_7320', 'dim_7321', 'dim_7322', 'dim_7323', 'dim_7335', 'dim_7336', 'dim_7337', 'dim_7338', 'dim_7339', 'dim_7351', 'dim_7352', 'dim_7353', 'dim_7354', 'dim_7355', 'dim_7367', 'dim_7368', 'dim_7369', 'dim_7370', 'dim_7371', 'dim_7383', 'dim_7384', 'dim_7385', 'dim_7386', 'dim_7392', 'dim_7399', 'dim_7400', 'dim_7401', 'dim_7402', 'dim_7407', 'dim_7408', 'dim_7415', 'dim_7416', 'dim_7417', 'dim_7418', 'dim_7423', 'dim_7424', 'dim_7431', 'dim_7432', 'dim_7433', 'dim_7439', 'dim_7447', 'dim_7448', 'dim_7449', 'dim_7455', 'dim_7456', 'dim_7463', 'dim_7464', 'dim_7465', 'dim_7471', 'dim_7472', 'dim_7479', 'dim_7480', 'dim_7481', 'dim_7487', 'dim_7488', 'dim_7491', 'dim_7495', 'dim_7496', 'dim_7497', 'dim_7505', 'dim_7511', 'dim_7512', 'dim_7513', 'dim_7521', 'dim_7522', 'dim_7527', 'dim_7528', 'dim_7529', 'dim_7538', 'dim_7543', 'dim_7544', 'dim_7545', 'dim_7548', 'dim_7549', 'dim_7553', 'dim_7554', 'dim_7559', 'dim_7560', 'dim_7563', 'dim_7564', 'dim_7565', 'dim_7566', 'dim_7569', 'dim_7570', 'dim_7575', 'dim_7576', 'dim_7579', 'dim_7580', 'dim_7586', 'dim_7591', 'dim_7627', 'dim_7628', 'dim_7629', 'dim_7630', 'dim_7631', 'dim_7632', 'dim_7643', 'dim_7644', 'dim_7645', 'dim_7646', 'dim_7647', 'dim_7648', 'dim_7655', 'dim_7656', 'dim_7657', 'dim_7662', 'dim_7663', 'dim_7664', 'dim_7672', 'dim_7673', 'dim_7688', 'dim_7704', 'dim_7817', 'dim_7832', 'dim_7833', 'dim_7849', 'dim_7865', 'dim_7871', 'dim_7888', 'dim_7897', 'dim_7903', 'dim_7904', 'dim_7911', 'dim_7913', 'dim_7920', 'dim_7927', 'dim_7928', 'dim_7929', 'dim_7943', 'dim_7944', 'dim_7945', 'dim_7951', 'dim_7952', 'dim_7959', 'dim_7960', 'dim_7961', 'dim_7967', 'dim_7968', 'dim_7975', 'dim_7976', 'dim_7977', 'dim_7984', 'dim_7991', 'dim_7992', 'dim_7993', 'dim_8007', 'dim_8008', 'dim_8009', 'dim_8015', 'dim_8023', 'dim_8024', 'dim_8025', 'dim_8031', 'dim_8032', 'dim_8039', 'dim_8040', 'dim_8041', 'dim_8047', 'dim_8048', 'dim_8055', 'dim_8056', 'dim_8057', 'dim_8063', 'dim_8064', 'dim_8071', 'dim_8072', 'dim_8073', 'dim_8079', 'dim_8087', 'dim_8088', 'dim_8089', 'dim_8095', 'dim_8096', 'dim_8103', 'dim_8104', 'dim_8111', 'dim_8112', 'dim_8119', 'dim_8120', 'dim_8135', 'dim_8136', 'dim_8137', 'dim_8151', 'dim_8152', 'dim_8153', 'dim_8168', 'dim_8169', 'dim_8184', 'dim_8185', 'dim_8187', 'dim_8188', 'dim_8201', 'dim_8203', 'dim_8204', 'dim_8205', 'dim_8216', 'dim_8219', 'dim_8231', 'dim_8232', 'dim_8251', 'dim_8252', 'dim_8253', 'dim_8254', 'dim_8255', 'dim_8256', 'dim_8267', 'dim_8268', 'dim_8269', 'dim_8270', 'dim_8271', 'dim_8272', 'dim_8286', 'dim_8287', 'dim_8288', 'dim_8296', 'dim_8297', 'dim_8301', 'dim_8302', 'dim_8303', 'dim_8304', 'dim_8312', 'dim_8313', 'dim_8328', 'dim_8344', 'dim_8360', 'dim_8511', 'dim_8512', 'dim_8525', 'dim_8526', 'dim_8528', 'dim_8543', 'dim_8544', 'dim_8560', 'dim_8575', 'dim_8590', 'dim_8607', 'dim_8608', 'dim_8622', 'dim_8670', 'dim_8688', 'dim_8703', 'dim_8780', 'dim_8796', 'dim_8811', 'dim_8827', 'dim_8828', 'dim_8843', 'dim_8875', 'dim_8893', 'dim_8894', 'dim_8895', 'dim_8896', 'dim_8926', 'dim_8927', 'dim_8928', 'dim_8937', 'dim_8942', 'dim_8943', 'dim_8944', 'dim_8958', 'dim_8959', 'dim_8960', 'dim_9017', 'dim_9132', 'dim_9148', 'dim_9149', 'dim_9166', 'dim_9180', 'dim_9182', 'dim_9196', 'dim_9197', 'dim_9198', 'dim_9199', 'dim_9200', 'dim_9212', 'dim_9213', 'dim_9214', 'dim_9228', 'dim_9231', 'dim_9232', 'dim_9244', 'dim_9247', 'dim_9262', 'dim_9263', 'dim_9295', 'dim_9325', 'dim_9435', 'dim_9451', 'dim_9467', 'dim_9536', 'dim_9545', 'dim_9559', 'dim_9583', 'dim_9592', 'dim_9593', 'dim_9638', 'dim_9639', 'dim_9640', 'dim_9655', 'dim_9656', 'dim_9657', 'dim_9671', 'dim_9673', 'dim_9687', 'dim_9688', 'dim_9690', 'dim_9706', 'dim_9719', 'dim_9721', 'dim_9722', 'dim_9737', 'dim_9739', 'dim_9751', 'dim_9753', 'dim_9755', 'dim_9767', 'dim_9769', 'dim_9771', 'dim_9787', 'dim_9788', 'dim_9789', 'dim_9803', 'dim_9805', 'dim_9819', 'dim_9822', 'dim_9838', 'dim_9839', 'dim_9847', 'dim_9848', 'dim_9850', 'dim_9851', 'dim_9852', 'dim_9863', 'dim_9864', 'dim_9866', 'dim_9867', 'dim_9868', 'dim_9869', 'dim_9879', 'dim_9880', 'dim_9881', 'dim_9882', 'dim_9883', 'dim_9884', 'dim_9885', 'dim_9888', 'dim_9895', 'dim_9896', 'dim_9897', 'dim_9898', 'dim_9902', 'dim_9903', 'dim_9904', 'dim_9911', 'dim_9912', 'dim_9913', 'dim_9914', 'dim_9927', 'dim_9928', 'dim_9929', 'dim_9930', 'dim_9943', 'dim_9944', 'dim_9945', 'dim_9959', 'dim_9960', 'dim_9961', 'dim_9962', 'dim_9975', 'dim_9976', 'dim_9977', 'dim_9991', 'dim_9992', 'dim_9993', 'dim_10007', 'dim_10008', 'dim_10009', 'dim_10023', 'dim_10024', 'dim_10025', 'dim_10039', 'dim_10040', 'dim_10041', 'dim_10055', 'dim_10056', 'dim_10057', 'dim_10058', 'dim_10059', 'dim_10071', 'dim_10072', 'dim_10073', 'dim_10074', 'dim_10075', 'dim_10086', 'dim_10087', 'dim_10089', 'dim_10091', 'dim_10092', 'dim_10107', 'dim_10122', 'dim_10138', 'dim_10140', 'dim_10141', 'dim_10151', 'dim_10152', 'dim_10153', 'dim_10157', 'dim_10167', 'dim_10168', 'dim_10169', 'dim_10183', 'dim_10184', 'dim_10185', 'dim_10199', 'dim_10200']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t88.6s = Fit runtime\n",
      "\t8082 features in original data used to generate 8082 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.84 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 92.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-10240_sdf/learner.pkl\n",
      "Saving ./agModels-10240_sdf/utils/data/X.pkl\n",
      "Saving ./agModels-10240_sdf/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 8082 of 8082 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 8082 of 8082 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.16s\t = Training   runtime\n",
      "\t1.27s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.75s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 8082 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.01s\t = Training   runtime\n",
      "\t1.8s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0456\t = Validation score   (-root_mean_squared_error)\n",
      "\t3131.73s\t = Training   runtime\n",
      "\t10.4s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 8082 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0483\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.48s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0457\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.06s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0481\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.38s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.05s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 8082 features.\n",
      "\tDropped 0 of 8082 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8082 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0489\t = Validation score   (-root_mean_squared_error)\n",
      "\t105.16s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 16\n",
      "Ensemble indices: [7, 0, 5, 7, 0, 7, 5, 7, 0, 5, 7, 0, 7, 5, 0, 7]\n",
      "Ensemble weights: \n",
      "[0.3125 0.     0.     0.     0.     0.25   0.     0.4375 0.    ]\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.044\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0463\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.47s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0467\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.35s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.96s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0459\t = Validation score   (-root_mean_squared_error)\n",
      "\t206.06s\t = Training   runtime\n",
      "\t8.8s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0463\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.07s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0447\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.94s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.0472\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.62s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.47s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.047\t = Validation score   (-root_mean_squared_error)\n",
      "\t115.46s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 5\n",
      "Ensemble indices: [7, 5, 7, 5, 7]\n",
      "Ensemble weights: \n",
      "[0.  0.  0.  0.  0.  0.4 0.  0.6 0. ]\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0437\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.93s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0438\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.15s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0454\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.4s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0458\t = Validation score   (-root_mean_squared_error)\n",
      "\t2914.2s\t = Training   runtime\n",
      "\t9.54s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0459\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.41s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0443\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.88s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0456\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.22s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0441\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.73s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0456\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.86s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 17\n",
      "Ensemble indices: [1, 5, 7, 1, 5, 1, 7, 1, 5, 1, 7, 5, 1, 7, 1, 5, 1]\n",
      "Ensemble weights: \n",
      "[0.         0.47058824 0.         0.         0.         0.29411765\n",
      " 0.         0.23529412 0.        ]\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.043\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.0456\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.18s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0439\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.66s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.0459\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.52s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0452\t = Validation score   (-root_mean_squared_error)\n",
      "\t370.52s\t = Training   runtime\n",
      "\t10.12s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 8091 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.47s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0441\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.56s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.46s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0441\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.64s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 8091 features.\n",
      "\tDropped 0 of 8091 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 8091 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0453\t = Validation score   (-root_mean_squared_error)\n",
      "\t89.98s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 19\n",
      "Ensemble indices: [1, 5, 7, 1, 5, 1, 5, 7, 1, 5, 1, 7, 5, 1, 5, 1, 7, 1, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.42105263 0.         0.         0.         0.36842105\n",
      " 0.         0.21052632 0.        ]\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0429\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 8343.97s ... Best model: \"WeightedEnsemble_L5\"\n",
      "Loading: ./agModels-10240_sdf/models/trainer.pkl\n",
      "Saving ./agModels-10240_sdf/models/trainer.pkl\n",
      "Saving ./agModels-10240_sdf/learner.pkl\n",
      "Saving ./agModels-10240_sdf/predictor.pkl\n",
      "Saving ./agModels-10240_sdf/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-10240_sdf/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-10240_sdf/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-10240_sdf'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_10231</th>\n",
       "      <th>dim_10232</th>\n",
       "      <th>dim_10233</th>\n",
       "      <th>dim_10234</th>\n",
       "      <th>dim_10235</th>\n",
       "      <th>dim_10236</th>\n",
       "      <th>dim_10237</th>\n",
       "      <th>dim_10238</th>\n",
       "      <th>dim_10239</th>\n",
       "      <th>dim_10240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "46     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "101    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "175    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "9      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "136    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_10231  dim_10232  dim_10233  dim_10234  dim_10235  dim_10236  \\\n",
       "46   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "101  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "175  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9    ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "136  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     dim_10237  dim_10238  dim_10239  dim_10240  \n",
       "46         0.0        0.0        0.0        0.0  \n",
       "101        0.0        0.0        0.0        0.0  \n",
       "175        0.0        0.0        0.0        0.0  \n",
       "9          0.0        0.0        0.0        0.0  \n",
       "136        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 10240 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-10240_sdf/predictor.pkl\n",
      "Loading: ./agModels-10240_sdf/learner.pkl\n",
      "Loading: ./agModels-10240_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.045845797954722774\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.045845797954722774,\n",
      "    \"mean_squared_error\": -0.0021018371901052628,\n",
      "    \"mean_absolute_error\": -0.03366941952705383,\n",
      "    \"r2\": 0.2852379482668894,\n",
      "    \"pearsonr\": 0.5425642270570767,\n",
      "    \"median_absolute_error\": -0.023420639038085944\n",
      "}\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3855823874473572\n",
      "0.37652477622032166\n",
      "0.37653520703315735\n",
      "0.5039375424385071\n",
      "0.396253377199173\n",
      "0.3928704261779785\n",
      "0.44374266266822815\n",
      "0.48590314388275146\n",
      "0.4101971387863159\n",
      "0.3381831645965576\n",
      "0.35397082567214966\n",
      "0.39465779066085815\n",
      "0.41688838601112366\n",
      "0.41871803998947144\n",
      "0.4270835518836975\n",
      "0.4227288067340851\n",
      "0.4115671217441559\n",
      "0.38709789514541626\n",
      "0.35796669125556946\n",
      "0.3658645451068878\n",
      "0.4334506690502167\n",
      "0.4040217697620392\n",
      "0.3799241781234741\n",
      "0.3704388737678528\n",
      "0.4786181151866913\n",
      "0.4168073534965515\n",
      "0.43478724360466003\n",
      "0.387883722782135\n",
      "0.40147292613983154\n",
      "0.3734070956707001\n",
      "0.46458470821380615\n",
      "0.3686337471008301\n",
      "0.38103538751602173\n",
      "0.408187597990036\n",
      "0.3927827477455139\n",
      "0.3706616163253784\n",
      "0.373718798160553\n",
      "0.4444604814052582\n",
      "0.40578195452690125\n",
      "0.3785912096500397\n",
      "0.4793473482131958\n",
      "0.3530932664871216\n",
      "0.4819127321243286\n",
      "0.36806443333625793\n",
      "0.4265803098678589\n",
      "0.38869011402130127\n",
      "0.43856433033943176\n",
      "0.38580620288848877\n",
      "0.36255717277526855\n",
      "0.35951322317123413\n",
      "0.4118318557739258\n",
      "0.35934367775917053\n",
      "0.4242067337036133\n",
      "0.42542344331741333\n",
      "0.3986271321773529\n",
      "0.38622334599494934\n",
      "0.39488449692726135\n",
      "0.4034756124019623\n",
      "0.3530852198600769\n",
      "0.43475329875946045\n",
      "0.3992101550102234\n",
      "0.39327263832092285\n",
      "0.34914374351501465\n",
      "0.39908862113952637\n",
      "0.42682966589927673\n",
      "0.343377023935318\n",
      "0.39748650789260864\n",
      "0.3538283109664917\n",
      "0.37023210525512695\n",
      "0.42850902676582336\n",
      "0.4134294092655182\n",
      "0.3869338035583496\n",
      "0.3869673013687134\n",
      "0.3720129728317261\n",
      "0.3999671936035156\n",
      "0.3575865626335144\n",
      "0.3807613253593445\n",
      "0.3769313395023346\n",
      "0.35553792119026184\n",
      "0.43134188652038574\n",
      "0.4144885540008545\n",
      "0.4061685800552368\n",
      "0.3504653573036194\n",
      "0.3760746121406555\n",
      "0.3841245174407959\n",
      "0.43437257409095764\n",
      "0.4027397632598877\n",
      "0.36066895723342896\n",
      "Predictions:  \n",
      " 46     0.385582\n",
      "101    0.376525\n",
      "175    0.376535\n",
      "9      0.503938\n",
      "136    0.396253\n",
      "         ...   \n",
      "173    0.376075\n",
      "5      0.384125\n",
      "55     0.434373\n",
      "428    0.402740\n",
      "334    0.360669\n",
      "Name: drag, Length: 88, dtype: float32\n",
      "{'root_mean_squared_error': -0.045845797954722774, 'mean_squared_error': -0.0021018371901052628, 'mean_absolute_error': -0.03366941952705383, 'r2': 0.2852379482668894, 'pearsonr': 0.5425642270570767, 'median_absolute_error': -0.023420639038085944}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L5  -0.042904      54.647398  7045.368813                0.000890           0.538277            5       True         40\n",
      "1      WeightedEnsemble_L4  -0.042968      36.697826  3892.419991                0.001086           0.483313            4       True         30\n",
      "2      WeightedEnsemble_L3  -0.043733      19.913322  3416.580253                0.000586           0.397269            3       True         20\n",
      "3          LightGBM_BAG_L3  -0.043768      33.985416  3806.322276                0.700787          15.153840            3       True         22\n",
      "4          LightGBM_BAG_L4  -0.043889      52.335592  6967.622514                0.863915          12.664916            4       True         32\n",
      "5      WeightedEnsemble_L2  -0.043978       2.813807    80.697425                0.000946           0.430221            2       True         10\n",
      "6    NeuralNetTorch_BAG_L4  -0.044054      52.837976  6998.601927                1.366299          43.644329            4       True         38\n",
      "7    NeuralNetTorch_BAG_L3  -0.044062      34.868298  3847.898365                1.583668          56.729929            3       True         28\n",
      "8   NeuralNetFastAI_BAG_L4  -0.044134      52.416295  6988.521291                0.944618          33.563693            4       True         36\n",
      "9    NeuralNetTorch_BAG_L2  -0.044229      19.078201  3399.238901                0.857128          21.470441            2       True         18\n",
      "10  NeuralNetFastAI_BAG_L3  -0.044324      34.412285  3820.052909                1.127655          28.884473            3       True         26\n",
      "11  NeuralNetFastAI_BAG_L2  -0.044740      19.055608  3394.712543                0.834535          16.944083            2       True         16\n",
      "12   NeuralNetTorch_BAG_L1  -0.044980       0.701397    30.047072                0.701397          30.047072            1       True          8\n",
      "13          XGBoost_BAG_L4  -0.045006      52.331740  7002.417482                0.860063          47.459884            4       True         37\n",
      "14       LightGBMXT_BAG_L3  -0.045042      34.075703  3810.095383                0.791073          18.926947            3       True         21\n",
      "15         CatBoost_BAG_L4  -0.045213      61.596458  7325.476490               10.124781         370.518892            4       True         34\n",
      "16    LightGBMLarge_BAG_L4  -0.045324      52.539340  7044.936426                1.067662          89.978828            4       True         39\n",
      "17  RandomForestMSE_BAG_L3  -0.045387      34.021477  3799.567457                0.736847           8.399021            3       True         23\n",
      "18          XGBoost_BAG_L3  -0.045575      34.390928  3840.391025                1.106298          49.222589            3       True         27\n",
      "19    LightGBMLarge_BAG_L3  -0.045581      34.653000  3852.025501                1.368370          60.857065            3       True         29\n",
      "20         CatBoost_BAG_L1  -0.045616      10.402238  3131.726905               10.402238        3131.726905            1       True          4\n",
      "21       LightGBMXT_BAG_L4  -0.045630      52.481232  6984.141783                1.009555          29.184185            4       True         31\n",
      "22  NeuralNetFastAI_BAG_L1  -0.045729       0.843191    26.055804                0.843191          26.055804            1       True          6\n",
      "23         CatBoost_BAG_L3  -0.045799      42.828624  6705.369738                9.543994        2914.201302            3       True         24\n",
      "24    ExtraTreesMSE_BAG_L3  -0.045879      34.512985  3802.582433                1.228355          11.413996            3       True         25\n",
      "25  RandomForestMSE_BAG_L4  -0.045915      52.631028  6964.476501                1.159351           9.518903            4       True         33\n",
      "26         CatBoost_BAG_L2  -0.045941      27.017529  3583.825975                8.796456         206.057515            2       True         14\n",
      "27    ExtraTreesMSE_BAG_L4  -0.046158      53.297365  6969.422635                1.825688          14.465037            4       True         35\n",
      "28       LightGBMXT_BAG_L1  -0.046238       1.268273    24.164328                1.268273          24.164328            1       True          1\n",
      "29         LightGBM_BAG_L1  -0.046238       1.034039    15.751665                1.034039          15.751665            1       True          2\n",
      "30  RandomForestMSE_BAG_L2  -0.046242      19.079654  3386.731447                0.858581           8.962987            2       True         13\n",
      "31       LightGBMXT_BAG_L2  -0.046264      18.980083  3386.235805                0.759010           8.467345            2       True         11\n",
      "32    ExtraTreesMSE_BAG_L2  -0.046292      19.050568  3385.839437                0.829494           8.070977            2       True         15\n",
      "33         LightGBM_BAG_L2  -0.046686      18.974693  3386.118766                0.753620           8.350306            2       True         12\n",
      "34    LightGBMLarge_BAG_L2  -0.046968      19.110858  3493.229401                0.889785         115.460941            2       True         19\n",
      "35          XGBoost_BAG_L2  -0.047209      18.706023  3397.383841                0.484949          19.615381            2       True         17\n",
      "36          XGBoost_BAG_L1  -0.048111       0.419225    22.375360                0.419225          22.375360            1       True          7\n",
      "37    ExtraTreesMSE_BAG_L1  -0.048342       0.829413     9.478027                0.829413           9.478027            1       True          5\n",
      "38  RandomForestMSE_BAG_L1  -0.048498       1.796543    13.008452                1.796543          13.008452            1       True          3\n",
      "39    LightGBMLarge_BAG_L1  -0.048853       0.926753   105.160849                0.926753         105.160849            1       True          9\n",
      "Number of models trained: 40\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 5 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('int', ['bool']) : 8082 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L2': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L2': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L2': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L2': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L3': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L3': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L3': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L3': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L3': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L3': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L3': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L3': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L3': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L3': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L4': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L4': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L4': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L4': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L4': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L4': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L4': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L4': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L4': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L4': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L5': 'WeightedEnsembleModel'}, 'model_performance': {'LightGBMXT_BAG_L1': -0.04623754806710462, 'LightGBM_BAG_L1': -0.046237548527766875, 'RandomForestMSE_BAG_L1': -0.048498198003396824, 'CatBoost_BAG_L1': -0.045615889504167055, 'ExtraTreesMSE_BAG_L1': -0.04834193099007964, 'NeuralNetFastAI_BAG_L1': -0.0457294552439902, 'XGBoost_BAG_L1': -0.04811147158918628, 'NeuralNetTorch_BAG_L1': -0.044980061108754445, 'LightGBMLarge_BAG_L1': -0.04885277741549908, 'WeightedEnsemble_L2': -0.04397796907089541, 'LightGBMXT_BAG_L2': -0.04626412737549878, 'LightGBM_BAG_L2': -0.04668633084313691, 'RandomForestMSE_BAG_L2': -0.04624247923075548, 'CatBoost_BAG_L2': -0.045940572515154064, 'ExtraTreesMSE_BAG_L2': -0.046292194655916816, 'NeuralNetFastAI_BAG_L2': -0.044739749235595705, 'XGBoost_BAG_L2': -0.047208903673305325, 'NeuralNetTorch_BAG_L2': -0.044228577928657364, 'LightGBMLarge_BAG_L2': -0.046967738289996105, 'WeightedEnsemble_L3': -0.04373332867664774, 'LightGBMXT_BAG_L3': -0.04504159657130684, 'LightGBM_BAG_L3': -0.043767973700829244, 'RandomForestMSE_BAG_L3': -0.04538685739987965, 'CatBoost_BAG_L3': -0.04579862208205818, 'ExtraTreesMSE_BAG_L3': -0.04587858119081806, 'NeuralNetFastAI_BAG_L3': -0.04432359570783015, 'XGBoost_BAG_L3': -0.04557457037072817, 'NeuralNetTorch_BAG_L3': -0.044062348643597524, 'LightGBMLarge_BAG_L3': -0.04558109871381328, 'WeightedEnsemble_L4': -0.042968496297668184, 'LightGBMXT_BAG_L4': -0.045630177568906374, 'LightGBM_BAG_L4': -0.04388877161735554, 'RandomForestMSE_BAG_L4': -0.04591490455268046, 'CatBoost_BAG_L4': -0.045212673952310975, 'ExtraTreesMSE_BAG_L4': -0.04615817830576693, 'NeuralNetFastAI_BAG_L4': -0.0441338660448369, 'XGBoost_BAG_L4': -0.045006204303813795, 'NeuralNetTorch_BAG_L4': -0.04405401006863709, 'LightGBMLarge_BAG_L4': -0.04532379977837349, 'WeightedEnsemble_L5': -0.04290447206172206}, 'model_best': 'WeightedEnsemble_L5', 'model_paths': {'LightGBMXT_BAG_L1': './agModels-10240_sdf/models/LightGBMXT_BAG_L1/', 'LightGBM_BAG_L1': './agModels-10240_sdf/models/LightGBM_BAG_L1/', 'RandomForestMSE_BAG_L1': './agModels-10240_sdf/models/RandomForestMSE_BAG_L1/', 'CatBoost_BAG_L1': './agModels-10240_sdf/models/CatBoost_BAG_L1/', 'ExtraTreesMSE_BAG_L1': './agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/', 'NeuralNetFastAI_BAG_L1': './agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/', 'XGBoost_BAG_L1': './agModels-10240_sdf/models/XGBoost_BAG_L1/', 'NeuralNetTorch_BAG_L1': './agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/', 'LightGBMLarge_BAG_L1': './agModels-10240_sdf/models/LightGBMLarge_BAG_L1/', 'WeightedEnsemble_L2': './agModels-10240_sdf/models/WeightedEnsemble_L2/', 'LightGBMXT_BAG_L2': './agModels-10240_sdf/models/LightGBMXT_BAG_L2/', 'LightGBM_BAG_L2': './agModels-10240_sdf/models/LightGBM_BAG_L2/', 'RandomForestMSE_BAG_L2': './agModels-10240_sdf/models/RandomForestMSE_BAG_L2/', 'CatBoost_BAG_L2': './agModels-10240_sdf/models/CatBoost_BAG_L2/', 'ExtraTreesMSE_BAG_L2': './agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/', 'NeuralNetFastAI_BAG_L2': './agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/', 'XGBoost_BAG_L2': './agModels-10240_sdf/models/XGBoost_BAG_L2/', 'NeuralNetTorch_BAG_L2': './agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/', 'LightGBMLarge_BAG_L2': './agModels-10240_sdf/models/LightGBMLarge_BAG_L2/', 'WeightedEnsemble_L3': './agModels-10240_sdf/models/WeightedEnsemble_L3/', 'LightGBMXT_BAG_L3': './agModels-10240_sdf/models/LightGBMXT_BAG_L3/', 'LightGBM_BAG_L3': './agModels-10240_sdf/models/LightGBM_BAG_L3/', 'RandomForestMSE_BAG_L3': './agModels-10240_sdf/models/RandomForestMSE_BAG_L3/', 'CatBoost_BAG_L3': './agModels-10240_sdf/models/CatBoost_BAG_L3/', 'ExtraTreesMSE_BAG_L3': './agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/', 'NeuralNetFastAI_BAG_L3': './agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/', 'XGBoost_BAG_L3': './agModels-10240_sdf/models/XGBoost_BAG_L3/', 'NeuralNetTorch_BAG_L3': './agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/', 'LightGBMLarge_BAG_L3': './agModels-10240_sdf/models/LightGBMLarge_BAG_L3/', 'WeightedEnsemble_L4': './agModels-10240_sdf/models/WeightedEnsemble_L4/', 'LightGBMXT_BAG_L4': './agModels-10240_sdf/models/LightGBMXT_BAG_L4/', 'LightGBM_BAG_L4': './agModels-10240_sdf/models/LightGBM_BAG_L4/', 'RandomForestMSE_BAG_L4': './agModels-10240_sdf/models/RandomForestMSE_BAG_L4/', 'CatBoost_BAG_L4': './agModels-10240_sdf/models/CatBoost_BAG_L4/', 'ExtraTreesMSE_BAG_L4': './agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/', 'NeuralNetFastAI_BAG_L4': './agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/', 'XGBoost_BAG_L4': './agModels-10240_sdf/models/XGBoost_BAG_L4/', 'NeuralNetTorch_BAG_L4': './agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/', 'LightGBMLarge_BAG_L4': './agModels-10240_sdf/models/LightGBMLarge_BAG_L4/', 'WeightedEnsemble_L5': './agModels-10240_sdf/models/WeightedEnsemble_L5/'}, 'model_fit_times': {'LightGBMXT_BAG_L1': 24.16432762145996, 'LightGBM_BAG_L1': 15.751664638519287, 'RandomForestMSE_BAG_L1': 13.008451700210571, 'CatBoost_BAG_L1': 3131.726905107498, 'ExtraTreesMSE_BAG_L1': 9.478026628494263, 'NeuralNetFastAI_BAG_L1': 26.055803775787354, 'XGBoost_BAG_L1': 22.375359535217285, 'NeuralNetTorch_BAG_L1': 30.047072410583496, 'LightGBMLarge_BAG_L1': 105.16084861755371, 'WeightedEnsemble_L2': 0.4302210807800293, 'LightGBMXT_BAG_L2': 8.467344522476196, 'LightGBM_BAG_L2': 8.350305557250977, 'RandomForestMSE_BAG_L2': 8.962986946105957, 'CatBoost_BAG_L2': 206.05751538276672, 'ExtraTreesMSE_BAG_L2': 8.070977449417114, 'NeuralNetFastAI_BAG_L2': 16.944083213806152, 'XGBoost_BAG_L2': 19.61538076400757, 'NeuralNetTorch_BAG_L2': 21.47044086456299, 'LightGBMLarge_BAG_L2': 115.46094131469727, 'WeightedEnsemble_L3': 0.39726853370666504, 'LightGBMXT_BAG_L3': 18.926946878433228, 'LightGBM_BAG_L3': 15.153840065002441, 'RandomForestMSE_BAG_L3': 8.39902114868164, 'CatBoost_BAG_L3': 2914.201301574707, 'ExtraTreesMSE_BAG_L3': 11.413996458053589, 'NeuralNetFastAI_BAG_L3': 28.884472846984863, 'XGBoost_BAG_L3': 49.22258925437927, 'NeuralNetTorch_BAG_L3': 56.72992920875549, 'LightGBMLarge_BAG_L3': 60.857064723968506, 'WeightedEnsemble_L4': 0.48331260681152344, 'LightGBMXT_BAG_L4': 29.184185028076172, 'LightGBM_BAG_L4': 12.664915561676025, 'RandomForestMSE_BAG_L4': 9.518903017044067, 'CatBoost_BAG_L4': 370.51889204978943, 'ExtraTreesMSE_BAG_L4': 14.465036869049072, 'NeuralNetFastAI_BAG_L4': 33.563693046569824, 'XGBoost_BAG_L4': 47.45988368988037, 'NeuralNetTorch_BAG_L4': 43.64432907104492, 'LightGBMLarge_BAG_L4': 89.9788281917572, 'WeightedEnsemble_L5': 0.5382766723632812}, 'model_pred_times': {'LightGBMXT_BAG_L1': 1.268272876739502, 'LightGBM_BAG_L1': 1.034038782119751, 'RandomForestMSE_BAG_L1': 1.7965433597564697, 'CatBoost_BAG_L1': 10.402237892150879, 'ExtraTreesMSE_BAG_L1': 0.8294134140014648, 'NeuralNetFastAI_BAG_L1': 0.8431911468505859, 'XGBoost_BAG_L1': 0.41922545433044434, 'NeuralNetTorch_BAG_L1': 0.7013969421386719, 'LightGBMLarge_BAG_L1': 0.9267532825469971, 'WeightedEnsemble_L2': 0.000946044921875, 'LightGBMXT_BAG_L2': 0.759009599685669, 'LightGBM_BAG_L2': 0.7536196708679199, 'RandomForestMSE_BAG_L2': 0.8585805892944336, 'CatBoost_BAG_L2': 8.79645586013794, 'ExtraTreesMSE_BAG_L2': 0.8294944763183594, 'NeuralNetFastAI_BAG_L2': 0.8345346450805664, 'XGBoost_BAG_L2': 0.48494935035705566, 'NeuralNetTorch_BAG_L2': 0.8571276664733887, 'LightGBMLarge_BAG_L2': 0.8897848129272461, 'WeightedEnsemble_L3': 0.0005862712860107422, 'LightGBMXT_BAG_L3': 0.7910728454589844, 'LightGBM_BAG_L3': 0.7007865905761719, 'RandomForestMSE_BAG_L3': 0.7368466854095459, 'CatBoost_BAG_L3': 9.543994188308716, 'ExtraTreesMSE_BAG_L3': 1.2283554077148438, 'NeuralNetFastAI_BAG_L3': 1.127655267715454, 'XGBoost_BAG_L3': 1.1062979698181152, 'NeuralNetTorch_BAG_L3': 1.5836679935455322, 'LightGBMLarge_BAG_L3': 1.3683702945709229, 'WeightedEnsemble_L4': 0.0010859966278076172, 'LightGBMXT_BAG_L4': 1.0095546245574951, 'LightGBM_BAG_L4': 0.863915205001831, 'RandomForestMSE_BAG_L4': 1.1593506336212158, 'CatBoost_BAG_L4': 10.124781131744385, 'ExtraTreesMSE_BAG_L4': 1.825688123703003, 'NeuralNetFastAI_BAG_L4': 0.9446179866790771, 'XGBoost_BAG_L4': 0.8600633144378662, 'NeuralNetTorch_BAG_L4': 1.3662986755371094, 'LightGBMLarge_BAG_L4': 1.0676624774932861, 'WeightedEnsemble_L5': 0.0008895397186279297}, 'num_bag_folds': 5, 'max_stack_level': 5, 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L3': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L4': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L5': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                      model  score_val  pred_time_val     fit_time  \\\n",
      "0      WeightedEnsemble_L5  -0.042904      54.647398  7045.368813   \n",
      "1      WeightedEnsemble_L4  -0.042968      36.697826  3892.419991   \n",
      "2      WeightedEnsemble_L3  -0.043733      19.913322  3416.580253   \n",
      "3          LightGBM_BAG_L3  -0.043768      33.985416  3806.322276   \n",
      "4          LightGBM_BAG_L4  -0.043889      52.335592  6967.622514   \n",
      "5      WeightedEnsemble_L2  -0.043978       2.813807    80.697425   \n",
      "6    NeuralNetTorch_BAG_L4  -0.044054      52.837976  6998.601927   \n",
      "7    NeuralNetTorch_BAG_L3  -0.044062      34.868298  3847.898365   \n",
      "8   NeuralNetFastAI_BAG_L4  -0.044134      52.416295  6988.521291   \n",
      "9    NeuralNetTorch_BAG_L2  -0.044229      19.078201  3399.238901   \n",
      "10  NeuralNetFastAI_BAG_L3  -0.044324      34.412285  3820.052909   \n",
      "11  NeuralNetFastAI_BAG_L2  -0.044740      19.055608  3394.712543   \n",
      "12   NeuralNetTorch_BAG_L1  -0.044980       0.701397    30.047072   \n",
      "13          XGBoost_BAG_L4  -0.045006      52.331740  7002.417482   \n",
      "14       LightGBMXT_BAG_L3  -0.045042      34.075703  3810.095383   \n",
      "15         CatBoost_BAG_L4  -0.045213      61.596458  7325.476490   \n",
      "16    LightGBMLarge_BAG_L4  -0.045324      52.539340  7044.936426   \n",
      "17  RandomForestMSE_BAG_L3  -0.045387      34.021477  3799.567457   \n",
      "18          XGBoost_BAG_L3  -0.045575      34.390928  3840.391025   \n",
      "19    LightGBMLarge_BAG_L3  -0.045581      34.653000  3852.025501   \n",
      "20         CatBoost_BAG_L1  -0.045616      10.402238  3131.726905   \n",
      "21       LightGBMXT_BAG_L4  -0.045630      52.481232  6984.141783   \n",
      "22  NeuralNetFastAI_BAG_L1  -0.045729       0.843191    26.055804   \n",
      "23         CatBoost_BAG_L3  -0.045799      42.828624  6705.369738   \n",
      "24    ExtraTreesMSE_BAG_L3  -0.045879      34.512985  3802.582433   \n",
      "25  RandomForestMSE_BAG_L4  -0.045915      52.631028  6964.476501   \n",
      "26         CatBoost_BAG_L2  -0.045941      27.017529  3583.825975   \n",
      "27    ExtraTreesMSE_BAG_L4  -0.046158      53.297365  6969.422635   \n",
      "28       LightGBMXT_BAG_L1  -0.046238       1.268273    24.164328   \n",
      "29         LightGBM_BAG_L1  -0.046238       1.034039    15.751665   \n",
      "30  RandomForestMSE_BAG_L2  -0.046242      19.079654  3386.731447   \n",
      "31       LightGBMXT_BAG_L2  -0.046264      18.980083  3386.235805   \n",
      "32    ExtraTreesMSE_BAG_L2  -0.046292      19.050568  3385.839437   \n",
      "33         LightGBM_BAG_L2  -0.046686      18.974693  3386.118766   \n",
      "34    LightGBMLarge_BAG_L2  -0.046968      19.110858  3493.229401   \n",
      "35          XGBoost_BAG_L2  -0.047209      18.706023  3397.383841   \n",
      "36          XGBoost_BAG_L1  -0.048111       0.419225    22.375360   \n",
      "37    ExtraTreesMSE_BAG_L1  -0.048342       0.829413     9.478027   \n",
      "38  RandomForestMSE_BAG_L1  -0.048498       1.796543    13.008452   \n",
      "39    LightGBMLarge_BAG_L1  -0.048853       0.926753   105.160849   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000890           0.538277            5       True   \n",
      "1                 0.001086           0.483313            4       True   \n",
      "2                 0.000586           0.397269            3       True   \n",
      "3                 0.700787          15.153840            3       True   \n",
      "4                 0.863915          12.664916            4       True   \n",
      "5                 0.000946           0.430221            2       True   \n",
      "6                 1.366299          43.644329            4       True   \n",
      "7                 1.583668          56.729929            3       True   \n",
      "8                 0.944618          33.563693            4       True   \n",
      "9                 0.857128          21.470441            2       True   \n",
      "10                1.127655          28.884473            3       True   \n",
      "11                0.834535          16.944083            2       True   \n",
      "12                0.701397          30.047072            1       True   \n",
      "13                0.860063          47.459884            4       True   \n",
      "14                0.791073          18.926947            3       True   \n",
      "15               10.124781         370.518892            4       True   \n",
      "16                1.067662          89.978828            4       True   \n",
      "17                0.736847           8.399021            3       True   \n",
      "18                1.106298          49.222589            3       True   \n",
      "19                1.368370          60.857065            3       True   \n",
      "20               10.402238        3131.726905            1       True   \n",
      "21                1.009555          29.184185            4       True   \n",
      "22                0.843191          26.055804            1       True   \n",
      "23                9.543994        2914.201302            3       True   \n",
      "24                1.228355          11.413996            3       True   \n",
      "25                1.159351           9.518903            4       True   \n",
      "26                8.796456         206.057515            2       True   \n",
      "27                1.825688          14.465037            4       True   \n",
      "28                1.268273          24.164328            1       True   \n",
      "29                1.034039          15.751665            1       True   \n",
      "30                0.858581           8.962987            2       True   \n",
      "31                0.759010           8.467345            2       True   \n",
      "32                0.829494           8.070977            2       True   \n",
      "33                0.753620           8.350306            2       True   \n",
      "34                0.889785         115.460941            2       True   \n",
      "35                0.484949          19.615381            2       True   \n",
      "36                0.419225          22.375360            1       True   \n",
      "37                0.829413           9.478027            1       True   \n",
      "38                1.796543          13.008452            1       True   \n",
      "39                0.926753         105.160849            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          40  \n",
      "1          30  \n",
      "2          20  \n",
      "3          22  \n",
      "4          32  \n",
      "5          10  \n",
      "6          38  \n",
      "7          28  \n",
      "8          36  \n",
      "9          18  \n",
      "10         26  \n",
      "11         16  \n",
      "12          8  \n",
      "13         37  \n",
      "14         21  \n",
      "15         34  \n",
      "16         39  \n",
      "17         23  \n",
      "18         27  \n",
      "19         29  \n",
      "20          4  \n",
      "21         31  \n",
      "22          6  \n",
      "23         24  \n",
      "24         25  \n",
      "25         33  \n",
      "26         14  \n",
      "27         35  \n",
      "28          1  \n",
      "29          2  \n",
      "30         13  \n",
      "31         11  \n",
      "32         15  \n",
      "33         12  \n",
      "34         19  \n",
      "35         17  \n",
      "36          7  \n",
      "37          5  \n",
      "38          3  \n",
      "39          9  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate_autogluon/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': -0.04461926346645121, 'LightGBM_BAG_L1': -0.044619264183224004, 'RandomForestMSE_BAG_L1': -0.04549634266064906, 'CatBoost_BAG_L1': -0.04481192136242399, 'ExtraTreesMSE_BAG_L1': -0.04530325950895612, 'NeuralNetFastAI_BAG_L1': -0.047297151883562524, 'XGBoost_BAG_L1': -0.04437392978970303, 'NeuralNetTorch_BAG_L1': -0.04583863075797269, 'LightGBMLarge_BAG_L1': -0.04543846003417272, 'WeightedEnsemble_L2': -0.04494974424956646, 'LightGBMXT_BAG_L2': -0.04451270731132004, 'LightGBM_BAG_L2': -0.0439771457053058, 'RandomForestMSE_BAG_L2': -0.04424650053214454, 'CatBoost_BAG_L2': -0.04461014033026421, 'ExtraTreesMSE_BAG_L2': -0.04418252219417125, 'NeuralNetFastAI_BAG_L2': -0.04752228276089883, 'XGBoost_BAG_L2': -0.044494152352365, 'NeuralNetTorch_BAG_L2': -0.045740461316651056, 'LightGBMLarge_BAG_L2': -0.04511516427845549, 'WeightedEnsemble_L3': -0.0460834872059585, 'LightGBMXT_BAG_L3': -0.044663901453213674, 'LightGBM_BAG_L3': -0.04634440760137257, 'RandomForestMSE_BAG_L3': -0.04737230288646983, 'CatBoost_BAG_L3': -0.04428338491150672, 'ExtraTreesMSE_BAG_L3': -0.04480086911128973, 'NeuralNetFastAI_BAG_L3': -0.04779510396845262, 'XGBoost_BAG_L3': -0.04713248653215628, 'NeuralNetTorch_BAG_L3': -0.04574581711749286, 'LightGBMLarge_BAG_L3': -0.046935476765585696, 'WeightedEnsemble_L4': -0.046146662637171494, 'LightGBMXT_BAG_L4': -0.04512358593940756, 'LightGBM_BAG_L4': -0.04547384496856804, 'RandomForestMSE_BAG_L4': -0.047531256373387086, 'CatBoost_BAG_L4': -0.045631131153517517, 'ExtraTreesMSE_BAG_L4': -0.04611599566475468, 'NeuralNetFastAI_BAG_L4': -0.04758220050696563, 'XGBoost_BAG_L4': -0.04672085701164455, 'NeuralNetTorch_BAG_L4': -0.046047464330010224, 'LightGBMLarge_BAG_L4': -0.047192275699745365, 'WeightedEnsemble_L5': -0.045845797954722774}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_test  score_val  pred_time_test  \\\n",
      "0          LightGBM_BAG_L2   -0.043977  -0.046686       22.070255   \n",
      "1     ExtraTreesMSE_BAG_L2   -0.044183  -0.046292       18.847863   \n",
      "2   RandomForestMSE_BAG_L2   -0.044247  -0.046242       18.847174   \n",
      "3          CatBoost_BAG_L3   -0.044283  -0.045799       53.146310   \n",
      "4           XGBoost_BAG_L1   -0.044374  -0.048111        0.628648   \n",
      "5           XGBoost_BAG_L2   -0.044494  -0.047209       19.987348   \n",
      "6        LightGBMXT_BAG_L2   -0.044513  -0.046264       22.168594   \n",
      "7          CatBoost_BAG_L2   -0.044610  -0.045941       29.163202   \n",
      "8        LightGBMXT_BAG_L1   -0.044619  -0.046238        2.762116   \n",
      "9          LightGBM_BAG_L1   -0.044619  -0.046238        2.634249   \n",
      "10       LightGBMXT_BAG_L3   -0.044664  -0.045042       47.787476   \n",
      "11    ExtraTreesMSE_BAG_L3   -0.044801  -0.045879       44.973989   \n",
      "12         CatBoost_BAG_L1   -0.044812  -0.045616        7.918647   \n",
      "13     WeightedEnsemble_L2   -0.044950  -0.043978        4.543429   \n",
      "14    LightGBMLarge_BAG_L2   -0.045115  -0.046968       21.998228   \n",
      "15       LightGBMXT_BAG_L4   -0.045124  -0.045630       67.664462   \n",
      "16    ExtraTreesMSE_BAG_L1   -0.045303  -0.048342        0.133967   \n",
      "17    LightGBMLarge_BAG_L1   -0.045438  -0.048853        2.764925   \n",
      "18         LightGBM_BAG_L4   -0.045474  -0.043889       67.344732   \n",
      "19  RandomForestMSE_BAG_L1   -0.045496  -0.048498        0.128811   \n",
      "20         CatBoost_BAG_L4   -0.045631  -0.045213       72.860834   \n",
      "21   NeuralNetTorch_BAG_L2   -0.045740  -0.044229       21.181261   \n",
      "22   NeuralNetTorch_BAG_L3   -0.045746  -0.044062       45.999002   \n",
      "23   NeuralNetTorch_BAG_L1   -0.045839  -0.044980        0.844558   \n",
      "24     WeightedEnsemble_L5   -0.045846  -0.042904       69.280585   \n",
      "25   NeuralNetTorch_BAG_L4   -0.046047  -0.044054       65.822468   \n",
      "26     WeightedEnsemble_L3   -0.046083  -0.043733       22.994388   \n",
      "27    ExtraTreesMSE_BAG_L4   -0.046116  -0.046158       64.970723   \n",
      "28     WeightedEnsemble_L4   -0.046147  -0.042968       49.915220   \n",
      "29         LightGBM_BAG_L3   -0.046344  -0.043768       47.701720   \n",
      "30          XGBoost_BAG_L4   -0.046721  -0.045006       65.489051   \n",
      "31    LightGBMLarge_BAG_L3   -0.046935  -0.045581       47.542408   \n",
      "32          XGBoost_BAG_L3   -0.047132  -0.045575       45.583830   \n",
      "33    LightGBMLarge_BAG_L4   -0.047192  -0.045324       67.449380   \n",
      "34  NeuralNetFastAI_BAG_L1   -0.047297  -0.045729        0.930553   \n",
      "35  RandomForestMSE_BAG_L3   -0.047372  -0.045387       44.967839   \n",
      "36  NeuralNetFastAI_BAG_L2   -0.047522  -0.044740       20.553044   \n",
      "37  RandomForestMSE_BAG_L4   -0.047531  -0.045915       64.986288   \n",
      "38  NeuralNetFastAI_BAG_L4   -0.047582  -0.044134       65.777784   \n",
      "39  NeuralNetFastAI_BAG_L3   -0.047795  -0.044324       45.896212   \n",
      "\n",
      "    pred_time_val     fit_time  pred_time_test_marginal  \\\n",
      "0       18.974693  3386.118766                 3.323781   \n",
      "1       19.050568  3385.839437                 0.101389   \n",
      "2       19.079654  3386.731447                 0.100700   \n",
      "3       42.828624  6705.369738                 8.301134   \n",
      "4        0.419225    22.375360                 0.628648   \n",
      "5       18.706023  3397.383841                 1.240874   \n",
      "6       18.980083  3386.235805                 3.422120   \n",
      "7       27.017529  3583.825975                10.416728   \n",
      "8        1.268273    24.164328                 2.762116   \n",
      "9        1.034039    15.751665                 2.634249   \n",
      "10      34.075703  3810.095383                 2.942300   \n",
      "11      34.512985  3802.582433                 0.128813   \n",
      "12      10.402238  3131.726905                 7.918647   \n",
      "13       2.813807    80.697425                 0.006202   \n",
      "14      19.110858  3493.229401                 3.251754   \n",
      "15      52.481232  6984.141783                 2.827085   \n",
      "16       0.829413     9.478027                 0.133967   \n",
      "17       0.926753   105.160849                 2.764925   \n",
      "18      52.335592  6967.622514                 2.507355   \n",
      "19       1.796543    13.008452                 0.128811   \n",
      "20      61.596458  7325.476490                 8.023458   \n",
      "21      19.078201  3399.238901                 2.434787   \n",
      "22      34.868298  3847.898365                 1.153826   \n",
      "23       0.701397    30.047072                 0.844558   \n",
      "24      54.647398  7045.368813                 0.010355   \n",
      "25      52.837976  6998.601927                 0.985091   \n",
      "26      19.913322  3416.580253                 0.006557   \n",
      "27      53.297365  6969.422635                 0.133347   \n",
      "28      36.697826  3892.419991                 0.008638   \n",
      "29      33.985416  3806.322276                 2.856544   \n",
      "30      52.331740  7002.417482                 0.651675   \n",
      "31      34.653000  3852.025501                 2.697231   \n",
      "32      34.390928  3840.391025                 0.738654   \n",
      "33      52.539340  7044.936426                 2.612003   \n",
      "34       0.843191    26.055804                 0.930553   \n",
      "35      34.021477  3799.567457                 0.122663   \n",
      "36      19.055608  3394.712543                 1.806570   \n",
      "37      52.631028  6964.476501                 0.148911   \n",
      "38      52.416295  6988.521291                 0.940407   \n",
      "39      34.412285  3820.052909                 1.051036   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.753620           8.350306            2       True   \n",
      "1                 0.829494           8.070977            2       True   \n",
      "2                 0.858581           8.962987            2       True   \n",
      "3                 9.543994        2914.201302            3       True   \n",
      "4                 0.419225          22.375360            1       True   \n",
      "5                 0.484949          19.615381            2       True   \n",
      "6                 0.759010           8.467345            2       True   \n",
      "7                 8.796456         206.057515            2       True   \n",
      "8                 1.268273          24.164328            1       True   \n",
      "9                 1.034039          15.751665            1       True   \n",
      "10                0.791073          18.926947            3       True   \n",
      "11                1.228355          11.413996            3       True   \n",
      "12               10.402238        3131.726905            1       True   \n",
      "13                0.000946           0.430221            2       True   \n",
      "14                0.889785         115.460941            2       True   \n",
      "15                1.009555          29.184185            4       True   \n",
      "16                0.829413           9.478027            1       True   \n",
      "17                0.926753         105.160849            1       True   \n",
      "18                0.863915          12.664916            4       True   \n",
      "19                1.796543          13.008452            1       True   \n",
      "20               10.124781         370.518892            4       True   \n",
      "21                0.857128          21.470441            2       True   \n",
      "22                1.583668          56.729929            3       True   \n",
      "23                0.701397          30.047072            1       True   \n",
      "24                0.000890           0.538277            5       True   \n",
      "25                1.366299          43.644329            4       True   \n",
      "26                0.000586           0.397269            3       True   \n",
      "27                1.825688          14.465037            4       True   \n",
      "28                0.001086           0.483313            4       True   \n",
      "29                0.700787          15.153840            3       True   \n",
      "30                0.860063          47.459884            4       True   \n",
      "31                1.368370          60.857065            3       True   \n",
      "32                1.106298          49.222589            3       True   \n",
      "33                1.067662          89.978828            4       True   \n",
      "34                0.843191          26.055804            1       True   \n",
      "35                0.736847           8.399021            3       True   \n",
      "36                0.834535          16.944083            2       True   \n",
      "37                1.159351           9.518903            4       True   \n",
      "38                0.944618          33.563693            4       True   \n",
      "39                1.127655          28.884473            3       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1          15  \n",
      "2          13  \n",
      "3          24  \n",
      "4           7  \n",
      "5          17  \n",
      "6          11  \n",
      "7          14  \n",
      "8           1  \n",
      "9           2  \n",
      "10         21  \n",
      "11         25  \n",
      "12          4  \n",
      "13         10  \n",
      "14         19  \n",
      "15         31  \n",
      "16          5  \n",
      "17          9  \n",
      "18         32  \n",
      "19          3  \n",
      "20         34  \n",
      "21         18  \n",
      "22         28  \n",
      "23          8  \n",
      "24         40  \n",
      "25         38  \n",
      "26         20  \n",
      "27         35  \n",
      "28         30  \n",
      "29         22  \n",
      "30         37  \n",
      "31         29  \n",
      "32         27  \n",
      "33         39  \n",
      "34          6  \n",
      "35         23  \n",
      "36         16  \n",
      "37         33  \n",
      "38         36  \n",
      "39         26  \n"
     ]
    }
   ],
   "source": [
    "# %%capture log_output\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# %config Application.log_level = 'DEBUG'\n",
    "# %config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "# with open('./output_5040.log', 'w') as f:\n",
    "#     f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedEnsemble_L5\n"
     ]
    }
   ],
   "source": [
    "best_model = predictor.get_model_best()\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-10240_sdf/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model=best_model)\n",
    "test_data_pred = predictor.predict(test_data, model=best_model)\n",
    "\n",
    "import numpy as np\n",
    "#save np array y_train_hat to a csv file\n",
    "np.savetxt('./10240_vectors_y_test_hat_sdf.csv', test_data_pred, delimiter=',')\n",
    "np.savetxt('./10240_vectors_y_train_hat_sdf.csv', train_data_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
