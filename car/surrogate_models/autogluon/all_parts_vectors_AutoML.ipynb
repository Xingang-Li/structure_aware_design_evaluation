{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../spvae_vectors_drags.csv | Columns = 131 / 131 | Rows = 439 -> 439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_120</th>\n",
       "      <th>dim_121</th>\n",
       "      <th>dim_122</th>\n",
       "      <th>dim_123</th>\n",
       "      <th>dim_124</th>\n",
       "      <th>dim_125</th>\n",
       "      <th>dim_126</th>\n",
       "      <th>dim_127</th>\n",
       "      <th>dim_128</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.996583</td>\n",
       "      <td>0.253377</td>\n",
       "      <td>2.345441</td>\n",
       "      <td>-0.989086</td>\n",
       "      <td>-2.179726</td>\n",
       "      <td>4.450816</td>\n",
       "      <td>-0.333054</td>\n",
       "      <td>-0.833110</td>\n",
       "      <td>0.170525</td>\n",
       "      <td>0.681121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321793</td>\n",
       "      <td>-0.977492</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>-2.447803</td>\n",
       "      <td>-0.851386</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.704168</td>\n",
       "      <td>0.301570</td>\n",
       "      <td>0.179546</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.107085</td>\n",
       "      <td>1.786517</td>\n",
       "      <td>1.586284</td>\n",
       "      <td>-1.288352</td>\n",
       "      <td>-1.469519</td>\n",
       "      <td>1.856284</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.707441</td>\n",
       "      <td>0.195338</td>\n",
       "      <td>0.934119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>-1.589034</td>\n",
       "      <td>-3.525021</td>\n",
       "      <td>-4.223967</td>\n",
       "      <td>-2.653476</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.977202</td>\n",
       "      <td>-0.662360</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-3.295154</td>\n",
       "      <td>-1.133777</td>\n",
       "      <td>-0.713116</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.565126</td>\n",
       "      <td>-1.224105</td>\n",
       "      <td>-0.519147</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>...</td>\n",
       "      <td>2.272549</td>\n",
       "      <td>-0.996835</td>\n",
       "      <td>5.970934</td>\n",
       "      <td>0.562599</td>\n",
       "      <td>3.063003</td>\n",
       "      <td>-0.003317</td>\n",
       "      <td>1.284646</td>\n",
       "      <td>-0.388674</td>\n",
       "      <td>0.367492</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-0.809618</td>\n",
       "      <td>-1.043127</td>\n",
       "      <td>0.594460</td>\n",
       "      <td>1.935878</td>\n",
       "      <td>0.173827</td>\n",
       "      <td>1.941216</td>\n",
       "      <td>-0.689809</td>\n",
       "      <td>-1.535557</td>\n",
       "      <td>1.745006</td>\n",
       "      <td>0.349334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602183</td>\n",
       "      <td>-0.519529</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>1.788710</td>\n",
       "      <td>-0.448435</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.998566</td>\n",
       "      <td>-0.302207</td>\n",
       "      <td>0.684875</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.572277</td>\n",
       "      <td>-0.328782</td>\n",
       "      <td>0.444743</td>\n",
       "      <td>0.411545</td>\n",
       "      <td>-1.628947</td>\n",
       "      <td>3.242414</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-0.790840</td>\n",
       "      <td>0.288297</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>...</td>\n",
       "      <td>2.103731</td>\n",
       "      <td>-2.167353</td>\n",
       "      <td>-1.278066</td>\n",
       "      <td>-1.638192</td>\n",
       "      <td>2.981116</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>-0.616031</td>\n",
       "      <td>-0.505367</td>\n",
       "      <td>0.432376</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "61  -0.996583  0.253377  2.345441 -0.989086 -2.179726  4.450816 -0.333054   \n",
       "354 -0.107085  1.786517  1.586284 -1.288352 -1.469519  1.856284  0.022899   \n",
       "358 -3.295154 -1.133777 -0.713116  0.946432  0.027521  0.023506  0.565126   \n",
       "275 -0.809618 -1.043127  0.594460  1.935878  0.173827  1.941216 -0.689809   \n",
       "18  -0.572277 -0.328782  0.444743  0.411545 -1.628947  3.242414 -0.008619   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_120   dim_121   dim_122  \\\n",
       "61  -0.833110  0.170525  0.681121  ...  1.321793 -0.977492  0.493258   \n",
       "354  0.707441  0.195338  0.934119  ...  0.785785 -1.589034 -3.525021   \n",
       "358 -1.224105 -0.519147  0.146645  ...  2.272549 -0.996835  5.970934   \n",
       "275 -1.535557  1.745006  0.349334  ...  0.602183 -0.519529  0.047703   \n",
       "18  -0.790840  0.288297  0.432827  ...  2.103731 -2.167353 -1.278066   \n",
       "\n",
       "      dim_123   dim_124   dim_125   dim_126   dim_127   dim_128   drag  \n",
       "61  -2.447803 -0.851386  0.003659 -0.704168  0.301570  0.179546  0.375  \n",
       "354 -4.223967 -2.653476  0.012422  0.597222  0.977202 -0.662360  0.374  \n",
       "358  0.562599  3.063003 -0.003317  1.284646 -0.388674  0.367492  0.435  \n",
       "275  1.788710 -0.448435 -0.003273 -0.998566 -0.302207  0.684875  0.437  \n",
       "18  -1.638192  2.981116  0.002460 -0.616031 -0.505367  0.432376  0.367  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = '../all_parts_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 , 0.375\n",
      "354 , 0.374\n",
      "358 , 0.435\n",
      "275 , 0.437\n",
      "18 , 0.367\n",
      "107 , 0.36\n",
      "57 , 0.456\n",
      "430 , 0.386\n",
      "374 , 0.345\n",
      "179 , 0.345\n",
      "287 , 0.341\n",
      "51 , 0.55\n",
      "395 , 0.48\n",
      "133 , 0.371\n",
      "233 , 0.427\n",
      "210 , 0.478\n",
      "151 , 0.294\n",
      "375 , 0.411\n",
      "24 , 0.538\n",
      "311 , 0.356\n",
      "152 , 0.429\n",
      "369 , 0.478\n",
      "8 , 0.317\n",
      "90 , 0.439\n",
      "47 , 0.418\n",
      "305 , 0.423\n",
      "421 , 0.377\n",
      "253 , 0.418\n",
      "167 , 0.322\n",
      "315 , 0.355\n",
      "345 , 0.489\n",
      "366 , 0.42\n",
      "41 , 0.51\n",
      "359 , 0.453\n",
      "269 , 0.362\n",
      "56 , 0.375\n",
      "193 , 0.408\n",
      "283 , 0.513\n",
      "204 , 0.315\n",
      "224 , 0.333\n",
      "316 , 0.571\n",
      "19 , 0.375\n",
      "150 , 0.33\n",
      "118 , 0.298\n",
      "58 , 0.341\n",
      "223 , 0.359\n",
      "1 , 0.393\n",
      "226 , 0.403\n",
      "124 , 0.339\n",
      "232 , 0.404\n",
      "278 , 0.404\n",
      "342 , 0.344\n",
      "26 , 0.4\n",
      "390 , 0.326\n",
      "379 , 0.417\n",
      "81 , 0.384\n",
      "236 , 0.432\n",
      "100 , 0.374\n",
      "383 , 0.315\n",
      "148 , 0.334\n",
      "3 , 0.337\n",
      "371 , 0.329\n",
      "123 , 0.446\n",
      "231 , 0.348\n",
      "248 , 0.37\n",
      "39 , 0.379\n",
      "120 , 0.439\n",
      "273 , 0.317\n",
      "29 , 0.436\n",
      "378 , 0.371\n",
      "352 , 0.429\n",
      "154 , 0.362\n",
      "407 , 0.347\n",
      "131 , 0.357\n",
      "261 , 0.387\n",
      "262 , 0.402\n",
      "382 , 0.468\n",
      "10 , 0.425\n",
      "88 , 0.402\n",
      "372 , 0.445\n",
      "73 , 0.417\n",
      "234 , 0.516\n",
      "106 , 0.307\n",
      "213 , 0.334\n",
      "364 , 0.356\n",
      "206 , 0.434\n",
      "33 , 0.38\n",
      "437 , 0.456\n",
      "353 , 0.392\n",
      "176 , 0.397\n",
      "337 , 0.336\n",
      "399 , 0.304\n",
      "335 , 0.469\n",
      "140 , 0.349\n",
      "256 , 0.427\n",
      "250 , 0.344\n",
      "419 , 0.373\n",
      "98 , 0.335\n",
      "373 , 0.516\n",
      "93 , 0.335\n",
      "208 , 0.423\n",
      "149 , 0.431\n",
      "70 , 0.358\n",
      "336 , 0.416\n",
      "13 , 0.435\n",
      "293 , 0.322\n",
      "327 , 0.315\n",
      "212 , 0.441\n",
      "319 , 0.404\n",
      "289 , 0.518\n",
      "119 , 0.294\n",
      "76 , 0.418\n",
      "158 , 0.355\n",
      "320 , 0.407\n",
      "191 , 0.431\n",
      "155 , 0.384\n",
      "414 , 0.324\n",
      "240 , 0.341\n",
      "67 , 0.547\n",
      "22 , 0.357\n",
      "367 , 0.408\n",
      "246 , 0.42\n",
      "160 , 0.374\n",
      "194 , 0.425\n",
      "332 , 0.454\n",
      "249 , 0.332\n",
      "143 , 0.456\n",
      "393 , 0.49\n",
      "132 , 0.366\n",
      "15 , 0.327\n",
      "137 , 0.372\n",
      "96 , 0.465\n",
      "308 , 0.322\n",
      "201 , 0.387\n",
      "209 , 0.459\n",
      "296 , 0.437\n",
      "285 , 0.388\n",
      "156 , 0.479\n",
      "114 , 0.367\n",
      "135 , 0.337\n",
      "141 , 0.441\n",
      "279 , 0.415\n",
      "329 , 0.381\n",
      "306 , 0.364\n",
      "424 , 0.402\n",
      "267 , 0.377\n",
      "403 , 0.4\n",
      "284 , 0.397\n",
      "218 , 0.474\n",
      "159 , 0.339\n",
      "247 , 0.441\n",
      "391 , 0.453\n",
      "389 , 0.509\n",
      "270 , 0.472\n",
      "207 , 0.394\n",
      "122 , 0.35\n",
      "377 , 0.387\n",
      "310 , 0.452\n",
      "434 , 0.432\n",
      "301 , 0.365\n",
      "69 , 0.477\n",
      "230 , 0.348\n",
      "121 , 0.44\n",
      "68 , 0.411\n",
      "129 , 0.338\n",
      "197 , 0.334\n",
      "111 , 0.433\n",
      "258 , 0.441\n",
      "84 , 0.306\n",
      "219 , 0.417\n",
      "216 , 0.358\n",
      "214 , 0.403\n",
      "268 , 0.407\n",
      "139 , 0.399\n",
      "386 , 0.409\n",
      "45 , 0.449\n",
      "405 , 0.478\n",
      "163 , 0.382\n",
      "105 , 0.428\n",
      "344 , 0.437\n",
      "11 , 0.429\n",
      "43 , 0.333\n",
      "82 , 0.393\n",
      "350 , 0.38\n",
      "396 , 0.403\n",
      "102 , 0.349\n",
      "220 , 0.458\n",
      "274 , 0.337\n",
      "27 , 0.46\n",
      "299 , 0.366\n",
      "66 , 0.47\n",
      "112 , 0.347\n",
      "211 , 0.375\n",
      "370 , 0.547\n",
      "35 , 0.503\n",
      "333 , 0.436\n",
      "266 , 0.415\n",
      "180 , 0.47\n",
      "254 , 0.323\n",
      "291 , 0.456\n",
      "40 , 0.387\n",
      "2 , 0.404\n",
      "244 , 0.357\n",
      "64 , 0.327\n",
      "313 , 0.445\n",
      "14 , 0.335\n",
      "94 , 0.393\n",
      "410 , 0.422\n",
      "404 , 0.414\n",
      "83 , 0.385\n",
      "288 , 0.522\n",
      "259 , 0.373\n",
      "162 , 0.355\n",
      "203 , 0.419\n",
      "113 , 0.355\n",
      "205 , 0.345\n",
      "431 , 0.373\n",
      "385 , 0.418\n",
      "42 , 0.427\n",
      "380 , 0.421\n",
      "387 , 0.361\n",
      "104 , 0.318\n",
      "317 , 0.497\n",
      "298 , 0.407\n",
      "294 , 0.483\n",
      "348 , 0.288\n",
      "394 , 0.333\n",
      "227 , 0.393\n",
      "198 , 0.363\n",
      "435 , 0.319\n",
      "126 , 0.403\n",
      "331 , 0.321\n",
      "363 , 0.417\n",
      "164 , 0.384\n",
      "251 , 0.336\n",
      "181 , 0.339\n",
      "357 , 0.51\n",
      "49 , 0.357\n",
      "432 , 0.527\n",
      "346 , 0.358\n",
      "388 , 0.424\n",
      "425 , 0.393\n",
      "323 , 0.333\n",
      "20 , 0.4\n",
      "99 , 0.409\n",
      "413 , 0.364\n",
      "415 , 0.417\n",
      "199 , 0.427\n",
      "30 , 0.357\n",
      "297 , 0.387\n",
      "343 , 0.358\n",
      "62 , 0.375\n",
      "109 , 0.402\n",
      "91 , 0.399\n",
      "44 , 0.395\n",
      "23 , 0.472\n",
      "37 , 0.328\n",
      "314 , 0.451\n",
      "125 , 0.36\n",
      "235 , 0.341\n",
      "195 , 0.333\n",
      "34 , 0.363\n",
      "182 , 0.466\n",
      "95 , 0.321\n",
      "190 , 0.481\n",
      "85 , 0.377\n",
      "272 , 0.398\n",
      "108 , 0.495\n",
      "265 , 0.471\n",
      "264 , 0.375\n",
      "17 , 0.507\n",
      "429 , 0.478\n",
      "189 , 0.397\n",
      "427 , 0.318\n",
      "217 , 0.325\n",
      "183 , 0.431\n",
      "309 , 0.296\n",
      "0 , 0.32\n",
      "341 , 0.481\n",
      "392 , 0.382\n",
      "117 , 0.446\n",
      "356 , 0.313\n",
      "361 , 0.395\n",
      "80 , 0.394\n",
      "4 , 0.377\n",
      "330 , 0.34\n",
      "228 , 0.322\n",
      "138 , 0.494\n",
      "276 , 0.394\n",
      "225 , 0.53\n",
      "221 , 0.421\n",
      "229 , 0.368\n",
      "92 , 0.296\n",
      "245 , 0.338\n",
      "28 , 0.362\n",
      "78 , 0.435\n",
      "53 , 0.361\n",
      "38 , 0.598\n",
      "384 , 0.345\n",
      "171 , 0.428\n",
      "292 , 0.371\n",
      "115 , 0.334\n",
      "237 , 0.405\n",
      "355 , 0.335\n",
      "16 , 0.323\n",
      "130 , 0.415\n",
      "186 , 0.413\n",
      "307 , 0.36\n",
      "360 , 0.335\n",
      "128 , 0.444\n",
      "376 , 0.573\n",
      "271 , 0.541\n",
      "60 , 0.438\n",
      "202 , 0.381\n",
      "322 , 0.536\n",
      "326 , 0.433\n",
      "312 , 0.454\n",
      "324 , 0.424\n",
      "365 , 0.391\n",
      "318 , 0.395\n",
      "50 , 0.576\n",
      "418 , 0.367\n",
      "74 , 0.322\n",
      "438 , 0.351\n",
      "187 , 0.327\n",
      "31 , 0.461\n",
      "65 , 0.39\n",
      "263 , 0.409\n",
      "325 , 0.278\n",
      "340 , 0.378\n",
      "338 , 0.413\n",
      "321 , 0.299\n",
      "347 , 0.435\n",
      "32 , 0.484\n",
      "142 , 0.429\n",
      "397 , 0.468\n",
      "402 , 0.441\n",
      "295 , 0.482\n",
      "280 , 0.345\n",
      "302 , 0.367\n",
      "423 , 0.355\n",
      "116 , 0.388\n",
      "127 , 0.328\n",
      "157 , 0.417\n",
      "71 , 0.419\n",
      "433 , 0.503\n",
      "87 , 0.321\n",
      "422 , 0.437\n",
      "59 , 0.338\n",
      "303 , 0.385\n",
      "103 , 0.337\n"
     ]
    }
   ],
   "source": [
    "train_drags = train_df[\"drag\"]\n",
    "train_index = train_df[\"i\"]\n",
    "for index, drag in zip(train_index, train_drags):\n",
    "    print(index, \",\" ,drag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-spvae2\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 0,\n",
      " 'num_bag_sets': 0,\n",
      " 'num_stack_levels': 0,\n",
      " 'verbosity': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 2 µs, total: 42 µs\n",
      "Wall time: 83.4 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 0,\n",
      " 'num_bag_sets': 0,\n",
      " 'num_stack_levels': 0,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=0, num_bag_sets=0\n",
      "Saving ./agModels-spvae2/learner.pkl\n",
      "Saving ./agModels-spvae2/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-spvae2/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 128\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    259996.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-spvae2/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 280, Val Rows: 71\n",
      "Saving ./agModels-spvae2/utils/data/X.pkl\n",
      "Saving ./agModels-spvae2/utils/data/y.pkl\n",
      "Saving ./agModels-spvae2/utils/data/X_val.pkl\n",
      "Saving ./agModels-spvae2/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting KNeighborsUnif with 'num_gpus': 0, 'num_cpus': 32\n",
      "Saving ./agModels-spvae2/models/KNeighborsUnif/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/KNeighborsUnif/y_pred_proba_val.pkl\n",
      "\t-0.0558\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting KNeighborsDist with 'num_gpus': 0, 'num_cpus': 32\n",
      "Saving ./agModels-spvae2/models/KNeighborsDist/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/KNeighborsDist/y_pred_proba_val.pkl\n",
      "\t-0.0552\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: LightGBMXT ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBMXT with 'num_gpus': 0, 'num_cpus': 20\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's rmse: 0.0583063\n",
      "[2]\tvalid_set's rmse: 0.05801\n",
      "[3]\tvalid_set's rmse: 0.0576597\n",
      "[4]\tvalid_set's rmse: 0.0571314\n",
      "[5]\tvalid_set's rmse: 0.0569612\n",
      "[6]\tvalid_set's rmse: 0.0570144\n",
      "[7]\tvalid_set's rmse: 0.0567542\n",
      "[8]\tvalid_set's rmse: 0.0565622\n",
      "[9]\tvalid_set's rmse: 0.0562202\n",
      "[10]\tvalid_set's rmse: 0.0558066\n",
      "[11]\tvalid_set's rmse: 0.0556623\n",
      "[12]\tvalid_set's rmse: 0.0556173\n",
      "[13]\tvalid_set's rmse: 0.0553268\n",
      "[14]\tvalid_set's rmse: 0.0552455\n",
      "[15]\tvalid_set's rmse: 0.0550106\n",
      "[16]\tvalid_set's rmse: 0.0550851\n",
      "[17]\tvalid_set's rmse: 0.0551156\n",
      "[18]\tvalid_set's rmse: 0.0550753\n",
      "[19]\tvalid_set's rmse: 0.0549598\n",
      "[20]\tvalid_set's rmse: 0.0548997\n",
      "[21]\tvalid_set's rmse: 0.0546861\n",
      "[22]\tvalid_set's rmse: 0.0546323\n",
      "[23]\tvalid_set's rmse: 0.0544171\n",
      "[24]\tvalid_set's rmse: 0.0542238\n",
      "[25]\tvalid_set's rmse: 0.0541799\n",
      "[26]\tvalid_set's rmse: 0.0540439\n",
      "[27]\tvalid_set's rmse: 0.0540089\n",
      "[28]\tvalid_set's rmse: 0.0539085\n",
      "[29]\tvalid_set's rmse: 0.0539308\n",
      "[30]\tvalid_set's rmse: 0.0538693\n",
      "[31]\tvalid_set's rmse: 0.0539999\n",
      "[32]\tvalid_set's rmse: 0.0539942\n",
      "[33]\tvalid_set's rmse: 0.0539843\n",
      "[34]\tvalid_set's rmse: 0.0538809\n",
      "[35]\tvalid_set's rmse: 0.0539322\n",
      "[36]\tvalid_set's rmse: 0.0539145\n",
      "[37]\tvalid_set's rmse: 0.0538838\n",
      "[38]\tvalid_set's rmse: 0.0538245\n",
      "[39]\tvalid_set's rmse: 0.0538126\n",
      "[40]\tvalid_set's rmse: 0.0537652\n",
      "[41]\tvalid_set's rmse: 0.0536777\n",
      "[42]\tvalid_set's rmse: 0.0535744\n",
      "[43]\tvalid_set's rmse: 0.0536134\n",
      "[44]\tvalid_set's rmse: 0.0535367\n",
      "[45]\tvalid_set's rmse: 0.0534855\n",
      "[46]\tvalid_set's rmse: 0.0534945\n",
      "[47]\tvalid_set's rmse: 0.0535035\n",
      "[48]\tvalid_set's rmse: 0.0535099\n",
      "[49]\tvalid_set's rmse: 0.0533988\n",
      "[50]\tvalid_set's rmse: 0.0534221\n",
      "[51]\tvalid_set's rmse: 0.0534199\n",
      "[52]\tvalid_set's rmse: 0.0533633\n",
      "[53]\tvalid_set's rmse: 0.0533655\n",
      "[54]\tvalid_set's rmse: 0.0533041\n",
      "[55]\tvalid_set's rmse: 0.0532487\n",
      "[56]\tvalid_set's rmse: 0.0533249\n",
      "[57]\tvalid_set's rmse: 0.0533421\n",
      "[58]\tvalid_set's rmse: 0.0533113\n",
      "[59]\tvalid_set's rmse: 0.0532632\n",
      "[60]\tvalid_set's rmse: 0.0532208\n",
      "[61]\tvalid_set's rmse: 0.0531236\n",
      "[62]\tvalid_set's rmse: 0.053063\n",
      "[63]\tvalid_set's rmse: 0.0530696\n",
      "[64]\tvalid_set's rmse: 0.0530199\n",
      "[65]\tvalid_set's rmse: 0.0530955\n",
      "[66]\tvalid_set's rmse: 0.0531413\n",
      "[67]\tvalid_set's rmse: 0.0530249\n",
      "[68]\tvalid_set's rmse: 0.0530494\n",
      "[69]\tvalid_set's rmse: 0.0530404\n",
      "[70]\tvalid_set's rmse: 0.0529975\n",
      "[71]\tvalid_set's rmse: 0.0530178\n",
      "[72]\tvalid_set's rmse: 0.0529463\n",
      "[73]\tvalid_set's rmse: 0.0529558\n",
      "[74]\tvalid_set's rmse: 0.052989\n",
      "[75]\tvalid_set's rmse: 0.0529113\n",
      "[76]\tvalid_set's rmse: 0.0529537\n",
      "[77]\tvalid_set's rmse: 0.0529985\n",
      "[78]\tvalid_set's rmse: 0.0529617\n",
      "[79]\tvalid_set's rmse: 0.0530637\n",
      "[80]\tvalid_set's rmse: 0.0531255\n",
      "[81]\tvalid_set's rmse: 0.0530985\n",
      "[82]\tvalid_set's rmse: 0.0530316\n",
      "[83]\tvalid_set's rmse: 0.0529731\n",
      "[84]\tvalid_set's rmse: 0.0528925\n",
      "[85]\tvalid_set's rmse: 0.0528772\n",
      "[86]\tvalid_set's rmse: 0.0528563\n",
      "[87]\tvalid_set's rmse: 0.0528786\n",
      "[88]\tvalid_set's rmse: 0.0529708\n",
      "[89]\tvalid_set's rmse: 0.052811\n",
      "[90]\tvalid_set's rmse: 0.0528731\n",
      "[91]\tvalid_set's rmse: 0.0527823\n",
      "[92]\tvalid_set's rmse: 0.0527242\n",
      "[93]\tvalid_set's rmse: 0.052756\n",
      "[94]\tvalid_set's rmse: 0.052672\n",
      "[95]\tvalid_set's rmse: 0.0527252\n",
      "[96]\tvalid_set's rmse: 0.0526178\n",
      "[97]\tvalid_set's rmse: 0.052741\n",
      "[98]\tvalid_set's rmse: 0.0527305\n",
      "[99]\tvalid_set's rmse: 0.0528555\n",
      "[100]\tvalid_set's rmse: 0.052908\n",
      "[101]\tvalid_set's rmse: 0.052914\n",
      "[102]\tvalid_set's rmse: 0.052867\n",
      "[103]\tvalid_set's rmse: 0.0528327\n",
      "[104]\tvalid_set's rmse: 0.0528165\n",
      "[105]\tvalid_set's rmse: 0.0527374\n",
      "[106]\tvalid_set's rmse: 0.0527106\n",
      "[107]\tvalid_set's rmse: 0.0527806\n",
      "[108]\tvalid_set's rmse: 0.0527744\n",
      "[109]\tvalid_set's rmse: 0.0526811\n",
      "[110]\tvalid_set's rmse: 0.0527644\n",
      "[111]\tvalid_set's rmse: 0.052803\n",
      "[112]\tvalid_set's rmse: 0.0530016\n",
      "[113]\tvalid_set's rmse: 0.0530136\n",
      "[114]\tvalid_set's rmse: 0.0529978\n",
      "[115]\tvalid_set's rmse: 0.0529835\n",
      "[116]\tvalid_set's rmse: 0.0529596\n",
      "[117]\tvalid_set's rmse: 0.0529955\n",
      "[118]\tvalid_set's rmse: 0.0530249\n",
      "[119]\tvalid_set's rmse: 0.0530256\n",
      "[120]\tvalid_set's rmse: 0.0530926\n",
      "[121]\tvalid_set's rmse: 0.053108\n",
      "[122]\tvalid_set's rmse: 0.0530461\n",
      "[123]\tvalid_set's rmse: 0.0530299\n",
      "[124]\tvalid_set's rmse: 0.0529581\n",
      "[125]\tvalid_set's rmse: 0.052914\n",
      "[126]\tvalid_set's rmse: 0.0529183\n",
      "[127]\tvalid_set's rmse: 0.0528997\n",
      "[128]\tvalid_set's rmse: 0.0528369\n",
      "[129]\tvalid_set's rmse: 0.0527977\n",
      "[130]\tvalid_set's rmse: 0.0527074\n",
      "[131]\tvalid_set's rmse: 0.0526081\n",
      "[132]\tvalid_set's rmse: 0.0526114\n",
      "[133]\tvalid_set's rmse: 0.0525894\n",
      "[134]\tvalid_set's rmse: 0.0525252\n",
      "[135]\tvalid_set's rmse: 0.0526271\n",
      "[136]\tvalid_set's rmse: 0.0526687\n",
      "[137]\tvalid_set's rmse: 0.0526307\n",
      "[138]\tvalid_set's rmse: 0.0526148\n",
      "[139]\tvalid_set's rmse: 0.0526252\n",
      "[140]\tvalid_set's rmse: 0.0526852\n",
      "[141]\tvalid_set's rmse: 0.0526007\n",
      "[142]\tvalid_set's rmse: 0.0526038\n",
      "[143]\tvalid_set's rmse: 0.0525305\n",
      "[144]\tvalid_set's rmse: 0.0525158\n",
      "[145]\tvalid_set's rmse: 0.0525633\n",
      "[146]\tvalid_set's rmse: 0.0525539\n",
      "[147]\tvalid_set's rmse: 0.0525357\n",
      "[148]\tvalid_set's rmse: 0.052531\n",
      "[149]\tvalid_set's rmse: 0.0525334\n",
      "[150]\tvalid_set's rmse: 0.0524961\n",
      "[151]\tvalid_set's rmse: 0.0524827\n",
      "[152]\tvalid_set's rmse: 0.0524442\n",
      "[153]\tvalid_set's rmse: 0.0524358\n",
      "[154]\tvalid_set's rmse: 0.0524063\n",
      "[155]\tvalid_set's rmse: 0.0524052\n",
      "[156]\tvalid_set's rmse: 0.0525343\n",
      "[157]\tvalid_set's rmse: 0.0525098\n",
      "[158]\tvalid_set's rmse: 0.0525561\n",
      "[159]\tvalid_set's rmse: 0.0525695\n",
      "[160]\tvalid_set's rmse: 0.0525178\n",
      "[161]\tvalid_set's rmse: 0.0524935\n",
      "[162]\tvalid_set's rmse: 0.0524774\n",
      "[163]\tvalid_set's rmse: 0.0525251\n",
      "[164]\tvalid_set's rmse: 0.0525058\n",
      "[165]\tvalid_set's rmse: 0.0525314\n",
      "[166]\tvalid_set's rmse: 0.0525254\n",
      "[167]\tvalid_set's rmse: 0.0524385\n",
      "[168]\tvalid_set's rmse: 0.0525426\n",
      "[169]\tvalid_set's rmse: 0.0525633\n",
      "[170]\tvalid_set's rmse: 0.0525566\n",
      "[171]\tvalid_set's rmse: 0.0525432\n",
      "[172]\tvalid_set's rmse: 0.0525286\n",
      "[173]\tvalid_set's rmse: 0.052536\n",
      "[174]\tvalid_set's rmse: 0.0525506\n",
      "[175]\tvalid_set's rmse: 0.0525865\n",
      "[176]\tvalid_set's rmse: 0.0525583\n",
      "[177]\tvalid_set's rmse: 0.0525414\n",
      "[178]\tvalid_set's rmse: 0.0525379\n",
      "[179]\tvalid_set's rmse: 0.0524956\n",
      "[180]\tvalid_set's rmse: 0.0524778\n",
      "[181]\tvalid_set's rmse: 0.0524442\n",
      "[182]\tvalid_set's rmse: 0.0524981\n",
      "[183]\tvalid_set's rmse: 0.0525184\n",
      "[184]\tvalid_set's rmse: 0.0524893\n",
      "[185]\tvalid_set's rmse: 0.0525405\n",
      "[186]\tvalid_set's rmse: 0.0525081\n",
      "[187]\tvalid_set's rmse: 0.05253\n",
      "[188]\tvalid_set's rmse: 0.0525434\n",
      "[189]\tvalid_set's rmse: 0.0525202\n",
      "[190]\tvalid_set's rmse: 0.0525249\n",
      "[191]\tvalid_set's rmse: 0.0525123\n",
      "[192]\tvalid_set's rmse: 0.0525148\n",
      "[193]\tvalid_set's rmse: 0.052501\n",
      "[194]\tvalid_set's rmse: 0.0525001\n",
      "[195]\tvalid_set's rmse: 0.0524975\n",
      "[196]\tvalid_set's rmse: 0.0525127\n",
      "[197]\tvalid_set's rmse: 0.0525238\n",
      "[198]\tvalid_set's rmse: 0.0524842\n",
      "[199]\tvalid_set's rmse: 0.0524856\n",
      "[200]\tvalid_set's rmse: 0.0524946\n",
      "[201]\tvalid_set's rmse: 0.0524759\n",
      "[202]\tvalid_set's rmse: 0.0525\n",
      "[203]\tvalid_set's rmse: 0.0524703\n",
      "[204]\tvalid_set's rmse: 0.0525188\n",
      "[205]\tvalid_set's rmse: 0.0525871\n",
      "[206]\tvalid_set's rmse: 0.0526063\n",
      "[207]\tvalid_set's rmse: 0.0525817\n",
      "[208]\tvalid_set's rmse: 0.0526545\n",
      "[209]\tvalid_set's rmse: 0.0526768\n",
      "[210]\tvalid_set's rmse: 0.0526903\n",
      "[211]\tvalid_set's rmse: 0.0526337\n",
      "[212]\tvalid_set's rmse: 0.052624\n",
      "[213]\tvalid_set's rmse: 0.0525996\n",
      "[214]\tvalid_set's rmse: 0.0525875\n",
      "[215]\tvalid_set's rmse: 0.0526177\n",
      "[216]\tvalid_set's rmse: 0.0526636\n",
      "[217]\tvalid_set's rmse: 0.0526765\n",
      "[218]\tvalid_set's rmse: 0.0526599\n",
      "[219]\tvalid_set's rmse: 0.052663\n",
      "[220]\tvalid_set's rmse: 0.0526764\n",
      "[221]\tvalid_set's rmse: 0.0526634\n",
      "[222]\tvalid_set's rmse: 0.052683\n",
      "[223]\tvalid_set's rmse: 0.0526812\n",
      "[224]\tvalid_set's rmse: 0.0527\n",
      "[225]\tvalid_set's rmse: 0.052723\n",
      "[226]\tvalid_set's rmse: 0.0527276\n",
      "[227]\tvalid_set's rmse: 0.0527654\n",
      "[228]\tvalid_set's rmse: 0.052799\n",
      "[229]\tvalid_set's rmse: 0.0527883\n",
      "[230]\tvalid_set's rmse: 0.0527698\n",
      "[231]\tvalid_set's rmse: 0.0527683\n",
      "[232]\tvalid_set's rmse: 0.0527778\n",
      "[233]\tvalid_set's rmse: 0.0527695\n",
      "[234]\tvalid_set's rmse: 0.0527572\n",
      "[235]\tvalid_set's rmse: 0.0527357\n",
      "[236]\tvalid_set's rmse: 0.0527011\n",
      "[237]\tvalid_set's rmse: 0.0527024\n",
      "[238]\tvalid_set's rmse: 0.0526864\n",
      "[239]\tvalid_set's rmse: 0.0527034\n",
      "[240]\tvalid_set's rmse: 0.0526988\n",
      "[241]\tvalid_set's rmse: 0.0526715\n",
      "[242]\tvalid_set's rmse: 0.0526836\n",
      "[243]\tvalid_set's rmse: 0.052693\n",
      "[244]\tvalid_set's rmse: 0.0527116\n",
      "[245]\tvalid_set's rmse: 0.0527377\n",
      "[246]\tvalid_set's rmse: 0.05276\n",
      "[247]\tvalid_set's rmse: 0.0527495\n",
      "[248]\tvalid_set's rmse: 0.0527828\n",
      "[249]\tvalid_set's rmse: 0.0528417\n",
      "[250]\tvalid_set's rmse: 0.0528502\n",
      "[251]\tvalid_set's rmse: 0.0528849\n",
      "[252]\tvalid_set's rmse: 0.0528417\n",
      "[253]\tvalid_set's rmse: 0.0528705\n",
      "[254]\tvalid_set's rmse: 0.0528776\n",
      "[255]\tvalid_set's rmse: 0.0529001\n",
      "[256]\tvalid_set's rmse: 0.0528888\n",
      "[257]\tvalid_set's rmse: 0.0528601\n",
      "[258]\tvalid_set's rmse: 0.0528703\n",
      "[259]\tvalid_set's rmse: 0.0528683\n",
      "[260]\tvalid_set's rmse: 0.052881\n",
      "[261]\tvalid_set's rmse: 0.0529022\n",
      "[262]\tvalid_set's rmse: 0.0529247\n",
      "[263]\tvalid_set's rmse: 0.0528707\n",
      "[264]\tvalid_set's rmse: 0.0528765\n",
      "[265]\tvalid_set's rmse: 0.0528763\n",
      "[266]\tvalid_set's rmse: 0.0528655\n",
      "[267]\tvalid_set's rmse: 0.0528312\n",
      "[268]\tvalid_set's rmse: 0.0528215\n",
      "[269]\tvalid_set's rmse: 0.0528674\n",
      "[270]\tvalid_set's rmse: 0.0528769\n",
      "[271]\tvalid_set's rmse: 0.0528721\n",
      "[272]\tvalid_set's rmse: 0.0529143\n",
      "[273]\tvalid_set's rmse: 0.0529227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/LightGBMXT/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
      "\t-0.0524\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: LightGBM ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBM with 'num_gpus': 0, 'num_cpus': 20\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274]\tvalid_set's rmse: 0.0529389\n",
      "[275]\tvalid_set's rmse: 0.0529376\n",
      "[276]\tvalid_set's rmse: 0.052906\n",
      "[277]\tvalid_set's rmse: 0.0528859\n",
      "[278]\tvalid_set's rmse: 0.0528937\n",
      "[279]\tvalid_set's rmse: 0.0528916\n",
      "[280]\tvalid_set's rmse: 0.0528894\n",
      "[281]\tvalid_set's rmse: 0.0528967\n",
      "[282]\tvalid_set's rmse: 0.0528477\n",
      "[283]\tvalid_set's rmse: 0.0528655\n",
      "[284]\tvalid_set's rmse: 0.0528779\n",
      "[285]\tvalid_set's rmse: 0.0528888\n",
      "[286]\tvalid_set's rmse: 0.05291\n",
      "[287]\tvalid_set's rmse: 0.0529097\n",
      "[288]\tvalid_set's rmse: 0.0529009\n",
      "[289]\tvalid_set's rmse: 0.0529308\n",
      "[290]\tvalid_set's rmse: 0.0529352\n",
      "[291]\tvalid_set's rmse: 0.052954\n",
      "[292]\tvalid_set's rmse: 0.052943\n",
      "[293]\tvalid_set's rmse: 0.0529184\n",
      "[294]\tvalid_set's rmse: 0.0529482\n",
      "[295]\tvalid_set's rmse: 0.0529696\n",
      "[296]\tvalid_set's rmse: 0.0529908\n",
      "[297]\tvalid_set's rmse: 0.0529674\n",
      "[298]\tvalid_set's rmse: 0.0530004\n",
      "[299]\tvalid_set's rmse: 0.0530066\n",
      "[300]\tvalid_set's rmse: 0.053007\n",
      "[301]\tvalid_set's rmse: 0.0530365\n",
      "[302]\tvalid_set's rmse: 0.0530374\n",
      "[303]\tvalid_set's rmse: 0.0530841\n",
      "[304]\tvalid_set's rmse: 0.0530668\n",
      "[305]\tvalid_set's rmse: 0.0530665\n",
      "[306]\tvalid_set's rmse: 0.0530704\n",
      "[307]\tvalid_set's rmse: 0.0530404\n",
      "[308]\tvalid_set's rmse: 0.0530689\n",
      "[309]\tvalid_set's rmse: 0.0530917\n",
      "[310]\tvalid_set's rmse: 0.0530992\n",
      "[311]\tvalid_set's rmse: 0.0531072\n",
      "[312]\tvalid_set's rmse: 0.0531024\n",
      "[313]\tvalid_set's rmse: 0.0531031\n",
      "[314]\tvalid_set's rmse: 0.0530958\n",
      "[315]\tvalid_set's rmse: 0.0530872\n",
      "[316]\tvalid_set's rmse: 0.0530625\n",
      "[317]\tvalid_set's rmse: 0.0530701\n",
      "[318]\tvalid_set's rmse: 0.053061\n",
      "[319]\tvalid_set's rmse: 0.0530539\n",
      "[320]\tvalid_set's rmse: 0.0530531\n",
      "[321]\tvalid_set's rmse: 0.0530783\n",
      "[322]\tvalid_set's rmse: 0.0530898\n",
      "[323]\tvalid_set's rmse: 0.0531\n",
      "[324]\tvalid_set's rmse: 0.0531043\n",
      "[325]\tvalid_set's rmse: 0.053097\n",
      "[326]\tvalid_set's rmse: 0.0531142\n",
      "[327]\tvalid_set's rmse: 0.0531025\n",
      "[328]\tvalid_set's rmse: 0.0531249\n",
      "[329]\tvalid_set's rmse: 0.0531156\n",
      "[330]\tvalid_set's rmse: 0.0531447\n",
      "[331]\tvalid_set's rmse: 0.053167\n",
      "[332]\tvalid_set's rmse: 0.0531729\n",
      "[333]\tvalid_set's rmse: 0.0531748\n",
      "[334]\tvalid_set's rmse: 0.0531865\n",
      "[335]\tvalid_set's rmse: 0.0531728\n",
      "[336]\tvalid_set's rmse: 0.0531756\n",
      "[337]\tvalid_set's rmse: 0.0531385\n",
      "[338]\tvalid_set's rmse: 0.0531348\n",
      "[339]\tvalid_set's rmse: 0.0531416\n",
      "[340]\tvalid_set's rmse: 0.0531642\n",
      "[341]\tvalid_set's rmse: 0.0531669\n",
      "[342]\tvalid_set's rmse: 0.0531706\n",
      "[343]\tvalid_set's rmse: 0.053186\n",
      "[344]\tvalid_set's rmse: 0.0532228\n",
      "[345]\tvalid_set's rmse: 0.0532423\n",
      "[346]\tvalid_set's rmse: 0.053254\n",
      "[347]\tvalid_set's rmse: 0.0532361\n",
      "[348]\tvalid_set's rmse: 0.0532263\n",
      "[349]\tvalid_set's rmse: 0.0532212\n",
      "[350]\tvalid_set's rmse: 0.053232\n",
      "[351]\tvalid_set's rmse: 0.0532358\n",
      "[352]\tvalid_set's rmse: 0.0532609\n",
      "[353]\tvalid_set's rmse: 0.0532736\n",
      "[354]\tvalid_set's rmse: 0.0532639\n",
      "[355]\tvalid_set's rmse: 0.053269\n",
      "[356]\tvalid_set's rmse: 0.0532668\n",
      "[357]\tvalid_set's rmse: 0.053287\n",
      "[358]\tvalid_set's rmse: 0.0532626\n",
      "[359]\tvalid_set's rmse: 0.0532834\n",
      "[360]\tvalid_set's rmse: 0.0532468\n",
      "[361]\tvalid_set's rmse: 0.0532712\n",
      "[362]\tvalid_set's rmse: 0.0532897\n",
      "[363]\tvalid_set's rmse: 0.0532698\n",
      "[364]\tvalid_set's rmse: 0.0532774\n",
      "[365]\tvalid_set's rmse: 0.053289\n",
      "[366]\tvalid_set's rmse: 0.0533014\n",
      "[367]\tvalid_set's rmse: 0.0532857\n",
      "[368]\tvalid_set's rmse: 0.0532764\n",
      "[369]\tvalid_set's rmse: 0.053279\n",
      "[370]\tvalid_set's rmse: 0.0532699\n",
      "[371]\tvalid_set's rmse: 0.0532735\n",
      "[372]\tvalid_set's rmse: 0.0532831\n",
      "[373]\tvalid_set's rmse: 0.0532824\n",
      "[374]\tvalid_set's rmse: 0.05328\n",
      "[375]\tvalid_set's rmse: 0.0532686\n",
      "[376]\tvalid_set's rmse: 0.05327\n",
      "[377]\tvalid_set's rmse: 0.0532632\n",
      "[378]\tvalid_set's rmse: 0.0532699\n",
      "[379]\tvalid_set's rmse: 0.05327\n",
      "[380]\tvalid_set's rmse: 0.0532809\n",
      "[381]\tvalid_set's rmse: 0.0532651\n",
      "[382]\tvalid_set's rmse: 0.053282\n",
      "[383]\tvalid_set's rmse: 0.0532998\n",
      "[384]\tvalid_set's rmse: 0.0533077\n",
      "[385]\tvalid_set's rmse: 0.0533355\n",
      "[386]\tvalid_set's rmse: 0.0533324\n",
      "[387]\tvalid_set's rmse: 0.0533592\n",
      "[388]\tvalid_set's rmse: 0.0533654\n",
      "[389]\tvalid_set's rmse: 0.053373\n",
      "[390]\tvalid_set's rmse: 0.0533738\n",
      "[391]\tvalid_set's rmse: 0.0533936\n",
      "[392]\tvalid_set's rmse: 0.0533994\n",
      "[393]\tvalid_set's rmse: 0.053397\n",
      "[394]\tvalid_set's rmse: 0.0533927\n",
      "[395]\tvalid_set's rmse: 0.0533662\n",
      "[396]\tvalid_set's rmse: 0.0533624\n",
      "[397]\tvalid_set's rmse: 0.0533447\n",
      "[398]\tvalid_set's rmse: 0.0533688\n",
      "[399]\tvalid_set's rmse: 0.0533648\n",
      "[400]\tvalid_set's rmse: 0.0533418\n",
      "[401]\tvalid_set's rmse: 0.0533483\n",
      "[402]\tvalid_set's rmse: 0.0533388\n",
      "[403]\tvalid_set's rmse: 0.0533421\n",
      "[404]\tvalid_set's rmse: 0.053324\n",
      "[405]\tvalid_set's rmse: 0.0533203\n",
      "[406]\tvalid_set's rmse: 0.0533109\n",
      "[407]\tvalid_set's rmse: 0.0533092\n",
      "[408]\tvalid_set's rmse: 0.053318\n",
      "[409]\tvalid_set's rmse: 0.0533138\n",
      "[410]\tvalid_set's rmse: 0.0533214\n",
      "[411]\tvalid_set's rmse: 0.0533377\n",
      "[412]\tvalid_set's rmse: 0.0533451\n",
      "[413]\tvalid_set's rmse: 0.0533606\n",
      "[414]\tvalid_set's rmse: 0.0533694\n",
      "[415]\tvalid_set's rmse: 0.053373\n",
      "[416]\tvalid_set's rmse: 0.0533948\n",
      "[417]\tvalid_set's rmse: 0.0533935\n",
      "[418]\tvalid_set's rmse: 0.0533974\n",
      "[419]\tvalid_set's rmse: 0.0533987\n",
      "[420]\tvalid_set's rmse: 0.0533937\n",
      "[421]\tvalid_set's rmse: 0.0533843\n",
      "[422]\tvalid_set's rmse: 0.0533988\n",
      "[423]\tvalid_set's rmse: 0.0534125\n",
      "[424]\tvalid_set's rmse: 0.0533891\n",
      "[425]\tvalid_set's rmse: 0.0533818\n",
      "[426]\tvalid_set's rmse: 0.0533892\n",
      "[427]\tvalid_set's rmse: 0.0533842\n",
      "[428]\tvalid_set's rmse: 0.0534013\n",
      "[429]\tvalid_set's rmse: 0.0534061\n",
      "[430]\tvalid_set's rmse: 0.0534243\n",
      "[431]\tvalid_set's rmse: 0.0534308\n",
      "[432]\tvalid_set's rmse: 0.0534348\n",
      "[433]\tvalid_set's rmse: 0.0534322\n",
      "[434]\tvalid_set's rmse: 0.0534289\n",
      "[435]\tvalid_set's rmse: 0.0534415\n",
      "[436]\tvalid_set's rmse: 0.0534487\n",
      "[437]\tvalid_set's rmse: 0.0534336\n",
      "[438]\tvalid_set's rmse: 0.0534536\n",
      "[439]\tvalid_set's rmse: 0.0534518\n",
      "[440]\tvalid_set's rmse: 0.0534445\n",
      "[441]\tvalid_set's rmse: 0.0534437\n",
      "[442]\tvalid_set's rmse: 0.0534539\n",
      "[443]\tvalid_set's rmse: 0.0534679\n",
      "[444]\tvalid_set's rmse: 0.0534696\n",
      "[445]\tvalid_set's rmse: 0.0534533\n",
      "[446]\tvalid_set's rmse: 0.0534507\n",
      "[447]\tvalid_set's rmse: 0.0534435\n",
      "[448]\tvalid_set's rmse: 0.0534384\n",
      "[449]\tvalid_set's rmse: 0.0534459\n",
      "[450]\tvalid_set's rmse: 0.0534355\n",
      "[451]\tvalid_set's rmse: 0.053438\n",
      "[452]\tvalid_set's rmse: 0.0534322\n",
      "[453]\tvalid_set's rmse: 0.053431\n",
      "[454]\tvalid_set's rmse: 0.0534285\n",
      "[455]\tvalid_set's rmse: 0.0534262\n",
      "[1]\tvalid_set's rmse: 0.0582303\n",
      "[2]\tvalid_set's rmse: 0.0579813\n",
      "[3]\tvalid_set's rmse: 0.057556\n",
      "[4]\tvalid_set's rmse: 0.0573308\n",
      "[5]\tvalid_set's rmse: 0.0570366\n",
      "[6]\tvalid_set's rmse: 0.0568654\n",
      "[7]\tvalid_set's rmse: 0.056507\n",
      "[8]\tvalid_set's rmse: 0.0561256\n",
      "[9]\tvalid_set's rmse: 0.0561018\n",
      "[10]\tvalid_set's rmse: 0.0558246\n",
      "[11]\tvalid_set's rmse: 0.0558453\n",
      "[12]\tvalid_set's rmse: 0.0555339\n",
      "[13]\tvalid_set's rmse: 0.0552595\n",
      "[14]\tvalid_set's rmse: 0.055038\n",
      "[15]\tvalid_set's rmse: 0.0548669\n",
      "[16]\tvalid_set's rmse: 0.0546542\n",
      "[17]\tvalid_set's rmse: 0.054692\n",
      "[18]\tvalid_set's rmse: 0.0547139\n",
      "[19]\tvalid_set's rmse: 0.0547717\n",
      "[20]\tvalid_set's rmse: 0.0548003\n",
      "[21]\tvalid_set's rmse: 0.0545992\n",
      "[22]\tvalid_set's rmse: 0.0545869\n",
      "[23]\tvalid_set's rmse: 0.0546509\n",
      "[24]\tvalid_set's rmse: 0.054549\n",
      "[25]\tvalid_set's rmse: 0.0544877\n",
      "[26]\tvalid_set's rmse: 0.0545203\n",
      "[27]\tvalid_set's rmse: 0.054513\n",
      "[28]\tvalid_set's rmse: 0.0544182\n",
      "[29]\tvalid_set's rmse: 0.0542242\n",
      "[30]\tvalid_set's rmse: 0.054025\n",
      "[31]\tvalid_set's rmse: 0.0541275\n",
      "[32]\tvalid_set's rmse: 0.0539718\n",
      "[33]\tvalid_set's rmse: 0.0539662\n",
      "[34]\tvalid_set's rmse: 0.0537263\n",
      "[35]\tvalid_set's rmse: 0.0536797\n",
      "[36]\tvalid_set's rmse: 0.0537297\n",
      "[37]\tvalid_set's rmse: 0.0537576\n",
      "[38]\tvalid_set's rmse: 0.0537967\n",
      "[39]\tvalid_set's rmse: 0.0537379\n",
      "[40]\tvalid_set's rmse: 0.0537712\n",
      "[41]\tvalid_set's rmse: 0.0538394\n",
      "[42]\tvalid_set's rmse: 0.0538415\n",
      "[43]\tvalid_set's rmse: 0.0538605\n",
      "[44]\tvalid_set's rmse: 0.0539034\n",
      "[45]\tvalid_set's rmse: 0.0539866\n",
      "[46]\tvalid_set's rmse: 0.0538654\n",
      "[47]\tvalid_set's rmse: 0.0538388\n",
      "[48]\tvalid_set's rmse: 0.0538986\n",
      "[49]\tvalid_set's rmse: 0.0539589\n",
      "[50]\tvalid_set's rmse: 0.0539128\n",
      "[51]\tvalid_set's rmse: 0.053883\n",
      "[52]\tvalid_set's rmse: 0.0538186\n",
      "[53]\tvalid_set's rmse: 0.0538316\n",
      "[54]\tvalid_set's rmse: 0.0538372\n",
      "[55]\tvalid_set's rmse: 0.0537426\n",
      "[56]\tvalid_set's rmse: 0.0536852\n",
      "[57]\tvalid_set's rmse: 0.0537431\n",
      "[58]\tvalid_set's rmse: 0.0536433\n",
      "[59]\tvalid_set's rmse: 0.0537269\n",
      "[60]\tvalid_set's rmse: 0.0536464\n",
      "[61]\tvalid_set's rmse: 0.0535302\n",
      "[62]\tvalid_set's rmse: 0.0536551\n",
      "[63]\tvalid_set's rmse: 0.0536264\n",
      "[64]\tvalid_set's rmse: 0.0534595\n",
      "[65]\tvalid_set's rmse: 0.0534597\n",
      "[66]\tvalid_set's rmse: 0.0532915\n",
      "[67]\tvalid_set's rmse: 0.0533267\n",
      "[68]\tvalid_set's rmse: 0.0533547\n",
      "[69]\tvalid_set's rmse: 0.0533852\n",
      "[70]\tvalid_set's rmse: 0.0534006\n",
      "[71]\tvalid_set's rmse: 0.0534649\n",
      "[72]\tvalid_set's rmse: 0.0536172\n",
      "[73]\tvalid_set's rmse: 0.0535936\n",
      "[74]\tvalid_set's rmse: 0.0535303\n",
      "[75]\tvalid_set's rmse: 0.0536425\n",
      "[76]\tvalid_set's rmse: 0.0536845\n",
      "[77]\tvalid_set's rmse: 0.0536465\n",
      "[78]\tvalid_set's rmse: 0.0537779\n",
      "[79]\tvalid_set's rmse: 0.0538175\n",
      "[80]\tvalid_set's rmse: 0.0537612\n",
      "[81]\tvalid_set's rmse: 0.0537182\n",
      "[82]\tvalid_set's rmse: 0.053784\n",
      "[83]\tvalid_set's rmse: 0.0538005\n",
      "[84]\tvalid_set's rmse: 0.0537602\n",
      "[85]\tvalid_set's rmse: 0.0537091\n",
      "[86]\tvalid_set's rmse: 0.053803\n",
      "[87]\tvalid_set's rmse: 0.0538537\n",
      "[88]\tvalid_set's rmse: 0.0538701\n",
      "[89]\tvalid_set's rmse: 0.0538131\n",
      "[90]\tvalid_set's rmse: 0.0538113\n",
      "[91]\tvalid_set's rmse: 0.0538003\n",
      "[92]\tvalid_set's rmse: 0.0538516\n",
      "[93]\tvalid_set's rmse: 0.0537771\n",
      "[94]\tvalid_set's rmse: 0.0537134\n",
      "[95]\tvalid_set's rmse: 0.05372\n",
      "[96]\tvalid_set's rmse: 0.0538034\n",
      "[97]\tvalid_set's rmse: 0.05379\n",
      "[98]\tvalid_set's rmse: 0.0538561\n",
      "[99]\tvalid_set's rmse: 0.0537854\n",
      "[100]\tvalid_set's rmse: 0.0537799\n",
      "[101]\tvalid_set's rmse: 0.0537613\n",
      "[102]\tvalid_set's rmse: 0.0538024\n",
      "[103]\tvalid_set's rmse: 0.0538495\n",
      "[104]\tvalid_set's rmse: 0.0538504\n",
      "[105]\tvalid_set's rmse: 0.0537962\n",
      "[106]\tvalid_set's rmse: 0.0537897\n",
      "[107]\tvalid_set's rmse: 0.0536822\n",
      "[108]\tvalid_set's rmse: 0.0537051\n",
      "[109]\tvalid_set's rmse: 0.0537109\n",
      "[110]\tvalid_set's rmse: 0.0537642\n",
      "[111]\tvalid_set's rmse: 0.0537554\n",
      "[112]\tvalid_set's rmse: 0.0537723\n",
      "[113]\tvalid_set's rmse: 0.0538806\n",
      "[114]\tvalid_set's rmse: 0.0539693\n",
      "[115]\tvalid_set's rmse: 0.0540058\n",
      "[116]\tvalid_set's rmse: 0.0540458\n",
      "[117]\tvalid_set's rmse: 0.0540652\n",
      "[118]\tvalid_set's rmse: 0.054028\n",
      "[119]\tvalid_set's rmse: 0.0540271\n",
      "[120]\tvalid_set's rmse: 0.0540503\n",
      "[121]\tvalid_set's rmse: 0.0540636\n",
      "[122]\tvalid_set's rmse: 0.0540608\n",
      "[123]\tvalid_set's rmse: 0.0540922\n",
      "[124]\tvalid_set's rmse: 0.0541047\n",
      "[125]\tvalid_set's rmse: 0.0540801\n",
      "[126]\tvalid_set's rmse: 0.0541063\n",
      "[127]\tvalid_set's rmse: 0.0540734\n",
      "[128]\tvalid_set's rmse: 0.0539894\n",
      "[129]\tvalid_set's rmse: 0.05402\n",
      "[130]\tvalid_set's rmse: 0.0539825\n",
      "[131]\tvalid_set's rmse: 0.0539918\n",
      "[132]\tvalid_set's rmse: 0.054003\n",
      "[133]\tvalid_set's rmse: 0.0540575\n",
      "[134]\tvalid_set's rmse: 0.0540861\n",
      "[135]\tvalid_set's rmse: 0.0540428\n",
      "[136]\tvalid_set's rmse: 0.0541011\n",
      "[137]\tvalid_set's rmse: 0.0541268\n",
      "[138]\tvalid_set's rmse: 0.0541541\n",
      "[139]\tvalid_set's rmse: 0.0541002\n",
      "[140]\tvalid_set's rmse: 0.0540944\n",
      "[141]\tvalid_set's rmse: 0.0541122\n",
      "[142]\tvalid_set's rmse: 0.0541043\n",
      "[143]\tvalid_set's rmse: 0.0540776\n",
      "[144]\tvalid_set's rmse: 0.0540877\n",
      "[145]\tvalid_set's rmse: 0.0541088\n",
      "[146]\tvalid_set's rmse: 0.0540529\n",
      "[147]\tvalid_set's rmse: 0.0540354\n",
      "[148]\tvalid_set's rmse: 0.0540191\n",
      "[149]\tvalid_set's rmse: 0.0540343\n",
      "[150]\tvalid_set's rmse: 0.0540458\n",
      "[151]\tvalid_set's rmse: 0.0540449\n",
      "[152]\tvalid_set's rmse: 0.054044\n",
      "[153]\tvalid_set's rmse: 0.0540492\n",
      "[154]\tvalid_set's rmse: 0.0540417\n",
      "[155]\tvalid_set's rmse: 0.0540647\n",
      "[156]\tvalid_set's rmse: 0.0540483\n",
      "[157]\tvalid_set's rmse: 0.0541064\n",
      "[158]\tvalid_set's rmse: 0.0541405\n",
      "[159]\tvalid_set's rmse: 0.0541743\n",
      "[160]\tvalid_set's rmse: 0.0541913\n",
      "[161]\tvalid_set's rmse: 0.0542264\n",
      "[162]\tvalid_set's rmse: 0.0542471\n",
      "[163]\tvalid_set's rmse: 0.0542556\n",
      "[164]\tvalid_set's rmse: 0.0542449\n",
      "[165]\tvalid_set's rmse: 0.0543161\n",
      "[166]\tvalid_set's rmse: 0.0543385\n",
      "[167]\tvalid_set's rmse: 0.0543528\n",
      "[168]\tvalid_set's rmse: 0.0543439\n",
      "[169]\tvalid_set's rmse: 0.0543381\n",
      "[170]\tvalid_set's rmse: 0.0543217\n",
      "[171]\tvalid_set's rmse: 0.0543622\n",
      "[172]\tvalid_set's rmse: 0.0543568\n",
      "[173]\tvalid_set's rmse: 0.0543547\n",
      "[174]\tvalid_set's rmse: 0.054345\n",
      "[175]\tvalid_set's rmse: 0.0543562\n",
      "[176]\tvalid_set's rmse: 0.0543817\n",
      "[177]\tvalid_set's rmse: 0.054369\n",
      "[178]\tvalid_set's rmse: 0.0543557\n",
      "[179]\tvalid_set's rmse: 0.0543746\n",
      "[180]\tvalid_set's rmse: 0.0544009\n",
      "[181]\tvalid_set's rmse: 0.0544059\n",
      "[182]\tvalid_set's rmse: 0.0544077\n",
      "[183]\tvalid_set's rmse: 0.0543916\n",
      "[184]\tvalid_set's rmse: 0.0544293\n",
      "[185]\tvalid_set's rmse: 0.0544434\n",
      "[186]\tvalid_set's rmse: 0.0544314\n",
      "[187]\tvalid_set's rmse: 0.0544229\n",
      "[188]\tvalid_set's rmse: 0.0544167\n",
      "[189]\tvalid_set's rmse: 0.0544264\n",
      "[190]\tvalid_set's rmse: 0.054458\n",
      "[191]\tvalid_set's rmse: 0.0544514\n",
      "[192]\tvalid_set's rmse: 0.0544772\n",
      "[193]\tvalid_set's rmse: 0.0544854\n",
      "[194]\tvalid_set's rmse: 0.0544727\n",
      "[195]\tvalid_set's rmse: 0.0545139\n",
      "[196]\tvalid_set's rmse: 0.0545468\n",
      "[197]\tvalid_set's rmse: 0.0545281\n",
      "[198]\tvalid_set's rmse: 0.0545343\n",
      "[199]\tvalid_set's rmse: 0.054532\n",
      "[200]\tvalid_set's rmse: 0.0545085\n",
      "[201]\tvalid_set's rmse: 0.0544987\n",
      "[202]\tvalid_set's rmse: 0.054511\n",
      "[203]\tvalid_set's rmse: 0.0545239\n",
      "[204]\tvalid_set's rmse: 0.0545307\n",
      "[205]\tvalid_set's rmse: 0.05455\n",
      "[206]\tvalid_set's rmse: 0.0545825\n",
      "[207]\tvalid_set's rmse: 0.054582\n",
      "[208]\tvalid_set's rmse: 0.0545634\n",
      "[209]\tvalid_set's rmse: 0.0546152\n",
      "[210]\tvalid_set's rmse: 0.0545849\n",
      "[211]\tvalid_set's rmse: 0.0546014\n",
      "[212]\tvalid_set's rmse: 0.0545987\n",
      "[213]\tvalid_set's rmse: 0.0546104\n",
      "[214]\tvalid_set's rmse: 0.0546311\n",
      "[215]\tvalid_set's rmse: 0.0546263\n",
      "[216]\tvalid_set's rmse: 0.0546241\n",
      "[217]\tvalid_set's rmse: 0.0546104\n",
      "[218]\tvalid_set's rmse: 0.054626\n",
      "[219]\tvalid_set's rmse: 0.0546166\n",
      "[220]\tvalid_set's rmse: 0.0546254\n",
      "[221]\tvalid_set's rmse: 0.0546165\n",
      "[222]\tvalid_set's rmse: 0.0545808\n",
      "[223]\tvalid_set's rmse: 0.0545913\n",
      "[224]\tvalid_set's rmse: 0.0545882\n",
      "[225]\tvalid_set's rmse: 0.0545964\n",
      "[226]\tvalid_set's rmse: 0.0545931\n",
      "[227]\tvalid_set's rmse: 0.0546077\n",
      "[228]\tvalid_set's rmse: 0.0546218\n",
      "[229]\tvalid_set's rmse: 0.054624\n",
      "[230]\tvalid_set's rmse: 0.0546166\n",
      "[231]\tvalid_set's rmse: 0.0545931\n",
      "[232]\tvalid_set's rmse: 0.0545895\n",
      "[233]\tvalid_set's rmse: 0.0546086\n",
      "[234]\tvalid_set's rmse: 0.0546162\n",
      "[235]\tvalid_set's rmse: 0.0546402\n",
      "[236]\tvalid_set's rmse: 0.0546587\n",
      "[237]\tvalid_set's rmse: 0.0546519\n",
      "[238]\tvalid_set's rmse: 0.0546451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/LightGBM/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
      "\t-0.0533\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting RandomForestMSE with 'num_gpus': 0, 'num_cpus': 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239]\tvalid_set's rmse: 0.0546386\n",
      "[240]\tvalid_set's rmse: 0.0546356\n",
      "[241]\tvalid_set's rmse: 0.0546309\n",
      "[242]\tvalid_set's rmse: 0.0546369\n",
      "[243]\tvalid_set's rmse: 0.0546356\n",
      "[244]\tvalid_set's rmse: 0.0546299\n",
      "[245]\tvalid_set's rmse: 0.0546452\n",
      "[246]\tvalid_set's rmse: 0.0546541\n",
      "[247]\tvalid_set's rmse: 0.0546598\n",
      "[248]\tvalid_set's rmse: 0.0546526\n",
      "[249]\tvalid_set's rmse: 0.0546478\n",
      "[250]\tvalid_set's rmse: 0.0546367\n",
      "[251]\tvalid_set's rmse: 0.0546424\n",
      "[252]\tvalid_set's rmse: 0.0546552\n",
      "[253]\tvalid_set's rmse: 0.0546488\n",
      "[254]\tvalid_set's rmse: 0.0546356\n",
      "[255]\tvalid_set's rmse: 0.054665\n",
      "[256]\tvalid_set's rmse: 0.0546678\n",
      "[257]\tvalid_set's rmse: 0.05469\n",
      "[258]\tvalid_set's rmse: 0.054694\n",
      "[259]\tvalid_set's rmse: 0.0547083\n",
      "[260]\tvalid_set's rmse: 0.0547164\n",
      "[261]\tvalid_set's rmse: 0.0547004\n",
      "[262]\tvalid_set's rmse: 0.0546946\n",
      "[263]\tvalid_set's rmse: 0.0546919\n",
      "[264]\tvalid_set's rmse: 0.0547018\n",
      "[265]\tvalid_set's rmse: 0.0547288\n",
      "[266]\tvalid_set's rmse: 0.054733\n",
      "[267]\tvalid_set's rmse: 0.0547283\n",
      "[268]\tvalid_set's rmse: 0.0547416\n",
      "[269]\tvalid_set's rmse: 0.0547361\n",
      "[270]\tvalid_set's rmse: 0.0547175\n",
      "[271]\tvalid_set's rmse: 0.0547247\n",
      "[272]\tvalid_set's rmse: 0.0547044\n",
      "[273]\tvalid_set's rmse: 0.0547016\n",
      "[274]\tvalid_set's rmse: 0.0546885\n",
      "[275]\tvalid_set's rmse: 0.0546796\n",
      "[276]\tvalid_set's rmse: 0.0546654\n",
      "[277]\tvalid_set's rmse: 0.0546696\n",
      "[278]\tvalid_set's rmse: 0.0546638\n",
      "[279]\tvalid_set's rmse: 0.054664\n",
      "[280]\tvalid_set's rmse: 0.0546518\n",
      "[281]\tvalid_set's rmse: 0.0546664\n",
      "[282]\tvalid_set's rmse: 0.0546618\n",
      "[283]\tvalid_set's rmse: 0.0546463\n",
      "[284]\tvalid_set's rmse: 0.0546416\n",
      "[285]\tvalid_set's rmse: 0.0546449\n",
      "[286]\tvalid_set's rmse: 0.0546384\n",
      "[287]\tvalid_set's rmse: 0.0546272\n",
      "[288]\tvalid_set's rmse: 0.0546345\n",
      "[289]\tvalid_set's rmse: 0.0546311\n",
      "[290]\tvalid_set's rmse: 0.0546524\n",
      "[291]\tvalid_set's rmse: 0.0546354\n",
      "[292]\tvalid_set's rmse: 0.0546335\n",
      "[293]\tvalid_set's rmse: 0.0546351\n",
      "[294]\tvalid_set's rmse: 0.054638\n",
      "[295]\tvalid_set's rmse: 0.0546375\n",
      "[296]\tvalid_set's rmse: 0.0546431\n",
      "[297]\tvalid_set's rmse: 0.054632\n",
      "[298]\tvalid_set's rmse: 0.0546205\n",
      "[299]\tvalid_set's rmse: 0.054631\n",
      "[300]\tvalid_set's rmse: 0.0546422\n",
      "[301]\tvalid_set's rmse: 0.0546471\n",
      "[302]\tvalid_set's rmse: 0.0546645\n",
      "[303]\tvalid_set's rmse: 0.054653\n",
      "[304]\tvalid_set's rmse: 0.054655\n",
      "[305]\tvalid_set's rmse: 0.0546471\n",
      "[306]\tvalid_set's rmse: 0.0546401\n",
      "[307]\tvalid_set's rmse: 0.0546374\n",
      "[308]\tvalid_set's rmse: 0.0546318\n",
      "[309]\tvalid_set's rmse: 0.0546425\n",
      "[310]\tvalid_set's rmse: 0.0546338\n",
      "[311]\tvalid_set's rmse: 0.0546388\n",
      "[312]\tvalid_set's rmse: 0.0546354\n",
      "[313]\tvalid_set's rmse: 0.054649\n",
      "[314]\tvalid_set's rmse: 0.0546514\n",
      "[315]\tvalid_set's rmse: 0.0546409\n",
      "[316]\tvalid_set's rmse: 0.0546338\n",
      "[317]\tvalid_set's rmse: 0.0546508\n",
      "[318]\tvalid_set's rmse: 0.0546633\n",
      "[319]\tvalid_set's rmse: 0.0546557\n",
      "[320]\tvalid_set's rmse: 0.054653\n",
      "[321]\tvalid_set's rmse: 0.0546417\n",
      "[322]\tvalid_set's rmse: 0.054641\n",
      "[323]\tvalid_set's rmse: 0.0546514\n",
      "[324]\tvalid_set's rmse: 0.0546585\n",
      "[325]\tvalid_set's rmse: 0.0546512\n",
      "[326]\tvalid_set's rmse: 0.0546401\n",
      "[327]\tvalid_set's rmse: 0.0546412\n",
      "[328]\tvalid_set's rmse: 0.0546364\n",
      "[329]\tvalid_set's rmse: 0.0546335\n",
      "[330]\tvalid_set's rmse: 0.0546458\n",
      "[331]\tvalid_set's rmse: 0.0546561\n",
      "[332]\tvalid_set's rmse: 0.054646\n",
      "[333]\tvalid_set's rmse: 0.0546497\n",
      "[334]\tvalid_set's rmse: 0.0546516\n",
      "[335]\tvalid_set's rmse: 0.0546611\n",
      "[336]\tvalid_set's rmse: 0.0546561\n",
      "[337]\tvalid_set's rmse: 0.0546484\n",
      "[338]\tvalid_set's rmse: 0.0546564\n",
      "[339]\tvalid_set's rmse: 0.0546481\n",
      "[340]\tvalid_set's rmse: 0.0546464\n",
      "[341]\tvalid_set's rmse: 0.054646\n",
      "[342]\tvalid_set's rmse: 0.0546454\n",
      "[343]\tvalid_set's rmse: 0.0546469\n",
      "[344]\tvalid_set's rmse: 0.0546402\n",
      "[345]\tvalid_set's rmse: 0.0546457\n",
      "[346]\tvalid_set's rmse: 0.0546437\n",
      "[347]\tvalid_set's rmse: 0.0546409\n",
      "[348]\tvalid_set's rmse: 0.0546437\n",
      "[349]\tvalid_set's rmse: 0.0546445\n",
      "[350]\tvalid_set's rmse: 0.0546448\n",
      "[351]\tvalid_set's rmse: 0.054643\n",
      "[352]\tvalid_set's rmse: 0.0546466\n",
      "[353]\tvalid_set's rmse: 0.0546439\n",
      "[354]\tvalid_set's rmse: 0.0546421\n",
      "[355]\tvalid_set's rmse: 0.0546374\n",
      "[356]\tvalid_set's rmse: 0.0546317\n",
      "[357]\tvalid_set's rmse: 0.0546438\n",
      "[358]\tvalid_set's rmse: 0.0546454\n",
      "[359]\tvalid_set's rmse: 0.0546469\n",
      "[360]\tvalid_set's rmse: 0.0546458\n",
      "[361]\tvalid_set's rmse: 0.0546357\n",
      "[362]\tvalid_set's rmse: 0.0546344\n",
      "[363]\tvalid_set's rmse: 0.0546363\n",
      "[364]\tvalid_set's rmse: 0.0546241\n",
      "[365]\tvalid_set's rmse: 0.0546273\n",
      "[366]\tvalid_set's rmse: 0.0546237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/RandomForestMSE/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/RandomForestMSE/y_pred_proba_val.pkl\n",
      "\t-0.0529\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: CatBoost ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting CatBoost with 'num_gpus': 0, 'num_cpus': 20\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 20}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0599545\ttest: 0.0586303\tbest: 0.0586303 (0)\ttotal: 13.5ms\tremaining: 2m 14s\n",
      "1:\tlearn: 0.0594067\ttest: 0.0584641\tbest: 0.0584641 (1)\ttotal: 22.5ms\tremaining: 1m 52s\n",
      "2:\tlearn: 0.0589784\ttest: 0.0584145\tbest: 0.0584145 (2)\ttotal: 31ms\tremaining: 1m 43s\n",
      "3:\tlearn: 0.0583749\ttest: 0.0583901\tbest: 0.0583901 (3)\ttotal: 38.7ms\tremaining: 1m 36s\n",
      "4:\tlearn: 0.0580345\ttest: 0.0581394\tbest: 0.0581394 (4)\ttotal: 46ms\tremaining: 1m 31s\n",
      "5:\tlearn: 0.0575834\ttest: 0.0580518\tbest: 0.0580518 (5)\ttotal: 52.5ms\tremaining: 1m 27s\n",
      "6:\tlearn: 0.0571033\ttest: 0.0579818\tbest: 0.0579818 (6)\ttotal: 59.2ms\tremaining: 1m 24s\n",
      "7:\tlearn: 0.0566878\ttest: 0.0578297\tbest: 0.0578297 (7)\ttotal: 65.4ms\tremaining: 1m 21s\n",
      "8:\tlearn: 0.0562153\ttest: 0.0576512\tbest: 0.0576512 (8)\ttotal: 71.2ms\tremaining: 1m 19s\n",
      "9:\tlearn: 0.0558242\ttest: 0.0575838\tbest: 0.0575838 (9)\ttotal: 77.2ms\tremaining: 1m 17s\n",
      "10:\tlearn: 0.0554735\ttest: 0.0575097\tbest: 0.0575097 (10)\ttotal: 82.9ms\tremaining: 1m 15s\n",
      "11:\tlearn: 0.0550868\ttest: 0.0575752\tbest: 0.0575097 (10)\ttotal: 88.9ms\tremaining: 1m 14s\n",
      "12:\tlearn: 0.0547402\ttest: 0.0575829\tbest: 0.0575097 (10)\ttotal: 95.2ms\tremaining: 1m 13s\n",
      "13:\tlearn: 0.0542983\ttest: 0.0574729\tbest: 0.0574729 (13)\ttotal: 101ms\tremaining: 1m 11s\n",
      "14:\tlearn: 0.0538893\ttest: 0.0573781\tbest: 0.0573781 (14)\ttotal: 106ms\tremaining: 1m 10s\n",
      "15:\tlearn: 0.0533457\ttest: 0.0572981\tbest: 0.0572981 (15)\ttotal: 112ms\tremaining: 1m 9s\n",
      "16:\tlearn: 0.0529570\ttest: 0.0570281\tbest: 0.0570281 (16)\ttotal: 118ms\tremaining: 1m 9s\n",
      "17:\tlearn: 0.0525931\ttest: 0.0567915\tbest: 0.0567915 (17)\ttotal: 124ms\tremaining: 1m 8s\n",
      "18:\tlearn: 0.0522700\ttest: 0.0568118\tbest: 0.0567915 (17)\ttotal: 130ms\tremaining: 1m 8s\n",
      "19:\tlearn: 0.0518582\ttest: 0.0566555\tbest: 0.0566555 (19)\ttotal: 137ms\tremaining: 1m 8s\n",
      "20:\tlearn: 0.0515325\ttest: 0.0566299\tbest: 0.0566299 (20)\ttotal: 144ms\tremaining: 1m 8s\n",
      "21:\tlearn: 0.0510362\ttest: 0.0565666\tbest: 0.0565666 (21)\ttotal: 151ms\tremaining: 1m 8s\n",
      "22:\tlearn: 0.0506537\ttest: 0.0564022\tbest: 0.0564022 (22)\ttotal: 159ms\tremaining: 1m 8s\n",
      "23:\tlearn: 0.0503796\ttest: 0.0562910\tbest: 0.0562910 (23)\ttotal: 166ms\tremaining: 1m 8s\n",
      "24:\tlearn: 0.0500596\ttest: 0.0560822\tbest: 0.0560822 (24)\ttotal: 173ms\tremaining: 1m 9s\n",
      "25:\tlearn: 0.0497559\ttest: 0.0560051\tbest: 0.0560051 (25)\ttotal: 180ms\tremaining: 1m 8s\n",
      "26:\tlearn: 0.0494842\ttest: 0.0559632\tbest: 0.0559632 (26)\ttotal: 186ms\tremaining: 1m 8s\n",
      "27:\tlearn: 0.0492389\ttest: 0.0558944\tbest: 0.0558944 (27)\ttotal: 192ms\tremaining: 1m 8s\n",
      "28:\tlearn: 0.0489725\ttest: 0.0558268\tbest: 0.0558268 (28)\ttotal: 198ms\tremaining: 1m 8s\n",
      "29:\tlearn: 0.0486299\ttest: 0.0558981\tbest: 0.0558268 (28)\ttotal: 204ms\tremaining: 1m 7s\n",
      "30:\tlearn: 0.0482976\ttest: 0.0558086\tbest: 0.0558086 (30)\ttotal: 210ms\tremaining: 1m 7s\n",
      "31:\tlearn: 0.0481470\ttest: 0.0556976\tbest: 0.0556976 (31)\ttotal: 215ms\tremaining: 1m 7s\n",
      "32:\tlearn: 0.0479304\ttest: 0.0556323\tbest: 0.0556323 (32)\ttotal: 221ms\tremaining: 1m 6s\n",
      "33:\tlearn: 0.0476307\ttest: 0.0555036\tbest: 0.0555036 (33)\ttotal: 226ms\tremaining: 1m 6s\n",
      "34:\tlearn: 0.0472611\ttest: 0.0553380\tbest: 0.0553380 (34)\ttotal: 231ms\tremaining: 1m 5s\n",
      "35:\tlearn: 0.0468630\ttest: 0.0553188\tbest: 0.0553188 (35)\ttotal: 236ms\tremaining: 1m 5s\n",
      "36:\tlearn: 0.0465726\ttest: 0.0552330\tbest: 0.0552330 (36)\ttotal: 241ms\tremaining: 1m 4s\n",
      "37:\tlearn: 0.0461796\ttest: 0.0551621\tbest: 0.0551621 (37)\ttotal: 245ms\tremaining: 1m 4s\n",
      "38:\tlearn: 0.0460037\ttest: 0.0550984\tbest: 0.0550984 (38)\ttotal: 250ms\tremaining: 1m 3s\n",
      "39:\tlearn: 0.0457130\ttest: 0.0550245\tbest: 0.0550245 (39)\ttotal: 254ms\tremaining: 1m 3s\n",
      "40:\tlearn: 0.0454298\ttest: 0.0548317\tbest: 0.0548317 (40)\ttotal: 258ms\tremaining: 1m 2s\n",
      "41:\tlearn: 0.0451731\ttest: 0.0548626\tbest: 0.0548317 (40)\ttotal: 262ms\tremaining: 1m 2s\n",
      "42:\tlearn: 0.0449488\ttest: 0.0547190\tbest: 0.0547190 (42)\ttotal: 267ms\tremaining: 1m 1s\n",
      "43:\tlearn: 0.0446327\ttest: 0.0546496\tbest: 0.0546496 (43)\ttotal: 271ms\tremaining: 1m 1s\n",
      "44:\tlearn: 0.0443787\ttest: 0.0546732\tbest: 0.0546496 (43)\ttotal: 275ms\tremaining: 1m\n",
      "45:\tlearn: 0.0441161\ttest: 0.0546033\tbest: 0.0546033 (45)\ttotal: 280ms\tremaining: 1m\n",
      "46:\tlearn: 0.0438560\ttest: 0.0544934\tbest: 0.0544934 (46)\ttotal: 284ms\tremaining: 1m\n",
      "47:\tlearn: 0.0435307\ttest: 0.0544439\tbest: 0.0544439 (47)\ttotal: 288ms\tremaining: 59.7s\n",
      "48:\tlearn: 0.0433471\ttest: 0.0543892\tbest: 0.0543892 (48)\ttotal: 293ms\tremaining: 59.4s\n",
      "49:\tlearn: 0.0431007\ttest: 0.0543330\tbest: 0.0543330 (49)\ttotal: 296ms\tremaining: 59s\n",
      "50:\tlearn: 0.0427867\ttest: 0.0543987\tbest: 0.0543330 (49)\ttotal: 300ms\tremaining: 58.6s\n",
      "51:\tlearn: 0.0424081\ttest: 0.0544141\tbest: 0.0543330 (49)\ttotal: 305ms\tremaining: 58.3s\n",
      "52:\tlearn: 0.0421402\ttest: 0.0545164\tbest: 0.0543330 (49)\ttotal: 309ms\tremaining: 57.9s\n",
      "53:\tlearn: 0.0418644\ttest: 0.0545724\tbest: 0.0543330 (49)\ttotal: 313ms\tremaining: 57.6s\n",
      "54:\tlearn: 0.0416199\ttest: 0.0545399\tbest: 0.0543330 (49)\ttotal: 317ms\tremaining: 57.2s\n",
      "55:\tlearn: 0.0414351\ttest: 0.0546015\tbest: 0.0543330 (49)\ttotal: 320ms\tremaining: 56.9s\n",
      "56:\tlearn: 0.0410917\ttest: 0.0545266\tbest: 0.0543330 (49)\ttotal: 324ms\tremaining: 56.6s\n",
      "57:\tlearn: 0.0408607\ttest: 0.0544757\tbest: 0.0543330 (49)\ttotal: 328ms\tremaining: 56.3s\n",
      "58:\tlearn: 0.0405532\ttest: 0.0544438\tbest: 0.0543330 (49)\ttotal: 332ms\tremaining: 56s\n",
      "59:\tlearn: 0.0403166\ttest: 0.0544255\tbest: 0.0543330 (49)\ttotal: 336ms\tremaining: 55.7s\n",
      "60:\tlearn: 0.0400185\ttest: 0.0544216\tbest: 0.0543330 (49)\ttotal: 340ms\tremaining: 55.3s\n",
      "61:\tlearn: 0.0399147\ttest: 0.0544227\tbest: 0.0543330 (49)\ttotal: 344ms\tremaining: 55.2s\n",
      "62:\tlearn: 0.0396632\ttest: 0.0544104\tbest: 0.0543330 (49)\ttotal: 348ms\tremaining: 54.8s\n",
      "63:\tlearn: 0.0394411\ttest: 0.0544770\tbest: 0.0543330 (49)\ttotal: 351ms\tremaining: 54.6s\n",
      "64:\tlearn: 0.0392200\ttest: 0.0544281\tbest: 0.0543330 (49)\ttotal: 355ms\tremaining: 54.3s\n",
      "65:\tlearn: 0.0390047\ttest: 0.0544406\tbest: 0.0543330 (49)\ttotal: 359ms\tremaining: 54s\n",
      "66:\tlearn: 0.0386795\ttest: 0.0544896\tbest: 0.0543330 (49)\ttotal: 363ms\tremaining: 53.8s\n",
      "67:\tlearn: 0.0383712\ttest: 0.0544361\tbest: 0.0543330 (49)\ttotal: 367ms\tremaining: 53.6s\n",
      "68:\tlearn: 0.0381514\ttest: 0.0543715\tbest: 0.0543330 (49)\ttotal: 371ms\tremaining: 53.4s\n",
      "69:\tlearn: 0.0377761\ttest: 0.0544522\tbest: 0.0543330 (49)\ttotal: 375ms\tremaining: 53.1s\n",
      "70:\tlearn: 0.0375423\ttest: 0.0544314\tbest: 0.0543330 (49)\ttotal: 378ms\tremaining: 52.9s\n",
      "71:\tlearn: 0.0373386\ttest: 0.0544384\tbest: 0.0543330 (49)\ttotal: 382ms\tremaining: 52.7s\n",
      "72:\tlearn: 0.0371491\ttest: 0.0543967\tbest: 0.0543330 (49)\ttotal: 386ms\tremaining: 52.5s\n",
      "73:\tlearn: 0.0369304\ttest: 0.0544164\tbest: 0.0543330 (49)\ttotal: 390ms\tremaining: 52.3s\n",
      "74:\tlearn: 0.0366065\ttest: 0.0544302\tbest: 0.0543330 (49)\ttotal: 394ms\tremaining: 52.1s\n",
      "75:\tlearn: 0.0364503\ttest: 0.0543854\tbest: 0.0543330 (49)\ttotal: 397ms\tremaining: 51.9s\n",
      "76:\tlearn: 0.0362393\ttest: 0.0542859\tbest: 0.0542859 (76)\ttotal: 401ms\tremaining: 51.7s\n",
      "77:\tlearn: 0.0360944\ttest: 0.0542149\tbest: 0.0542149 (77)\ttotal: 404ms\tremaining: 51.5s\n",
      "78:\tlearn: 0.0358529\ttest: 0.0542719\tbest: 0.0542149 (77)\ttotal: 409ms\tremaining: 51.3s\n",
      "79:\tlearn: 0.0356883\ttest: 0.0543049\tbest: 0.0542149 (77)\ttotal: 412ms\tremaining: 51.1s\n",
      "80:\tlearn: 0.0353943\ttest: 0.0541788\tbest: 0.0541788 (80)\ttotal: 418ms\tremaining: 51.2s\n",
      "81:\tlearn: 0.0352199\ttest: 0.0541945\tbest: 0.0541788 (80)\ttotal: 424ms\tremaining: 51.3s\n",
      "82:\tlearn: 0.0350236\ttest: 0.0541676\tbest: 0.0541676 (82)\ttotal: 430ms\tremaining: 51.4s\n",
      "83:\tlearn: 0.0348705\ttest: 0.0542153\tbest: 0.0541676 (82)\ttotal: 436ms\tremaining: 51.5s\n",
      "84:\tlearn: 0.0345953\ttest: 0.0542468\tbest: 0.0541676 (82)\ttotal: 442ms\tremaining: 51.6s\n",
      "85:\tlearn: 0.0343008\ttest: 0.0542767\tbest: 0.0541676 (82)\ttotal: 448ms\tremaining: 51.7s\n",
      "86:\tlearn: 0.0341673\ttest: 0.0542376\tbest: 0.0541676 (82)\ttotal: 454ms\tremaining: 51.8s\n",
      "87:\tlearn: 0.0340143\ttest: 0.0541478\tbest: 0.0541478 (87)\ttotal: 460ms\tremaining: 51.9s\n",
      "88:\tlearn: 0.0339206\ttest: 0.0541039\tbest: 0.0541039 (88)\ttotal: 466ms\tremaining: 51.9s\n",
      "89:\tlearn: 0.0336995\ttest: 0.0541240\tbest: 0.0541039 (88)\ttotal: 472ms\tremaining: 51.9s\n",
      "90:\tlearn: 0.0335066\ttest: 0.0540871\tbest: 0.0540871 (90)\ttotal: 477ms\tremaining: 52s\n",
      "91:\tlearn: 0.0332580\ttest: 0.0540534\tbest: 0.0540534 (91)\ttotal: 482ms\tremaining: 52s\n",
      "92:\tlearn: 0.0330867\ttest: 0.0540753\tbest: 0.0540534 (91)\ttotal: 487ms\tremaining: 51.9s\n",
      "93:\tlearn: 0.0328869\ttest: 0.0540158\tbest: 0.0540158 (93)\ttotal: 492ms\tremaining: 51.9s\n",
      "94:\tlearn: 0.0327488\ttest: 0.0539626\tbest: 0.0539626 (94)\ttotal: 497ms\tremaining: 51.9s\n",
      "95:\tlearn: 0.0326477\ttest: 0.0539167\tbest: 0.0539167 (95)\ttotal: 502ms\tremaining: 51.8s\n",
      "96:\tlearn: 0.0325104\ttest: 0.0538518\tbest: 0.0538518 (96)\ttotal: 507ms\tremaining: 51.8s\n",
      "97:\tlearn: 0.0323551\ttest: 0.0537965\tbest: 0.0537965 (97)\ttotal: 512ms\tremaining: 51.7s\n",
      "98:\tlearn: 0.0322618\ttest: 0.0537602\tbest: 0.0537602 (98)\ttotal: 516ms\tremaining: 51.6s\n",
      "99:\tlearn: 0.0320156\ttest: 0.0538450\tbest: 0.0537602 (98)\ttotal: 521ms\tremaining: 51.6s\n",
      "100:\tlearn: 0.0317183\ttest: 0.0537776\tbest: 0.0537602 (98)\ttotal: 527ms\tremaining: 51.6s\n",
      "101:\tlearn: 0.0314515\ttest: 0.0537051\tbest: 0.0537051 (101)\ttotal: 532ms\tremaining: 51.7s\n",
      "102:\tlearn: 0.0312587\ttest: 0.0537106\tbest: 0.0537051 (101)\ttotal: 538ms\tremaining: 51.7s\n",
      "103:\tlearn: 0.0310617\ttest: 0.0536985\tbest: 0.0536985 (103)\ttotal: 543ms\tremaining: 51.7s\n",
      "104:\tlearn: 0.0309083\ttest: 0.0536708\tbest: 0.0536708 (104)\ttotal: 549ms\tremaining: 51.7s\n",
      "105:\tlearn: 0.0306836\ttest: 0.0536618\tbest: 0.0536618 (105)\ttotal: 554ms\tremaining: 51.7s\n",
      "106:\tlearn: 0.0305322\ttest: 0.0536220\tbest: 0.0536220 (106)\ttotal: 559ms\tremaining: 51.7s\n",
      "107:\tlearn: 0.0303225\ttest: 0.0536675\tbest: 0.0536220 (106)\ttotal: 564ms\tremaining: 51.7s\n",
      "108:\tlearn: 0.0301146\ttest: 0.0537125\tbest: 0.0536220 (106)\ttotal: 569ms\tremaining: 51.6s\n",
      "109:\tlearn: 0.0299556\ttest: 0.0536196\tbest: 0.0536196 (109)\ttotal: 574ms\tremaining: 51.6s\n",
      "110:\tlearn: 0.0298735\ttest: 0.0536139\tbest: 0.0536139 (110)\ttotal: 578ms\tremaining: 51.5s\n",
      "111:\tlearn: 0.0297243\ttest: 0.0536014\tbest: 0.0536014 (111)\ttotal: 583ms\tremaining: 51.5s\n",
      "112:\tlearn: 0.0295240\ttest: 0.0536020\tbest: 0.0536014 (111)\ttotal: 587ms\tremaining: 51.4s\n",
      "113:\tlearn: 0.0293040\ttest: 0.0536649\tbest: 0.0536014 (111)\ttotal: 592ms\tremaining: 51.3s\n",
      "114:\tlearn: 0.0290824\ttest: 0.0536433\tbest: 0.0536014 (111)\ttotal: 596ms\tremaining: 51.3s\n",
      "115:\tlearn: 0.0289406\ttest: 0.0536415\tbest: 0.0536014 (111)\ttotal: 601ms\tremaining: 51.2s\n",
      "116:\tlearn: 0.0287436\ttest: 0.0535675\tbest: 0.0535675 (116)\ttotal: 606ms\tremaining: 51.2s\n",
      "117:\tlearn: 0.0286054\ttest: 0.0535444\tbest: 0.0535444 (117)\ttotal: 610ms\tremaining: 51.1s\n",
      "118:\tlearn: 0.0284956\ttest: 0.0535396\tbest: 0.0535396 (118)\ttotal: 615ms\tremaining: 51s\n",
      "119:\tlearn: 0.0282874\ttest: 0.0535236\tbest: 0.0535236 (119)\ttotal: 619ms\tremaining: 51s\n",
      "120:\tlearn: 0.0280577\ttest: 0.0534432\tbest: 0.0534432 (120)\ttotal: 624ms\tremaining: 50.9s\n",
      "121:\tlearn: 0.0278181\ttest: 0.0534686\tbest: 0.0534432 (120)\ttotal: 629ms\tremaining: 50.9s\n",
      "122:\tlearn: 0.0276823\ttest: 0.0534307\tbest: 0.0534307 (122)\ttotal: 635ms\tremaining: 51s\n",
      "123:\tlearn: 0.0274446\ttest: 0.0534582\tbest: 0.0534307 (122)\ttotal: 641ms\tremaining: 51s\n",
      "124:\tlearn: 0.0271966\ttest: 0.0533853\tbest: 0.0533853 (124)\ttotal: 646ms\tremaining: 51.1s\n",
      "125:\tlearn: 0.0270160\ttest: 0.0533808\tbest: 0.0533808 (125)\ttotal: 652ms\tremaining: 51.1s\n",
      "126:\tlearn: 0.0267744\ttest: 0.0533219\tbest: 0.0533219 (126)\ttotal: 658ms\tremaining: 51.1s\n",
      "127:\tlearn: 0.0266424\ttest: 0.0532875\tbest: 0.0532875 (127)\ttotal: 663ms\tremaining: 51.2s\n",
      "128:\tlearn: 0.0264973\ttest: 0.0532811\tbest: 0.0532811 (128)\ttotal: 669ms\tremaining: 51.2s\n",
      "129:\tlearn: 0.0262968\ttest: 0.0532122\tbest: 0.0532122 (129)\ttotal: 675ms\tremaining: 51.2s\n",
      "130:\tlearn: 0.0261561\ttest: 0.0532326\tbest: 0.0532122 (129)\ttotal: 680ms\tremaining: 51.2s\n",
      "131:\tlearn: 0.0259538\ttest: 0.0532697\tbest: 0.0532122 (129)\ttotal: 686ms\tremaining: 51.3s\n",
      "132:\tlearn: 0.0257612\ttest: 0.0532907\tbest: 0.0532122 (129)\ttotal: 691ms\tremaining: 51.3s\n",
      "133:\tlearn: 0.0254943\ttest: 0.0532955\tbest: 0.0532122 (129)\ttotal: 696ms\tremaining: 51.3s\n",
      "134:\tlearn: 0.0253470\ttest: 0.0533592\tbest: 0.0532122 (129)\ttotal: 701ms\tremaining: 51.2s\n",
      "135:\tlearn: 0.0252903\ttest: 0.0533542\tbest: 0.0532122 (129)\ttotal: 706ms\tremaining: 51.2s\n",
      "136:\tlearn: 0.0252177\ttest: 0.0533808\tbest: 0.0532122 (129)\ttotal: 711ms\tremaining: 51.2s\n",
      "137:\tlearn: 0.0250823\ttest: 0.0533617\tbest: 0.0532122 (129)\ttotal: 716ms\tremaining: 51.1s\n",
      "138:\tlearn: 0.0249188\ttest: 0.0534074\tbest: 0.0532122 (129)\ttotal: 720ms\tremaining: 51.1s\n",
      "139:\tlearn: 0.0247777\ttest: 0.0533477\tbest: 0.0532122 (129)\ttotal: 725ms\tremaining: 51.1s\n",
      "140:\tlearn: 0.0246320\ttest: 0.0533761\tbest: 0.0532122 (129)\ttotal: 729ms\tremaining: 51s\n",
      "141:\tlearn: 0.0243353\ttest: 0.0532970\tbest: 0.0532122 (129)\ttotal: 734ms\tremaining: 51s\n",
      "142:\tlearn: 0.0242119\ttest: 0.0532670\tbest: 0.0532122 (129)\ttotal: 738ms\tremaining: 50.9s\n",
      "143:\tlearn: 0.0240465\ttest: 0.0532457\tbest: 0.0532122 (129)\ttotal: 743ms\tremaining: 50.9s\n",
      "144:\tlearn: 0.0238662\ttest: 0.0533450\tbest: 0.0532122 (129)\ttotal: 747ms\tremaining: 50.8s\n",
      "145:\tlearn: 0.0236505\ttest: 0.0533006\tbest: 0.0532122 (129)\ttotal: 752ms\tremaining: 50.8s\n",
      "146:\tlearn: 0.0234356\ttest: 0.0532675\tbest: 0.0532122 (129)\ttotal: 756ms\tremaining: 50.7s\n",
      "147:\tlearn: 0.0232853\ttest: 0.0532705\tbest: 0.0532122 (129)\ttotal: 761ms\tremaining: 50.6s\n",
      "148:\tlearn: 0.0231076\ttest: 0.0532515\tbest: 0.0532122 (129)\ttotal: 765ms\tremaining: 50.6s\n",
      "149:\tlearn: 0.0229177\ttest: 0.0532236\tbest: 0.0532122 (129)\ttotal: 769ms\tremaining: 50.5s\n",
      "150:\tlearn: 0.0228461\ttest: 0.0532174\tbest: 0.0532122 (129)\ttotal: 773ms\tremaining: 50.4s\n",
      "151:\tlearn: 0.0226796\ttest: 0.0532375\tbest: 0.0532122 (129)\ttotal: 777ms\tremaining: 50.4s\n",
      "152:\tlearn: 0.0224727\ttest: 0.0532231\tbest: 0.0532122 (129)\ttotal: 781ms\tremaining: 50.3s\n",
      "153:\tlearn: 0.0223049\ttest: 0.0531835\tbest: 0.0531835 (153)\ttotal: 785ms\tremaining: 50.2s\n",
      "154:\tlearn: 0.0221470\ttest: 0.0531978\tbest: 0.0531835 (153)\ttotal: 789ms\tremaining: 50.1s\n",
      "155:\tlearn: 0.0219221\ttest: 0.0532136\tbest: 0.0531835 (153)\ttotal: 793ms\tremaining: 50.1s\n",
      "156:\tlearn: 0.0217675\ttest: 0.0532365\tbest: 0.0531835 (153)\ttotal: 797ms\tremaining: 50s\n",
      "157:\tlearn: 0.0215891\ttest: 0.0532095\tbest: 0.0531835 (153)\ttotal: 801ms\tremaining: 49.9s\n",
      "158:\tlearn: 0.0215103\ttest: 0.0531895\tbest: 0.0531835 (153)\ttotal: 805ms\tremaining: 49.9s\n",
      "159:\tlearn: 0.0213961\ttest: 0.0531906\tbest: 0.0531835 (153)\ttotal: 810ms\tremaining: 49.8s\n",
      "160:\tlearn: 0.0211989\ttest: 0.0532053\tbest: 0.0531835 (153)\ttotal: 813ms\tremaining: 49.7s\n",
      "161:\tlearn: 0.0210623\ttest: 0.0531577\tbest: 0.0531577 (161)\ttotal: 817ms\tremaining: 49.6s\n",
      "162:\tlearn: 0.0209240\ttest: 0.0531410\tbest: 0.0531410 (162)\ttotal: 822ms\tremaining: 49.6s\n",
      "163:\tlearn: 0.0208807\ttest: 0.0531533\tbest: 0.0531410 (162)\ttotal: 826ms\tremaining: 49.6s\n",
      "164:\tlearn: 0.0207246\ttest: 0.0531441\tbest: 0.0531410 (162)\ttotal: 831ms\tremaining: 49.5s\n",
      "165:\tlearn: 0.0206739\ttest: 0.0531431\tbest: 0.0531410 (162)\ttotal: 835ms\tremaining: 49.5s\n",
      "166:\tlearn: 0.0206271\ttest: 0.0531700\tbest: 0.0531410 (162)\ttotal: 839ms\tremaining: 49.4s\n",
      "167:\tlearn: 0.0204411\ttest: 0.0531531\tbest: 0.0531410 (162)\ttotal: 844ms\tremaining: 49.4s\n",
      "168:\tlearn: 0.0202817\ttest: 0.0531540\tbest: 0.0531410 (162)\ttotal: 848ms\tremaining: 49.3s\n",
      "169:\tlearn: 0.0200867\ttest: 0.0531322\tbest: 0.0531322 (169)\ttotal: 852ms\tremaining: 49.3s\n",
      "170:\tlearn: 0.0200205\ttest: 0.0531170\tbest: 0.0531170 (170)\ttotal: 856ms\tremaining: 49.2s\n",
      "171:\tlearn: 0.0197795\ttest: 0.0530959\tbest: 0.0530959 (171)\ttotal: 861ms\tremaining: 49.2s\n",
      "172:\tlearn: 0.0196168\ttest: 0.0530246\tbest: 0.0530246 (172)\ttotal: 866ms\tremaining: 49.2s\n",
      "173:\tlearn: 0.0194385\ttest: 0.0530666\tbest: 0.0530246 (172)\ttotal: 874ms\tremaining: 49.4s\n",
      "174:\tlearn: 0.0193311\ttest: 0.0529786\tbest: 0.0529786 (174)\ttotal: 882ms\tremaining: 49.5s\n",
      "175:\tlearn: 0.0192149\ttest: 0.0529506\tbest: 0.0529506 (175)\ttotal: 890ms\tremaining: 49.7s\n",
      "176:\tlearn: 0.0190363\ttest: 0.0529385\tbest: 0.0529385 (176)\ttotal: 897ms\tremaining: 49.8s\n",
      "177:\tlearn: 0.0188655\ttest: 0.0529207\tbest: 0.0529207 (177)\ttotal: 904ms\tremaining: 49.9s\n",
      "178:\tlearn: 0.0187186\ttest: 0.0528600\tbest: 0.0528600 (178)\ttotal: 912ms\tremaining: 50s\n",
      "179:\tlearn: 0.0185590\ttest: 0.0527994\tbest: 0.0527994 (179)\ttotal: 918ms\tremaining: 50.1s\n",
      "180:\tlearn: 0.0184188\ttest: 0.0527535\tbest: 0.0527535 (180)\ttotal: 925ms\tremaining: 50.2s\n",
      "181:\tlearn: 0.0182743\ttest: 0.0527685\tbest: 0.0527535 (180)\ttotal: 931ms\tremaining: 50.2s\n",
      "182:\tlearn: 0.0182074\ttest: 0.0527784\tbest: 0.0527535 (180)\ttotal: 937ms\tremaining: 50.3s\n",
      "183:\tlearn: 0.0180254\ttest: 0.0528386\tbest: 0.0527535 (180)\ttotal: 943ms\tremaining: 50.3s\n",
      "184:\tlearn: 0.0178516\ttest: 0.0527948\tbest: 0.0527535 (180)\ttotal: 949ms\tremaining: 50.3s\n",
      "185:\tlearn: 0.0177012\ttest: 0.0527756\tbest: 0.0527535 (180)\ttotal: 954ms\tremaining: 50.4s\n",
      "186:\tlearn: 0.0175329\ttest: 0.0526858\tbest: 0.0526858 (186)\ttotal: 960ms\tremaining: 50.4s\n",
      "187:\tlearn: 0.0173980\ttest: 0.0527121\tbest: 0.0526858 (186)\ttotal: 965ms\tremaining: 50.4s\n",
      "188:\tlearn: 0.0172570\ttest: 0.0526920\tbest: 0.0526858 (186)\ttotal: 970ms\tremaining: 50.3s\n",
      "189:\tlearn: 0.0172102\ttest: 0.0526812\tbest: 0.0526812 (189)\ttotal: 975ms\tremaining: 50.3s\n",
      "190:\tlearn: 0.0170711\ttest: 0.0526433\tbest: 0.0526433 (190)\ttotal: 979ms\tremaining: 50.3s\n",
      "191:\tlearn: 0.0169595\ttest: 0.0526136\tbest: 0.0526136 (191)\ttotal: 984ms\tremaining: 50.3s\n",
      "192:\tlearn: 0.0168626\ttest: 0.0525744\tbest: 0.0525744 (192)\ttotal: 989ms\tremaining: 50.3s\n",
      "193:\tlearn: 0.0167134\ttest: 0.0525764\tbest: 0.0525744 (192)\ttotal: 994ms\tremaining: 50.2s\n",
      "194:\tlearn: 0.0166705\ttest: 0.0525908\tbest: 0.0525744 (192)\ttotal: 999ms\tremaining: 50.3s\n",
      "195:\tlearn: 0.0165846\ttest: 0.0525697\tbest: 0.0525697 (195)\ttotal: 1s\tremaining: 50.2s\n",
      "196:\tlearn: 0.0165535\ttest: 0.0525916\tbest: 0.0525697 (195)\ttotal: 1.01s\tremaining: 50.2s\n",
      "197:\tlearn: 0.0165206\ttest: 0.0526003\tbest: 0.0525697 (195)\ttotal: 1.01s\tremaining: 50.2s\n",
      "198:\tlearn: 0.0164771\ttest: 0.0526031\tbest: 0.0525697 (195)\ttotal: 1.02s\tremaining: 50.1s\n",
      "199:\tlearn: 0.0163263\ttest: 0.0525974\tbest: 0.0525697 (195)\ttotal: 1.02s\tremaining: 50.1s\n",
      "200:\tlearn: 0.0161565\ttest: 0.0525568\tbest: 0.0525568 (200)\ttotal: 1.03s\tremaining: 50.1s\n",
      "201:\tlearn: 0.0159863\ttest: 0.0524265\tbest: 0.0524265 (201)\ttotal: 1.03s\tremaining: 50.1s\n",
      "202:\tlearn: 0.0159482\ttest: 0.0524279\tbest: 0.0524265 (201)\ttotal: 1.04s\tremaining: 50.1s\n",
      "203:\tlearn: 0.0158386\ttest: 0.0523968\tbest: 0.0523968 (203)\ttotal: 1.04s\tremaining: 50.1s\n",
      "204:\tlearn: 0.0156790\ttest: 0.0523671\tbest: 0.0523671 (204)\ttotal: 1.05s\tremaining: 50s\n",
      "205:\tlearn: 0.0155456\ttest: 0.0523515\tbest: 0.0523515 (205)\ttotal: 1.05s\tremaining: 50s\n",
      "206:\tlearn: 0.0154334\ttest: 0.0523529\tbest: 0.0523515 (205)\ttotal: 1.06s\tremaining: 50s\n",
      "207:\tlearn: 0.0152658\ttest: 0.0523802\tbest: 0.0523515 (205)\ttotal: 1.06s\tremaining: 50s\n",
      "208:\tlearn: 0.0151451\ttest: 0.0524019\tbest: 0.0523515 (205)\ttotal: 1.06s\tremaining: 49.9s\n",
      "209:\tlearn: 0.0150584\ttest: 0.0524188\tbest: 0.0523515 (205)\ttotal: 1.07s\tremaining: 49.9s\n",
      "210:\tlearn: 0.0149076\ttest: 0.0523614\tbest: 0.0523515 (205)\ttotal: 1.07s\tremaining: 49.9s\n",
      "211:\tlearn: 0.0147901\ttest: 0.0523436\tbest: 0.0523436 (211)\ttotal: 1.08s\tremaining: 49.8s\n",
      "212:\tlearn: 0.0146667\ttest: 0.0523189\tbest: 0.0523189 (212)\ttotal: 1.08s\tremaining: 49.8s\n",
      "213:\tlearn: 0.0146337\ttest: 0.0523125\tbest: 0.0523125 (213)\ttotal: 1.09s\tremaining: 49.7s\n",
      "214:\tlearn: 0.0146006\ttest: 0.0523172\tbest: 0.0523125 (213)\ttotal: 1.09s\tremaining: 49.7s\n",
      "215:\tlearn: 0.0144577\ttest: 0.0523193\tbest: 0.0523125 (213)\ttotal: 1.1s\tremaining: 49.7s\n",
      "216:\tlearn: 0.0143889\ttest: 0.0523137\tbest: 0.0523125 (213)\ttotal: 1.1s\tremaining: 49.6s\n",
      "217:\tlearn: 0.0142735\ttest: 0.0523416\tbest: 0.0523125 (213)\ttotal: 1.1s\tremaining: 49.6s\n",
      "218:\tlearn: 0.0141249\ttest: 0.0523015\tbest: 0.0523015 (218)\ttotal: 1.11s\tremaining: 49.5s\n",
      "219:\tlearn: 0.0139714\ttest: 0.0522830\tbest: 0.0522830 (219)\ttotal: 1.11s\tremaining: 49.5s\n",
      "220:\tlearn: 0.0139044\ttest: 0.0523124\tbest: 0.0522830 (219)\ttotal: 1.12s\tremaining: 49.4s\n",
      "221:\tlearn: 0.0137526\ttest: 0.0523272\tbest: 0.0522830 (219)\ttotal: 1.12s\tremaining: 49.4s\n",
      "222:\tlearn: 0.0135912\ttest: 0.0523368\tbest: 0.0522830 (219)\ttotal: 1.13s\tremaining: 49.4s\n",
      "223:\tlearn: 0.0135664\ttest: 0.0523477\tbest: 0.0522830 (219)\ttotal: 1.13s\tremaining: 49.3s\n",
      "224:\tlearn: 0.0134717\ttest: 0.0523555\tbest: 0.0522830 (219)\ttotal: 1.13s\tremaining: 49.3s\n",
      "225:\tlearn: 0.0133700\ttest: 0.0523354\tbest: 0.0522830 (219)\ttotal: 1.14s\tremaining: 49.3s\n",
      "226:\tlearn: 0.0132350\ttest: 0.0523126\tbest: 0.0522830 (219)\ttotal: 1.14s\tremaining: 49.2s\n",
      "227:\tlearn: 0.0131417\ttest: 0.0523175\tbest: 0.0522830 (219)\ttotal: 1.15s\tremaining: 49.2s\n",
      "228:\tlearn: 0.0130258\ttest: 0.0522851\tbest: 0.0522830 (219)\ttotal: 1.15s\tremaining: 49.1s\n",
      "229:\tlearn: 0.0130083\ttest: 0.0522817\tbest: 0.0522817 (229)\ttotal: 1.16s\tremaining: 49.1s\n",
      "230:\tlearn: 0.0129121\ttest: 0.0522844\tbest: 0.0522817 (229)\ttotal: 1.16s\tremaining: 49s\n",
      "231:\tlearn: 0.0128148\ttest: 0.0522852\tbest: 0.0522817 (229)\ttotal: 1.16s\tremaining: 49s\n",
      "232:\tlearn: 0.0127463\ttest: 0.0522733\tbest: 0.0522733 (232)\ttotal: 1.17s\tremaining: 48.9s\n",
      "233:\tlearn: 0.0127150\ttest: 0.0522701\tbest: 0.0522701 (233)\ttotal: 1.17s\tremaining: 48.9s\n",
      "234:\tlearn: 0.0126214\ttest: 0.0522626\tbest: 0.0522626 (234)\ttotal: 1.18s\tremaining: 48.8s\n",
      "235:\tlearn: 0.0124932\ttest: 0.0522852\tbest: 0.0522626 (234)\ttotal: 1.18s\tremaining: 48.8s\n",
      "236:\tlearn: 0.0123623\ttest: 0.0522923\tbest: 0.0522626 (234)\ttotal: 1.18s\tremaining: 48.8s\n",
      "237:\tlearn: 0.0122371\ttest: 0.0522634\tbest: 0.0522626 (234)\ttotal: 1.19s\tremaining: 48.8s\n",
      "238:\tlearn: 0.0120936\ttest: 0.0522258\tbest: 0.0522258 (238)\ttotal: 1.2s\tremaining: 48.8s\n",
      "239:\tlearn: 0.0119832\ttest: 0.0521869\tbest: 0.0521869 (239)\ttotal: 1.2s\tremaining: 48.9s\n",
      "240:\tlearn: 0.0119243\ttest: 0.0521764\tbest: 0.0521764 (240)\ttotal: 1.21s\tremaining: 48.9s\n",
      "241:\tlearn: 0.0118082\ttest: 0.0521321\tbest: 0.0521321 (241)\ttotal: 1.21s\tremaining: 48.9s\n",
      "242:\tlearn: 0.0117273\ttest: 0.0521111\tbest: 0.0521111 (242)\ttotal: 1.22s\tremaining: 48.9s\n",
      "243:\tlearn: 0.0116871\ttest: 0.0521214\tbest: 0.0521111 (242)\ttotal: 1.22s\tremaining: 48.9s\n",
      "244:\tlearn: 0.0115866\ttest: 0.0521338\tbest: 0.0521111 (242)\ttotal: 1.23s\tremaining: 48.9s\n",
      "245:\tlearn: 0.0114943\ttest: 0.0521018\tbest: 0.0521018 (245)\ttotal: 1.23s\tremaining: 48.9s\n",
      "246:\tlearn: 0.0114625\ttest: 0.0521112\tbest: 0.0521018 (245)\ttotal: 1.24s\tremaining: 48.9s\n",
      "247:\tlearn: 0.0113899\ttest: 0.0520916\tbest: 0.0520916 (247)\ttotal: 1.24s\tremaining: 48.9s\n",
      "248:\tlearn: 0.0112567\ttest: 0.0520880\tbest: 0.0520880 (248)\ttotal: 1.25s\tremaining: 48.9s\n",
      "249:\tlearn: 0.0111423\ttest: 0.0521067\tbest: 0.0520880 (248)\ttotal: 1.25s\tremaining: 48.9s\n",
      "250:\tlearn: 0.0110777\ttest: 0.0520901\tbest: 0.0520880 (248)\ttotal: 1.26s\tremaining: 48.9s\n",
      "251:\tlearn: 0.0109784\ttest: 0.0520863\tbest: 0.0520863 (251)\ttotal: 1.26s\tremaining: 48.9s\n",
      "252:\tlearn: 0.0109628\ttest: 0.0520863\tbest: 0.0520863 (252)\ttotal: 1.27s\tremaining: 48.9s\n",
      "253:\tlearn: 0.0108581\ttest: 0.0520800\tbest: 0.0520800 (253)\ttotal: 1.27s\tremaining: 48.9s\n",
      "254:\tlearn: 0.0108074\ttest: 0.0520654\tbest: 0.0520654 (254)\ttotal: 1.28s\tremaining: 48.9s\n",
      "255:\tlearn: 0.0107955\ttest: 0.0520717\tbest: 0.0520654 (254)\ttotal: 1.28s\tremaining: 48.8s\n",
      "256:\tlearn: 0.0107170\ttest: 0.0520535\tbest: 0.0520535 (256)\ttotal: 1.29s\tremaining: 48.8s\n",
      "257:\tlearn: 0.0106508\ttest: 0.0520905\tbest: 0.0520535 (256)\ttotal: 1.29s\tremaining: 48.8s\n",
      "258:\tlearn: 0.0105819\ttest: 0.0520812\tbest: 0.0520535 (256)\ttotal: 1.3s\tremaining: 48.8s\n",
      "259:\tlearn: 0.0105579\ttest: 0.0520788\tbest: 0.0520535 (256)\ttotal: 1.3s\tremaining: 48.8s\n",
      "260:\tlearn: 0.0104888\ttest: 0.0521001\tbest: 0.0520535 (256)\ttotal: 1.31s\tremaining: 48.8s\n",
      "261:\tlearn: 0.0104230\ttest: 0.0520968\tbest: 0.0520535 (256)\ttotal: 1.31s\tremaining: 48.8s\n",
      "262:\tlearn: 0.0103444\ttest: 0.0521065\tbest: 0.0520535 (256)\ttotal: 1.32s\tremaining: 48.8s\n",
      "263:\tlearn: 0.0102441\ttest: 0.0521051\tbest: 0.0520535 (256)\ttotal: 1.32s\tremaining: 48.8s\n",
      "264:\tlearn: 0.0101703\ttest: 0.0521020\tbest: 0.0520535 (256)\ttotal: 1.33s\tremaining: 48.8s\n",
      "265:\tlearn: 0.0101542\ttest: 0.0521073\tbest: 0.0520535 (256)\ttotal: 1.33s\tremaining: 48.8s\n",
      "266:\tlearn: 0.0100987\ttest: 0.0520731\tbest: 0.0520535 (256)\ttotal: 1.34s\tremaining: 48.8s\n",
      "267:\tlearn: 0.0100489\ttest: 0.0520924\tbest: 0.0520535 (256)\ttotal: 1.34s\tremaining: 48.8s\n",
      "268:\tlearn: 0.0099698\ttest: 0.0521163\tbest: 0.0520535 (256)\ttotal: 1.35s\tremaining: 48.7s\n",
      "269:\tlearn: 0.0099274\ttest: 0.0521120\tbest: 0.0520535 (256)\ttotal: 1.35s\tremaining: 48.7s\n",
      "270:\tlearn: 0.0099001\ttest: 0.0521161\tbest: 0.0520535 (256)\ttotal: 1.36s\tremaining: 48.7s\n",
      "271:\tlearn: 0.0097999\ttest: 0.0521231\tbest: 0.0520535 (256)\ttotal: 1.36s\tremaining: 48.7s\n",
      "272:\tlearn: 0.0097071\ttest: 0.0520985\tbest: 0.0520535 (256)\ttotal: 1.37s\tremaining: 48.7s\n",
      "273:\tlearn: 0.0096214\ttest: 0.0521147\tbest: 0.0520535 (256)\ttotal: 1.37s\tremaining: 48.7s\n",
      "274:\tlearn: 0.0095554\ttest: 0.0520952\tbest: 0.0520535 (256)\ttotal: 1.38s\tremaining: 48.7s\n",
      "275:\tlearn: 0.0095082\ttest: 0.0520997\tbest: 0.0520535 (256)\ttotal: 1.38s\tremaining: 48.7s\n",
      "276:\tlearn: 0.0094834\ttest: 0.0521159\tbest: 0.0520535 (256)\ttotal: 1.39s\tremaining: 48.7s\n",
      "277:\tlearn: 0.0093831\ttest: 0.0521099\tbest: 0.0520535 (256)\ttotal: 1.39s\tremaining: 48.7s\n",
      "278:\tlearn: 0.0093588\ttest: 0.0521113\tbest: 0.0520535 (256)\ttotal: 1.4s\tremaining: 48.7s\n",
      "279:\tlearn: 0.0092765\ttest: 0.0520949\tbest: 0.0520535 (256)\ttotal: 1.4s\tremaining: 48.7s\n",
      "280:\tlearn: 0.0091949\ttest: 0.0520930\tbest: 0.0520535 (256)\ttotal: 1.41s\tremaining: 48.7s\n",
      "281:\tlearn: 0.0091276\ttest: 0.0520898\tbest: 0.0520535 (256)\ttotal: 1.41s\tremaining: 48.7s\n",
      "282:\tlearn: 0.0090551\ttest: 0.0520802\tbest: 0.0520535 (256)\ttotal: 1.42s\tremaining: 48.7s\n",
      "283:\tlearn: 0.0089761\ttest: 0.0520959\tbest: 0.0520535 (256)\ttotal: 1.42s\tremaining: 48.7s\n",
      "284:\tlearn: 0.0088935\ttest: 0.0520662\tbest: 0.0520535 (256)\ttotal: 1.43s\tremaining: 48.7s\n",
      "285:\tlearn: 0.0088344\ttest: 0.0520678\tbest: 0.0520535 (256)\ttotal: 1.43s\tremaining: 48.7s\n",
      "286:\tlearn: 0.0087905\ttest: 0.0520563\tbest: 0.0520535 (256)\ttotal: 1.44s\tremaining: 48.7s\n",
      "287:\tlearn: 0.0087405\ttest: 0.0520362\tbest: 0.0520362 (287)\ttotal: 1.44s\tremaining: 48.7s\n",
      "288:\tlearn: 0.0087182\ttest: 0.0520285\tbest: 0.0520285 (288)\ttotal: 1.45s\tremaining: 48.7s\n",
      "289:\tlearn: 0.0086777\ttest: 0.0520266\tbest: 0.0520266 (289)\ttotal: 1.46s\tremaining: 48.8s\n",
      "290:\tlearn: 0.0086225\ttest: 0.0520000\tbest: 0.0520000 (290)\ttotal: 1.46s\tremaining: 48.8s\n",
      "291:\tlearn: 0.0085397\ttest: 0.0519821\tbest: 0.0519821 (291)\ttotal: 1.47s\tremaining: 48.8s\n",
      "292:\tlearn: 0.0084769\ttest: 0.0519854\tbest: 0.0519821 (291)\ttotal: 1.47s\tremaining: 48.8s\n",
      "293:\tlearn: 0.0084032\ttest: 0.0519695\tbest: 0.0519695 (293)\ttotal: 1.48s\tremaining: 48.9s\n",
      "294:\tlearn: 0.0083331\ttest: 0.0519391\tbest: 0.0519391 (294)\ttotal: 1.49s\tremaining: 48.9s\n",
      "295:\tlearn: 0.0082412\ttest: 0.0519445\tbest: 0.0519391 (294)\ttotal: 1.49s\tremaining: 48.9s\n",
      "296:\tlearn: 0.0081611\ttest: 0.0519295\tbest: 0.0519295 (296)\ttotal: 1.5s\tremaining: 49s\n",
      "297:\tlearn: 0.0081142\ttest: 0.0519101\tbest: 0.0519101 (297)\ttotal: 1.5s\tremaining: 49s\n",
      "298:\tlearn: 0.0080475\ttest: 0.0519041\tbest: 0.0519041 (298)\ttotal: 1.51s\tremaining: 49s\n",
      "299:\tlearn: 0.0079726\ttest: 0.0519040\tbest: 0.0519040 (299)\ttotal: 1.52s\tremaining: 49s\n",
      "300:\tlearn: 0.0079206\ttest: 0.0518815\tbest: 0.0518815 (300)\ttotal: 1.52s\tremaining: 49s\n",
      "301:\tlearn: 0.0079011\ttest: 0.0518791\tbest: 0.0518791 (301)\ttotal: 1.53s\tremaining: 49.1s\n",
      "302:\tlearn: 0.0078895\ttest: 0.0518829\tbest: 0.0518791 (301)\ttotal: 1.53s\tremaining: 49.1s\n",
      "303:\tlearn: 0.0078337\ttest: 0.0518748\tbest: 0.0518748 (303)\ttotal: 1.54s\tremaining: 49.1s\n",
      "304:\tlearn: 0.0077758\ttest: 0.0518508\tbest: 0.0518508 (304)\ttotal: 1.54s\tremaining: 49.1s\n",
      "305:\tlearn: 0.0076986\ttest: 0.0518161\tbest: 0.0518161 (305)\ttotal: 1.55s\tremaining: 49.1s\n",
      "306:\tlearn: 0.0076885\ttest: 0.0518160\tbest: 0.0518160 (306)\ttotal: 1.55s\tremaining: 49.1s\n",
      "307:\tlearn: 0.0076216\ttest: 0.0518090\tbest: 0.0518090 (307)\ttotal: 1.56s\tremaining: 49.1s\n",
      "308:\tlearn: 0.0075754\ttest: 0.0517890\tbest: 0.0517890 (308)\ttotal: 1.57s\tremaining: 49.1s\n",
      "309:\tlearn: 0.0075445\ttest: 0.0517897\tbest: 0.0517890 (308)\ttotal: 1.57s\tremaining: 49.1s\n",
      "310:\tlearn: 0.0074802\ttest: 0.0517920\tbest: 0.0517890 (308)\ttotal: 1.58s\tremaining: 49.1s\n",
      "311:\tlearn: 0.0074438\ttest: 0.0517910\tbest: 0.0517890 (308)\ttotal: 1.58s\tremaining: 49.1s\n",
      "312:\tlearn: 0.0074275\ttest: 0.0517940\tbest: 0.0517890 (308)\ttotal: 1.59s\tremaining: 49.1s\n",
      "313:\tlearn: 0.0073680\ttest: 0.0517927\tbest: 0.0517890 (308)\ttotal: 1.59s\tremaining: 49.1s\n",
      "314:\tlearn: 0.0073019\ttest: 0.0517986\tbest: 0.0517890 (308)\ttotal: 1.6s\tremaining: 49.1s\n",
      "315:\tlearn: 0.0072499\ttest: 0.0517698\tbest: 0.0517698 (315)\ttotal: 1.6s\tremaining: 49.1s\n",
      "316:\tlearn: 0.0071875\ttest: 0.0517486\tbest: 0.0517486 (316)\ttotal: 1.6s\tremaining: 49s\n",
      "317:\tlearn: 0.0071442\ttest: 0.0517512\tbest: 0.0517486 (316)\ttotal: 1.61s\tremaining: 49s\n",
      "318:\tlearn: 0.0070706\ttest: 0.0517534\tbest: 0.0517486 (316)\ttotal: 1.61s\tremaining: 49s\n",
      "319:\tlearn: 0.0069910\ttest: 0.0517580\tbest: 0.0517486 (316)\ttotal: 1.62s\tremaining: 49s\n",
      "320:\tlearn: 0.0069819\ttest: 0.0517565\tbest: 0.0517486 (316)\ttotal: 1.62s\tremaining: 48.9s\n",
      "321:\tlearn: 0.0069273\ttest: 0.0517676\tbest: 0.0517486 (316)\ttotal: 1.63s\tremaining: 48.9s\n",
      "322:\tlearn: 0.0068687\ttest: 0.0517767\tbest: 0.0517486 (316)\ttotal: 1.63s\tremaining: 48.8s\n",
      "323:\tlearn: 0.0067967\ttest: 0.0517675\tbest: 0.0517486 (316)\ttotal: 1.63s\tremaining: 48.8s\n",
      "324:\tlearn: 0.0067874\ttest: 0.0517735\tbest: 0.0517486 (316)\ttotal: 1.64s\tremaining: 48.8s\n",
      "325:\tlearn: 0.0067292\ttest: 0.0517633\tbest: 0.0517486 (316)\ttotal: 1.64s\tremaining: 48.7s\n",
      "326:\tlearn: 0.0066790\ttest: 0.0517549\tbest: 0.0517486 (316)\ttotal: 1.65s\tremaining: 48.7s\n",
      "327:\tlearn: 0.0066352\ttest: 0.0517557\tbest: 0.0517486 (316)\ttotal: 1.65s\tremaining: 48.7s\n",
      "328:\tlearn: 0.0066196\ttest: 0.0517530\tbest: 0.0517486 (316)\ttotal: 1.65s\tremaining: 48.6s\n",
      "329:\tlearn: 0.0065607\ttest: 0.0517528\tbest: 0.0517486 (316)\ttotal: 1.66s\tremaining: 48.6s\n",
      "330:\tlearn: 0.0064853\ttest: 0.0517261\tbest: 0.0517261 (330)\ttotal: 1.66s\tremaining: 48.5s\n",
      "331:\tlearn: 0.0064506\ttest: 0.0517160\tbest: 0.0517160 (331)\ttotal: 1.67s\tremaining: 48.5s\n",
      "332:\tlearn: 0.0064125\ttest: 0.0517166\tbest: 0.0517160 (331)\ttotal: 1.67s\tremaining: 48.5s\n",
      "333:\tlearn: 0.0063956\ttest: 0.0517111\tbest: 0.0517111 (333)\ttotal: 1.67s\tremaining: 48.4s\n",
      "334:\tlearn: 0.0063452\ttest: 0.0517227\tbest: 0.0517111 (333)\ttotal: 1.68s\tremaining: 48.4s\n",
      "335:\tlearn: 0.0063287\ttest: 0.0517209\tbest: 0.0517111 (333)\ttotal: 1.68s\tremaining: 48.4s\n",
      "336:\tlearn: 0.0063144\ttest: 0.0517282\tbest: 0.0517111 (333)\ttotal: 1.69s\tremaining: 48.4s\n",
      "337:\tlearn: 0.0062667\ttest: 0.0517250\tbest: 0.0517111 (333)\ttotal: 1.69s\tremaining: 48.4s\n",
      "338:\tlearn: 0.0062386\ttest: 0.0517318\tbest: 0.0517111 (333)\ttotal: 1.7s\tremaining: 48.4s\n",
      "339:\tlearn: 0.0061973\ttest: 0.0517242\tbest: 0.0517111 (333)\ttotal: 1.71s\tremaining: 48.5s\n",
      "340:\tlearn: 0.0061384\ttest: 0.0517323\tbest: 0.0517111 (333)\ttotal: 1.71s\tremaining: 48.5s\n",
      "341:\tlearn: 0.0060862\ttest: 0.0517328\tbest: 0.0517111 (333)\ttotal: 1.72s\tremaining: 48.5s\n",
      "342:\tlearn: 0.0060194\ttest: 0.0517265\tbest: 0.0517111 (333)\ttotal: 1.72s\tremaining: 48.5s\n",
      "343:\tlearn: 0.0059783\ttest: 0.0517354\tbest: 0.0517111 (333)\ttotal: 1.73s\tremaining: 48.5s\n",
      "344:\tlearn: 0.0059644\ttest: 0.0517318\tbest: 0.0517111 (333)\ttotal: 1.73s\tremaining: 48.6s\n",
      "345:\tlearn: 0.0059573\ttest: 0.0517341\tbest: 0.0517111 (333)\ttotal: 1.74s\tremaining: 48.6s\n",
      "346:\tlearn: 0.0059101\ttest: 0.0517412\tbest: 0.0517111 (333)\ttotal: 1.75s\tremaining: 48.6s\n",
      "347:\tlearn: 0.0058551\ttest: 0.0517363\tbest: 0.0517111 (333)\ttotal: 1.75s\tremaining: 48.6s\n",
      "348:\tlearn: 0.0058073\ttest: 0.0517450\tbest: 0.0517111 (333)\ttotal: 1.76s\tremaining: 48.7s\n",
      "349:\tlearn: 0.0057993\ttest: 0.0517472\tbest: 0.0517111 (333)\ttotal: 1.76s\tremaining: 48.7s\n",
      "350:\tlearn: 0.0057550\ttest: 0.0517383\tbest: 0.0517111 (333)\ttotal: 1.77s\tremaining: 48.7s\n",
      "351:\tlearn: 0.0057495\ttest: 0.0517403\tbest: 0.0517111 (333)\ttotal: 1.78s\tremaining: 48.7s\n",
      "352:\tlearn: 0.0057206\ttest: 0.0517375\tbest: 0.0517111 (333)\ttotal: 1.78s\tremaining: 48.7s\n",
      "353:\tlearn: 0.0057080\ttest: 0.0517492\tbest: 0.0517111 (333)\ttotal: 1.79s\tremaining: 48.7s\n",
      "354:\tlearn: 0.0056792\ttest: 0.0517689\tbest: 0.0517111 (333)\ttotal: 1.79s\tremaining: 48.8s\n",
      "355:\tlearn: 0.0056206\ttest: 0.0517797\tbest: 0.0517111 (333)\ttotal: 1.8s\tremaining: 48.8s\n",
      "356:\tlearn: 0.0055750\ttest: 0.0517624\tbest: 0.0517111 (333)\ttotal: 1.8s\tremaining: 48.8s\n",
      "357:\tlearn: 0.0055218\ttest: 0.0517704\tbest: 0.0517111 (333)\ttotal: 1.81s\tremaining: 48.8s\n",
      "358:\tlearn: 0.0054868\ttest: 0.0517769\tbest: 0.0517111 (333)\ttotal: 1.82s\tremaining: 48.8s\n",
      "359:\tlearn: 0.0054797\ttest: 0.0517818\tbest: 0.0517111 (333)\ttotal: 1.82s\tremaining: 48.8s\n",
      "360:\tlearn: 0.0054328\ttest: 0.0517793\tbest: 0.0517111 (333)\ttotal: 1.83s\tremaining: 48.8s\n",
      "361:\tlearn: 0.0053894\ttest: 0.0517762\tbest: 0.0517111 (333)\ttotal: 1.83s\tremaining: 48.9s\n",
      "362:\tlearn: 0.0053381\ttest: 0.0517850\tbest: 0.0517111 (333)\ttotal: 1.84s\tremaining: 48.9s\n",
      "363:\tlearn: 0.0052855\ttest: 0.0517782\tbest: 0.0517111 (333)\ttotal: 1.85s\tremaining: 48.9s\n",
      "364:\tlearn: 0.0052395\ttest: 0.0517693\tbest: 0.0517111 (333)\ttotal: 1.85s\tremaining: 48.9s\n",
      "365:\tlearn: 0.0052266\ttest: 0.0517720\tbest: 0.0517111 (333)\ttotal: 1.86s\tremaining: 48.9s\n",
      "366:\tlearn: 0.0051831\ttest: 0.0517810\tbest: 0.0517111 (333)\ttotal: 1.86s\tremaining: 48.9s\n",
      "367:\tlearn: 0.0051215\ttest: 0.0517760\tbest: 0.0517111 (333)\ttotal: 1.87s\tremaining: 49s\n",
      "368:\tlearn: 0.0051026\ttest: 0.0517711\tbest: 0.0517111 (333)\ttotal: 1.88s\tremaining: 49s\n",
      "369:\tlearn: 0.0050676\ttest: 0.0517831\tbest: 0.0517111 (333)\ttotal: 1.88s\tremaining: 49s\n",
      "370:\tlearn: 0.0050434\ttest: 0.0517853\tbest: 0.0517111 (333)\ttotal: 1.89s\tremaining: 49s\n",
      "371:\tlearn: 0.0050355\ttest: 0.0517853\tbest: 0.0517111 (333)\ttotal: 1.89s\tremaining: 49s\n",
      "372:\tlearn: 0.0050264\ttest: 0.0517895\tbest: 0.0517111 (333)\ttotal: 1.9s\tremaining: 49s\n",
      "373:\tlearn: 0.0049904\ttest: 0.0518001\tbest: 0.0517111 (333)\ttotal: 1.9s\tremaining: 49s\n",
      "374:\tlearn: 0.0049485\ttest: 0.0517873\tbest: 0.0517111 (333)\ttotal: 1.91s\tremaining: 49s\n",
      "375:\tlearn: 0.0049050\ttest: 0.0517815\tbest: 0.0517111 (333)\ttotal: 1.92s\tremaining: 49s\n",
      "376:\tlearn: 0.0048982\ttest: 0.0517842\tbest: 0.0517111 (333)\ttotal: 1.92s\tremaining: 49.1s\n",
      "377:\tlearn: 0.0048905\ttest: 0.0517911\tbest: 0.0517111 (333)\ttotal: 1.93s\tremaining: 49.1s\n",
      "378:\tlearn: 0.0048393\ttest: 0.0517809\tbest: 0.0517111 (333)\ttotal: 1.93s\tremaining: 49.1s\n",
      "379:\tlearn: 0.0048039\ttest: 0.0517669\tbest: 0.0517111 (333)\ttotal: 1.94s\tremaining: 49.1s\n",
      "380:\tlearn: 0.0047477\ttest: 0.0517767\tbest: 0.0517111 (333)\ttotal: 1.95s\tremaining: 49.1s\n",
      "381:\tlearn: 0.0047402\ttest: 0.0517815\tbest: 0.0517111 (333)\ttotal: 1.95s\tremaining: 49.1s\n",
      "382:\tlearn: 0.0046974\ttest: 0.0517792\tbest: 0.0517111 (333)\ttotal: 1.96s\tremaining: 49.1s\n",
      "383:\tlearn: 0.0046724\ttest: 0.0517752\tbest: 0.0517111 (333)\ttotal: 1.96s\tremaining: 49.1s\n",
      "384:\tlearn: 0.0046443\ttest: 0.0517734\tbest: 0.0517111 (333)\ttotal: 1.97s\tremaining: 49.2s\n",
      "385:\tlearn: 0.0045977\ttest: 0.0517797\tbest: 0.0517111 (333)\ttotal: 1.97s\tremaining: 49.2s\n",
      "386:\tlearn: 0.0045923\ttest: 0.0517735\tbest: 0.0517111 (333)\ttotal: 1.98s\tremaining: 49.2s\n",
      "387:\tlearn: 0.0045540\ttest: 0.0517784\tbest: 0.0517111 (333)\ttotal: 1.98s\tremaining: 49.2s\n",
      "388:\tlearn: 0.0045287\ttest: 0.0517739\tbest: 0.0517111 (333)\ttotal: 1.99s\tremaining: 49.2s\n",
      "389:\tlearn: 0.0044818\ttest: 0.0517713\tbest: 0.0517111 (333)\ttotal: 2s\tremaining: 49.2s\n",
      "390:\tlearn: 0.0044750\ttest: 0.0517718\tbest: 0.0517111 (333)\ttotal: 2s\tremaining: 49.2s\n",
      "391:\tlearn: 0.0044370\ttest: 0.0517668\tbest: 0.0517111 (333)\ttotal: 2.01s\tremaining: 49.2s\n",
      "392:\tlearn: 0.0044327\ttest: 0.0517676\tbest: 0.0517111 (333)\ttotal: 2.02s\tremaining: 49.3s\n",
      "393:\tlearn: 0.0043985\ttest: 0.0517661\tbest: 0.0517111 (333)\ttotal: 2.02s\tremaining: 49.3s\n",
      "394:\tlearn: 0.0043891\ttest: 0.0517708\tbest: 0.0517111 (333)\ttotal: 2.03s\tremaining: 49.3s\n",
      "395:\tlearn: 0.0043679\ttest: 0.0517705\tbest: 0.0517111 (333)\ttotal: 2.03s\tremaining: 49.3s\n",
      "396:\tlearn: 0.0043643\ttest: 0.0517759\tbest: 0.0517111 (333)\ttotal: 2.04s\tremaining: 49.3s\n",
      "397:\tlearn: 0.0043218\ttest: 0.0517440\tbest: 0.0517111 (333)\ttotal: 2.05s\tremaining: 49.4s\n",
      "398:\tlearn: 0.0043161\ttest: 0.0517470\tbest: 0.0517111 (333)\ttotal: 2.05s\tremaining: 49.4s\n",
      "399:\tlearn: 0.0042875\ttest: 0.0517400\tbest: 0.0517111 (333)\ttotal: 2.06s\tremaining: 49.4s\n",
      "400:\tlearn: 0.0042560\ttest: 0.0517357\tbest: 0.0517111 (333)\ttotal: 2.06s\tremaining: 49.4s\n",
      "401:\tlearn: 0.0042147\ttest: 0.0517467\tbest: 0.0517111 (333)\ttotal: 2.07s\tremaining: 49.4s\n",
      "402:\tlearn: 0.0041751\ttest: 0.0517457\tbest: 0.0517111 (333)\ttotal: 2.08s\tremaining: 49.4s\n",
      "403:\tlearn: 0.0041482\ttest: 0.0517519\tbest: 0.0517111 (333)\ttotal: 2.08s\tremaining: 49.5s\n",
      "404:\tlearn: 0.0041330\ttest: 0.0517517\tbest: 0.0517111 (333)\ttotal: 2.09s\tremaining: 49.5s\n",
      "405:\tlearn: 0.0041010\ttest: 0.0517586\tbest: 0.0517111 (333)\ttotal: 2.09s\tremaining: 49.5s\n",
      "406:\tlearn: 0.0040860\ttest: 0.0517622\tbest: 0.0517111 (333)\ttotal: 2.1s\tremaining: 49.5s\n",
      "407:\tlearn: 0.0040810\ttest: 0.0517613\tbest: 0.0517111 (333)\ttotal: 2.11s\tremaining: 49.5s\n",
      "408:\tlearn: 0.0040369\ttest: 0.0517565\tbest: 0.0517111 (333)\ttotal: 2.11s\tremaining: 49.6s\n",
      "409:\tlearn: 0.0040122\ttest: 0.0517490\tbest: 0.0517111 (333)\ttotal: 2.12s\tremaining: 49.6s\n",
      "410:\tlearn: 0.0039823\ttest: 0.0517404\tbest: 0.0517111 (333)\ttotal: 2.13s\tremaining: 49.6s\n",
      "411:\tlearn: 0.0039507\ttest: 0.0517471\tbest: 0.0517111 (333)\ttotal: 2.13s\tremaining: 49.7s\n",
      "412:\tlearn: 0.0039386\ttest: 0.0517464\tbest: 0.0517111 (333)\ttotal: 2.14s\tremaining: 49.7s\n",
      "413:\tlearn: 0.0039195\ttest: 0.0517451\tbest: 0.0517111 (333)\ttotal: 2.15s\tremaining: 49.7s\n",
      "414:\tlearn: 0.0038969\ttest: 0.0517421\tbest: 0.0517111 (333)\ttotal: 2.15s\tremaining: 49.8s\n",
      "415:\tlearn: 0.0038916\ttest: 0.0517433\tbest: 0.0517111 (333)\ttotal: 2.16s\tremaining: 49.8s\n",
      "416:\tlearn: 0.0038832\ttest: 0.0517473\tbest: 0.0517111 (333)\ttotal: 2.17s\tremaining: 49.8s\n",
      "417:\tlearn: 0.0038558\ttest: 0.0517411\tbest: 0.0517111 (333)\ttotal: 2.17s\tremaining: 49.8s\n",
      "418:\tlearn: 0.0038310\ttest: 0.0517507\tbest: 0.0517111 (333)\ttotal: 2.18s\tremaining: 49.8s\n",
      "419:\tlearn: 0.0038273\ttest: 0.0517495\tbest: 0.0517111 (333)\ttotal: 2.19s\tremaining: 49.9s\n",
      "420:\tlearn: 0.0037960\ttest: 0.0517491\tbest: 0.0517111 (333)\ttotal: 2.19s\tremaining: 49.9s\n",
      "421:\tlearn: 0.0037613\ttest: 0.0517417\tbest: 0.0517111 (333)\ttotal: 2.2s\tremaining: 49.9s\n",
      "422:\tlearn: 0.0037285\ttest: 0.0517398\tbest: 0.0517111 (333)\ttotal: 2.21s\tremaining: 49.9s\n",
      "423:\tlearn: 0.0036986\ttest: 0.0517447\tbest: 0.0517111 (333)\ttotal: 2.21s\tremaining: 49.9s\n",
      "424:\tlearn: 0.0036717\ttest: 0.0517469\tbest: 0.0517111 (333)\ttotal: 2.22s\tremaining: 50s\n",
      "425:\tlearn: 0.0036650\ttest: 0.0517498\tbest: 0.0517111 (333)\ttotal: 2.22s\tremaining: 50s\n",
      "426:\tlearn: 0.0036480\ttest: 0.0517428\tbest: 0.0517111 (333)\ttotal: 2.23s\tremaining: 50s\n",
      "427:\tlearn: 0.0036236\ttest: 0.0517440\tbest: 0.0517111 (333)\ttotal: 2.23s\tremaining: 50s\n",
      "428:\tlearn: 0.0035869\ttest: 0.0517360\tbest: 0.0517111 (333)\ttotal: 2.24s\tremaining: 50s\n",
      "429:\tlearn: 0.0035491\ttest: 0.0517256\tbest: 0.0517111 (333)\ttotal: 2.25s\tremaining: 50s\n",
      "430:\tlearn: 0.0035052\ttest: 0.0517207\tbest: 0.0517111 (333)\ttotal: 2.25s\tremaining: 50s\n",
      "431:\tlearn: 0.0034683\ttest: 0.0517097\tbest: 0.0517097 (431)\ttotal: 2.26s\tremaining: 50s\n",
      "432:\tlearn: 0.0034398\ttest: 0.0517138\tbest: 0.0517097 (431)\ttotal: 2.26s\tremaining: 50s\n",
      "433:\tlearn: 0.0034077\ttest: 0.0517098\tbest: 0.0517097 (431)\ttotal: 2.27s\tremaining: 50s\n",
      "434:\tlearn: 0.0033845\ttest: 0.0517060\tbest: 0.0517060 (434)\ttotal: 2.27s\tremaining: 50s\n",
      "435:\tlearn: 0.0033459\ttest: 0.0517162\tbest: 0.0517060 (434)\ttotal: 2.28s\tremaining: 50s\n",
      "436:\tlearn: 0.0033303\ttest: 0.0517210\tbest: 0.0517060 (434)\ttotal: 2.29s\tremaining: 50s\n",
      "437:\tlearn: 0.0033018\ttest: 0.0517043\tbest: 0.0517043 (437)\ttotal: 2.29s\tremaining: 50s\n",
      "438:\tlearn: 0.0032792\ttest: 0.0517120\tbest: 0.0517043 (437)\ttotal: 2.29s\tremaining: 50s\n",
      "439:\tlearn: 0.0032411\ttest: 0.0516995\tbest: 0.0516995 (439)\ttotal: 2.3s\tremaining: 50s\n",
      "440:\tlearn: 0.0032310\ttest: 0.0517020\tbest: 0.0516995 (439)\ttotal: 2.31s\tremaining: 50s\n",
      "441:\tlearn: 0.0032076\ttest: 0.0517037\tbest: 0.0516995 (439)\ttotal: 2.31s\tremaining: 50s\n",
      "442:\tlearn: 0.0031761\ttest: 0.0517027\tbest: 0.0516995 (439)\ttotal: 2.32s\tremaining: 50s\n",
      "443:\tlearn: 0.0031507\ttest: 0.0516995\tbest: 0.0516995 (443)\ttotal: 2.32s\tremaining: 50s\n",
      "444:\tlearn: 0.0031250\ttest: 0.0517092\tbest: 0.0516995 (443)\ttotal: 2.33s\tremaining: 50s\n",
      "445:\tlearn: 0.0030915\ttest: 0.0516979\tbest: 0.0516979 (445)\ttotal: 2.33s\tremaining: 50s\n",
      "446:\tlearn: 0.0030865\ttest: 0.0516990\tbest: 0.0516979 (445)\ttotal: 2.34s\tremaining: 50s\n",
      "447:\tlearn: 0.0030682\ttest: 0.0516984\tbest: 0.0516979 (445)\ttotal: 2.34s\tremaining: 50s\n",
      "448:\tlearn: 0.0030518\ttest: 0.0516978\tbest: 0.0516978 (448)\ttotal: 2.35s\tremaining: 50s\n",
      "449:\tlearn: 0.0030155\ttest: 0.0516919\tbest: 0.0516919 (449)\ttotal: 2.35s\tremaining: 50s\n",
      "450:\tlearn: 0.0029801\ttest: 0.0516920\tbest: 0.0516919 (449)\ttotal: 2.36s\tremaining: 50s\n",
      "451:\tlearn: 0.0029553\ttest: 0.0516798\tbest: 0.0516798 (451)\ttotal: 2.37s\tremaining: 50s\n",
      "452:\tlearn: 0.0029318\ttest: 0.0516682\tbest: 0.0516682 (452)\ttotal: 2.37s\tremaining: 50s\n",
      "453:\tlearn: 0.0029155\ttest: 0.0516582\tbest: 0.0516582 (453)\ttotal: 2.38s\tremaining: 50s\n",
      "454:\tlearn: 0.0028879\ttest: 0.0516676\tbest: 0.0516582 (453)\ttotal: 2.38s\tremaining: 50s\n",
      "455:\tlearn: 0.0028637\ttest: 0.0516699\tbest: 0.0516582 (453)\ttotal: 2.39s\tremaining: 50s\n",
      "456:\tlearn: 0.0028435\ttest: 0.0516638\tbest: 0.0516582 (453)\ttotal: 2.39s\tremaining: 50s\n",
      "457:\tlearn: 0.0028252\ttest: 0.0516580\tbest: 0.0516580 (457)\ttotal: 2.4s\tremaining: 50s\n",
      "458:\tlearn: 0.0028116\ttest: 0.0516643\tbest: 0.0516580 (457)\ttotal: 2.4s\tremaining: 50s\n",
      "459:\tlearn: 0.0027878\ttest: 0.0516578\tbest: 0.0516578 (459)\ttotal: 2.41s\tremaining: 50s\n",
      "460:\tlearn: 0.0027718\ttest: 0.0516498\tbest: 0.0516498 (460)\ttotal: 2.42s\tremaining: 50s\n",
      "461:\tlearn: 0.0027480\ttest: 0.0516499\tbest: 0.0516498 (460)\ttotal: 2.42s\tremaining: 50s\n",
      "462:\tlearn: 0.0027163\ttest: 0.0516536\tbest: 0.0516498 (460)\ttotal: 2.43s\tremaining: 50s\n",
      "463:\tlearn: 0.0026932\ttest: 0.0516604\tbest: 0.0516498 (460)\ttotal: 2.43s\tremaining: 50s\n",
      "464:\tlearn: 0.0026734\ttest: 0.0516591\tbest: 0.0516498 (460)\ttotal: 2.44s\tremaining: 50s\n",
      "465:\tlearn: 0.0026637\ttest: 0.0516572\tbest: 0.0516498 (460)\ttotal: 2.44s\tremaining: 50s\n",
      "466:\tlearn: 0.0026491\ttest: 0.0516624\tbest: 0.0516498 (460)\ttotal: 2.45s\tremaining: 50s\n",
      "467:\tlearn: 0.0026335\ttest: 0.0516652\tbest: 0.0516498 (460)\ttotal: 2.45s\tremaining: 50s\n",
      "468:\tlearn: 0.0026150\ttest: 0.0516654\tbest: 0.0516498 (460)\ttotal: 2.46s\tremaining: 50s\n",
      "469:\tlearn: 0.0026017\ttest: 0.0516651\tbest: 0.0516498 (460)\ttotal: 2.47s\tremaining: 50s\n",
      "470:\tlearn: 0.0025780\ttest: 0.0516610\tbest: 0.0516498 (460)\ttotal: 2.47s\tremaining: 50s\n",
      "471:\tlearn: 0.0025497\ttest: 0.0516640\tbest: 0.0516498 (460)\ttotal: 2.48s\tremaining: 50s\n",
      "472:\tlearn: 0.0025355\ttest: 0.0516677\tbest: 0.0516498 (460)\ttotal: 2.48s\tremaining: 50.1s\n",
      "473:\tlearn: 0.0025254\ttest: 0.0516698\tbest: 0.0516498 (460)\ttotal: 2.49s\tremaining: 50.1s\n",
      "474:\tlearn: 0.0025036\ttest: 0.0516660\tbest: 0.0516498 (460)\ttotal: 2.5s\tremaining: 50.1s\n",
      "475:\tlearn: 0.0024898\ttest: 0.0516675\tbest: 0.0516498 (460)\ttotal: 2.5s\tremaining: 50.1s\n",
      "476:\tlearn: 0.0024703\ttest: 0.0516758\tbest: 0.0516498 (460)\ttotal: 2.51s\tremaining: 50.2s\n",
      "477:\tlearn: 0.0024554\ttest: 0.0516839\tbest: 0.0516498 (460)\ttotal: 2.52s\tremaining: 50.3s\n",
      "478:\tlearn: 0.0024332\ttest: 0.0516796\tbest: 0.0516498 (460)\ttotal: 2.53s\tremaining: 50.3s\n",
      "479:\tlearn: 0.0024127\ttest: 0.0516847\tbest: 0.0516498 (460)\ttotal: 2.54s\tremaining: 50.3s\n",
      "480:\tlearn: 0.0023887\ttest: 0.0516794\tbest: 0.0516498 (460)\ttotal: 2.54s\tremaining: 50.3s\n",
      "481:\tlearn: 0.0023762\ttest: 0.0516766\tbest: 0.0516498 (460)\ttotal: 2.55s\tremaining: 50.4s\n",
      "482:\tlearn: 0.0023578\ttest: 0.0516728\tbest: 0.0516498 (460)\ttotal: 2.56s\tremaining: 50.4s\n",
      "483:\tlearn: 0.0023460\ttest: 0.0516745\tbest: 0.0516498 (460)\ttotal: 2.56s\tremaining: 50.4s\n",
      "484:\tlearn: 0.0023304\ttest: 0.0516769\tbest: 0.0516498 (460)\ttotal: 2.57s\tremaining: 50.5s\n",
      "485:\tlearn: 0.0023217\ttest: 0.0516758\tbest: 0.0516498 (460)\ttotal: 2.58s\tremaining: 50.5s\n",
      "486:\tlearn: 0.0023077\ttest: 0.0516784\tbest: 0.0516498 (460)\ttotal: 2.58s\tremaining: 50.5s\n",
      "487:\tlearn: 0.0022814\ttest: 0.0516782\tbest: 0.0516498 (460)\ttotal: 2.59s\tremaining: 50.5s\n",
      "488:\tlearn: 0.0022590\ttest: 0.0516735\tbest: 0.0516498 (460)\ttotal: 2.6s\tremaining: 50.6s\n",
      "489:\tlearn: 0.0022375\ttest: 0.0516745\tbest: 0.0516498 (460)\ttotal: 2.61s\tremaining: 50.6s\n",
      "490:\tlearn: 0.0022279\ttest: 0.0516737\tbest: 0.0516498 (460)\ttotal: 2.61s\tremaining: 50.6s\n",
      "491:\tlearn: 0.0022250\ttest: 0.0516743\tbest: 0.0516498 (460)\ttotal: 2.62s\tremaining: 50.7s\n",
      "492:\tlearn: 0.0022109\ttest: 0.0516731\tbest: 0.0516498 (460)\ttotal: 2.63s\tremaining: 50.7s\n",
      "493:\tlearn: 0.0022085\ttest: 0.0516718\tbest: 0.0516498 (460)\ttotal: 2.64s\tremaining: 50.7s\n",
      "494:\tlearn: 0.0021913\ttest: 0.0516743\tbest: 0.0516498 (460)\ttotal: 2.64s\tremaining: 50.8s\n",
      "495:\tlearn: 0.0021706\ttest: 0.0516694\tbest: 0.0516498 (460)\ttotal: 2.65s\tremaining: 50.8s\n",
      "496:\tlearn: 0.0021629\ttest: 0.0516642\tbest: 0.0516498 (460)\ttotal: 2.66s\tremaining: 50.8s\n",
      "497:\tlearn: 0.0021390\ttest: 0.0516690\tbest: 0.0516498 (460)\ttotal: 2.67s\tremaining: 50.9s\n",
      "498:\tlearn: 0.0021173\ttest: 0.0516664\tbest: 0.0516498 (460)\ttotal: 2.68s\tremaining: 51s\n",
      "499:\tlearn: 0.0021024\ttest: 0.0516617\tbest: 0.0516498 (460)\ttotal: 2.69s\tremaining: 51.1s\n",
      "500:\tlearn: 0.0020846\ttest: 0.0516604\tbest: 0.0516498 (460)\ttotal: 2.7s\tremaining: 51.1s\n",
      "501:\tlearn: 0.0020702\ttest: 0.0516564\tbest: 0.0516498 (460)\ttotal: 2.71s\tremaining: 51.2s\n",
      "502:\tlearn: 0.0020592\ttest: 0.0516577\tbest: 0.0516498 (460)\ttotal: 2.71s\tremaining: 51.2s\n",
      "503:\tlearn: 0.0020472\ttest: 0.0516579\tbest: 0.0516498 (460)\ttotal: 2.72s\tremaining: 51.3s\n",
      "504:\tlearn: 0.0020280\ttest: 0.0516562\tbest: 0.0516498 (460)\ttotal: 2.73s\tremaining: 51.3s\n",
      "505:\tlearn: 0.0020119\ttest: 0.0516515\tbest: 0.0516498 (460)\ttotal: 2.74s\tremaining: 51.4s\n",
      "506:\tlearn: 0.0019912\ttest: 0.0516481\tbest: 0.0516481 (506)\ttotal: 2.74s\tremaining: 51.4s\n",
      "507:\tlearn: 0.0019715\ttest: 0.0516434\tbest: 0.0516434 (507)\ttotal: 2.75s\tremaining: 51.4s\n",
      "508:\tlearn: 0.0019534\ttest: 0.0516362\tbest: 0.0516362 (508)\ttotal: 2.76s\tremaining: 51.5s\n",
      "509:\tlearn: 0.0019360\ttest: 0.0516338\tbest: 0.0516338 (509)\ttotal: 2.77s\tremaining: 51.5s\n",
      "510:\tlearn: 0.0019158\ttest: 0.0516371\tbest: 0.0516338 (509)\ttotal: 2.77s\tremaining: 51.5s\n",
      "511:\tlearn: 0.0018997\ttest: 0.0516350\tbest: 0.0516338 (509)\ttotal: 2.78s\tremaining: 51.6s\n",
      "512:\tlearn: 0.0018848\ttest: 0.0516327\tbest: 0.0516327 (512)\ttotal: 2.79s\tremaining: 51.6s\n",
      "513:\tlearn: 0.0018738\ttest: 0.0516303\tbest: 0.0516303 (513)\ttotal: 2.8s\tremaining: 51.6s\n",
      "514:\tlearn: 0.0018579\ttest: 0.0516327\tbest: 0.0516303 (513)\ttotal: 2.8s\tremaining: 51.6s\n",
      "515:\tlearn: 0.0018417\ttest: 0.0516277\tbest: 0.0516277 (515)\ttotal: 2.81s\tremaining: 51.7s\n",
      "516:\tlearn: 0.0018256\ttest: 0.0516276\tbest: 0.0516276 (516)\ttotal: 2.82s\tremaining: 51.7s\n",
      "517:\tlearn: 0.0018113\ttest: 0.0516331\tbest: 0.0516276 (516)\ttotal: 2.82s\tremaining: 51.7s\n",
      "518:\tlearn: 0.0017941\ttest: 0.0516306\tbest: 0.0516276 (516)\ttotal: 2.83s\tremaining: 51.7s\n",
      "519:\tlearn: 0.0017852\ttest: 0.0516314\tbest: 0.0516276 (516)\ttotal: 2.84s\tremaining: 51.8s\n",
      "520:\tlearn: 0.0017829\ttest: 0.0516305\tbest: 0.0516276 (516)\ttotal: 2.85s\tremaining: 51.8s\n",
      "521:\tlearn: 0.0017683\ttest: 0.0516256\tbest: 0.0516256 (521)\ttotal: 2.85s\tremaining: 51.8s\n",
      "522:\tlearn: 0.0017505\ttest: 0.0516235\tbest: 0.0516235 (522)\ttotal: 2.86s\tremaining: 51.8s\n",
      "523:\tlearn: 0.0017486\ttest: 0.0516237\tbest: 0.0516235 (522)\ttotal: 2.87s\tremaining: 51.9s\n",
      "524:\tlearn: 0.0017336\ttest: 0.0516231\tbest: 0.0516231 (524)\ttotal: 2.87s\tremaining: 51.9s\n",
      "525:\tlearn: 0.0017263\ttest: 0.0516202\tbest: 0.0516202 (525)\ttotal: 2.88s\tremaining: 51.9s\n",
      "526:\tlearn: 0.0017111\ttest: 0.0516180\tbest: 0.0516180 (526)\ttotal: 2.89s\tremaining: 51.9s\n",
      "527:\tlearn: 0.0016947\ttest: 0.0516180\tbest: 0.0516180 (526)\ttotal: 2.89s\tremaining: 51.9s\n",
      "528:\tlearn: 0.0016929\ttest: 0.0516159\tbest: 0.0516159 (528)\ttotal: 2.9s\tremaining: 51.9s\n",
      "529:\tlearn: 0.0016877\ttest: 0.0516176\tbest: 0.0516159 (528)\ttotal: 2.91s\tremaining: 52s\n",
      "530:\tlearn: 0.0016765\ttest: 0.0516151\tbest: 0.0516151 (530)\ttotal: 2.92s\tremaining: 52s\n",
      "531:\tlearn: 0.0016715\ttest: 0.0516132\tbest: 0.0516132 (531)\ttotal: 2.92s\tremaining: 52s\n",
      "532:\tlearn: 0.0016559\ttest: 0.0516128\tbest: 0.0516128 (532)\ttotal: 2.93s\tremaining: 52s\n",
      "533:\tlearn: 0.0016494\ttest: 0.0516137\tbest: 0.0516128 (532)\ttotal: 2.94s\tremaining: 52s\n",
      "534:\tlearn: 0.0016479\ttest: 0.0516132\tbest: 0.0516128 (532)\ttotal: 2.94s\tremaining: 52s\n",
      "535:\tlearn: 0.0016394\ttest: 0.0516100\tbest: 0.0516100 (535)\ttotal: 2.95s\tremaining: 52.1s\n",
      "536:\tlearn: 0.0016262\ttest: 0.0516082\tbest: 0.0516082 (536)\ttotal: 2.96s\tremaining: 52.1s\n",
      "537:\tlearn: 0.0016178\ttest: 0.0516094\tbest: 0.0516082 (536)\ttotal: 2.96s\tremaining: 52.1s\n",
      "538:\tlearn: 0.0016025\ttest: 0.0516098\tbest: 0.0516082 (536)\ttotal: 2.97s\tremaining: 52.1s\n",
      "539:\tlearn: 0.0015852\ttest: 0.0516117\tbest: 0.0516082 (536)\ttotal: 2.98s\tremaining: 52.1s\n",
      "540:\tlearn: 0.0015781\ttest: 0.0516163\tbest: 0.0516082 (536)\ttotal: 2.98s\tremaining: 52.2s\n",
      "541:\tlearn: 0.0015649\ttest: 0.0516153\tbest: 0.0516082 (536)\ttotal: 2.99s\tremaining: 52.2s\n",
      "542:\tlearn: 0.0015479\ttest: 0.0516162\tbest: 0.0516082 (536)\ttotal: 3s\tremaining: 52.2s\n",
      "543:\tlearn: 0.0015386\ttest: 0.0516151\tbest: 0.0516082 (536)\ttotal: 3s\tremaining: 52.2s\n",
      "544:\tlearn: 0.0015269\ttest: 0.0516099\tbest: 0.0516082 (536)\ttotal: 3.01s\tremaining: 52.3s\n",
      "545:\tlearn: 0.0015160\ttest: 0.0516071\tbest: 0.0516071 (545)\ttotal: 3.02s\tremaining: 52.3s\n",
      "546:\tlearn: 0.0015016\ttest: 0.0516049\tbest: 0.0516049 (546)\ttotal: 3.03s\tremaining: 52.3s\n",
      "547:\tlearn: 0.0014870\ttest: 0.0516075\tbest: 0.0516049 (546)\ttotal: 3.03s\tremaining: 52.3s\n",
      "548:\tlearn: 0.0014771\ttest: 0.0516071\tbest: 0.0516049 (546)\ttotal: 3.04s\tremaining: 52.4s\n",
      "549:\tlearn: 0.0014645\ttest: 0.0516067\tbest: 0.0516049 (546)\ttotal: 3.05s\tremaining: 52.4s\n",
      "550:\tlearn: 0.0014560\ttest: 0.0516103\tbest: 0.0516049 (546)\ttotal: 3.06s\tremaining: 52.4s\n",
      "551:\tlearn: 0.0014542\ttest: 0.0516087\tbest: 0.0516049 (546)\ttotal: 3.06s\tremaining: 52.5s\n",
      "552:\tlearn: 0.0014436\ttest: 0.0516121\tbest: 0.0516049 (546)\ttotal: 3.07s\tremaining: 52.5s\n",
      "553:\tlearn: 0.0014373\ttest: 0.0516114\tbest: 0.0516049 (546)\ttotal: 3.08s\tremaining: 52.5s\n",
      "554:\tlearn: 0.0014282\ttest: 0.0516074\tbest: 0.0516049 (546)\ttotal: 3.09s\tremaining: 52.5s\n",
      "555:\tlearn: 0.0014164\ttest: 0.0516130\tbest: 0.0516049 (546)\ttotal: 3.1s\tremaining: 52.6s\n",
      "556:\tlearn: 0.0014113\ttest: 0.0516134\tbest: 0.0516049 (546)\ttotal: 3.1s\tremaining: 52.6s\n",
      "557:\tlearn: 0.0014012\ttest: 0.0516095\tbest: 0.0516049 (546)\ttotal: 3.11s\tremaining: 52.6s\n",
      "558:\tlearn: 0.0013951\ttest: 0.0516123\tbest: 0.0516049 (546)\ttotal: 3.12s\tremaining: 52.7s\n",
      "559:\tlearn: 0.0013847\ttest: 0.0516092\tbest: 0.0516049 (546)\ttotal: 3.13s\tremaining: 52.7s\n",
      "560:\tlearn: 0.0013711\ttest: 0.0516065\tbest: 0.0516049 (546)\ttotal: 3.13s\tremaining: 52.7s\n",
      "561:\tlearn: 0.0013634\ttest: 0.0516071\tbest: 0.0516049 (546)\ttotal: 3.14s\tremaining: 52.8s\n",
      "562:\tlearn: 0.0013506\ttest: 0.0516083\tbest: 0.0516049 (546)\ttotal: 3.15s\tremaining: 52.8s\n",
      "563:\tlearn: 0.0013424\ttest: 0.0516076\tbest: 0.0516049 (546)\ttotal: 3.15s\tremaining: 52.8s\n",
      "564:\tlearn: 0.0013401\ttest: 0.0516084\tbest: 0.0516049 (546)\ttotal: 3.16s\tremaining: 52.8s\n",
      "565:\tlearn: 0.0013287\ttest: 0.0516052\tbest: 0.0516049 (546)\ttotal: 3.17s\tremaining: 52.8s\n",
      "566:\tlearn: 0.0013179\ttest: 0.0516083\tbest: 0.0516049 (546)\ttotal: 3.18s\tremaining: 52.9s\n",
      "567:\tlearn: 0.0013102\ttest: 0.0516054\tbest: 0.0516049 (546)\ttotal: 3.19s\tremaining: 52.9s\n",
      "568:\tlearn: 0.0013026\ttest: 0.0516032\tbest: 0.0516032 (568)\ttotal: 3.19s\tremaining: 52.9s\n",
      "569:\tlearn: 0.0012959\ttest: 0.0516024\tbest: 0.0516024 (569)\ttotal: 3.2s\tremaining: 52.9s\n",
      "570:\tlearn: 0.0012936\ttest: 0.0516030\tbest: 0.0516024 (569)\ttotal: 3.21s\tremaining: 53s\n",
      "571:\tlearn: 0.0012828\ttest: 0.0516012\tbest: 0.0516012 (571)\ttotal: 3.21s\tremaining: 53s\n",
      "572:\tlearn: 0.0012725\ttest: 0.0516025\tbest: 0.0516012 (571)\ttotal: 3.22s\tremaining: 53s\n",
      "573:\tlearn: 0.0012609\ttest: 0.0516024\tbest: 0.0516012 (571)\ttotal: 3.23s\tremaining: 53s\n",
      "574:\tlearn: 0.0012598\ttest: 0.0516014\tbest: 0.0516012 (571)\ttotal: 3.23s\tremaining: 53s\n",
      "575:\tlearn: 0.0012488\ttest: 0.0516053\tbest: 0.0516012 (571)\ttotal: 3.24s\tremaining: 53s\n",
      "576:\tlearn: 0.0012442\ttest: 0.0516059\tbest: 0.0516012 (571)\ttotal: 3.25s\tremaining: 53.1s\n",
      "577:\tlearn: 0.0012353\ttest: 0.0516042\tbest: 0.0516012 (571)\ttotal: 3.26s\tremaining: 53.1s\n",
      "578:\tlearn: 0.0012243\ttest: 0.0516056\tbest: 0.0516012 (571)\ttotal: 3.26s\tremaining: 53.1s\n",
      "579:\tlearn: 0.0012140\ttest: 0.0515999\tbest: 0.0515999 (579)\ttotal: 3.27s\tremaining: 53.1s\n",
      "580:\tlearn: 0.0012048\ttest: 0.0515977\tbest: 0.0515977 (580)\ttotal: 3.28s\tremaining: 53.2s\n",
      "581:\tlearn: 0.0011924\ttest: 0.0515968\tbest: 0.0515968 (581)\ttotal: 3.29s\tremaining: 53.2s\n",
      "582:\tlearn: 0.0011864\ttest: 0.0515972\tbest: 0.0515968 (581)\ttotal: 3.29s\tremaining: 53.2s\n",
      "583:\tlearn: 0.0011751\ttest: 0.0515915\tbest: 0.0515915 (583)\ttotal: 3.3s\tremaining: 53.3s\n",
      "584:\tlearn: 0.0011692\ttest: 0.0515906\tbest: 0.0515906 (584)\ttotal: 3.31s\tremaining: 53.3s\n",
      "585:\tlearn: 0.0011571\ttest: 0.0515905\tbest: 0.0515905 (585)\ttotal: 3.32s\tremaining: 53.3s\n",
      "586:\tlearn: 0.0011496\ttest: 0.0515916\tbest: 0.0515905 (585)\ttotal: 3.33s\tremaining: 53.3s\n",
      "587:\tlearn: 0.0011415\ttest: 0.0515912\tbest: 0.0515905 (585)\ttotal: 3.33s\tremaining: 53.4s\n",
      "588:\tlearn: 0.0011347\ttest: 0.0515923\tbest: 0.0515905 (585)\ttotal: 3.34s\tremaining: 53.4s\n",
      "589:\tlearn: 0.0011254\ttest: 0.0515920\tbest: 0.0515905 (585)\ttotal: 3.35s\tremaining: 53.4s\n",
      "590:\tlearn: 0.0011148\ttest: 0.0515915\tbest: 0.0515905 (585)\ttotal: 3.36s\tremaining: 53.4s\n",
      "591:\tlearn: 0.0011050\ttest: 0.0515893\tbest: 0.0515893 (591)\ttotal: 3.36s\tremaining: 53.5s\n",
      "592:\tlearn: 0.0010942\ttest: 0.0515899\tbest: 0.0515893 (591)\ttotal: 3.37s\tremaining: 53.5s\n",
      "593:\tlearn: 0.0010845\ttest: 0.0515916\tbest: 0.0515893 (591)\ttotal: 3.38s\tremaining: 53.5s\n",
      "594:\tlearn: 0.0010760\ttest: 0.0515877\tbest: 0.0515877 (594)\ttotal: 3.39s\tremaining: 53.6s\n",
      "595:\tlearn: 0.0010669\ttest: 0.0515883\tbest: 0.0515877 (594)\ttotal: 3.4s\tremaining: 53.6s\n",
      "596:\tlearn: 0.0010657\ttest: 0.0515894\tbest: 0.0515877 (594)\ttotal: 3.41s\tremaining: 53.6s\n",
      "597:\tlearn: 0.0010574\ttest: 0.0515903\tbest: 0.0515877 (594)\ttotal: 3.41s\tremaining: 53.7s\n",
      "598:\tlearn: 0.0010517\ttest: 0.0515893\tbest: 0.0515877 (594)\ttotal: 3.42s\tremaining: 53.7s\n",
      "599:\tlearn: 0.0010439\ttest: 0.0515857\tbest: 0.0515857 (599)\ttotal: 3.43s\tremaining: 53.8s\n",
      "600:\tlearn: 0.0010327\ttest: 0.0515852\tbest: 0.0515852 (600)\ttotal: 3.44s\tremaining: 53.8s\n",
      "601:\tlearn: 0.0010289\ttest: 0.0515848\tbest: 0.0515848 (601)\ttotal: 3.45s\tremaining: 53.9s\n",
      "602:\tlearn: 0.0010253\ttest: 0.0515858\tbest: 0.0515848 (601)\ttotal: 3.46s\tremaining: 53.9s\n",
      "603:\tlearn: 0.0010168\ttest: 0.0515860\tbest: 0.0515848 (601)\ttotal: 3.46s\tremaining: 53.9s\n",
      "604:\tlearn: 0.0010095\ttest: 0.0515845\tbest: 0.0515845 (604)\ttotal: 3.47s\tremaining: 53.9s\n",
      "605:\tlearn: 0.0010018\ttest: 0.0515827\tbest: 0.0515827 (605)\ttotal: 3.48s\tremaining: 54s\n",
      "606:\tlearn: 0.0009939\ttest: 0.0515823\tbest: 0.0515823 (606)\ttotal: 3.49s\tremaining: 54s\n",
      "607:\tlearn: 0.0009870\ttest: 0.0515839\tbest: 0.0515823 (606)\ttotal: 3.5s\tremaining: 54s\n",
      "608:\tlearn: 0.0009851\ttest: 0.0515846\tbest: 0.0515823 (606)\ttotal: 3.5s\tremaining: 54s\n",
      "609:\tlearn: 0.0009792\ttest: 0.0515850\tbest: 0.0515823 (606)\ttotal: 3.51s\tremaining: 54.1s\n",
      "610:\tlearn: 0.0009736\ttest: 0.0515841\tbest: 0.0515823 (606)\ttotal: 3.52s\tremaining: 54.1s\n",
      "611:\tlearn: 0.0009646\ttest: 0.0515855\tbest: 0.0515823 (606)\ttotal: 3.53s\tremaining: 54.1s\n",
      "612:\tlearn: 0.0009604\ttest: 0.0515861\tbest: 0.0515823 (606)\ttotal: 3.53s\tremaining: 54.1s\n",
      "613:\tlearn: 0.0009515\ttest: 0.0515912\tbest: 0.0515823 (606)\ttotal: 3.54s\tremaining: 54.1s\n",
      "614:\tlearn: 0.0009505\ttest: 0.0515907\tbest: 0.0515823 (606)\ttotal: 3.55s\tremaining: 54.2s\n",
      "615:\tlearn: 0.0009427\ttest: 0.0515912\tbest: 0.0515823 (606)\ttotal: 3.56s\tremaining: 54.2s\n",
      "616:\tlearn: 0.0009355\ttest: 0.0515902\tbest: 0.0515823 (606)\ttotal: 3.56s\tremaining: 54.2s\n",
      "617:\tlearn: 0.0009243\ttest: 0.0515906\tbest: 0.0515823 (606)\ttotal: 3.57s\tremaining: 54.2s\n",
      "618:\tlearn: 0.0009138\ttest: 0.0515915\tbest: 0.0515823 (606)\ttotal: 3.58s\tremaining: 54.2s\n",
      "619:\tlearn: 0.0009053\ttest: 0.0515945\tbest: 0.0515823 (606)\ttotal: 3.58s\tremaining: 54.2s\n",
      "620:\tlearn: 0.0008968\ttest: 0.0515961\tbest: 0.0515823 (606)\ttotal: 3.59s\tremaining: 54.2s\n",
      "621:\tlearn: 0.0008957\ttest: 0.0515964\tbest: 0.0515823 (606)\ttotal: 3.6s\tremaining: 54.3s\n",
      "622:\tlearn: 0.0008872\ttest: 0.0515960\tbest: 0.0515823 (606)\ttotal: 3.61s\tremaining: 54.3s\n",
      "623:\tlearn: 0.0008807\ttest: 0.0515963\tbest: 0.0515823 (606)\ttotal: 3.62s\tremaining: 54.3s\n",
      "624:\tlearn: 0.0008750\ttest: 0.0515921\tbest: 0.0515823 (606)\ttotal: 3.62s\tremaining: 54.3s\n",
      "625:\tlearn: 0.0008673\ttest: 0.0515910\tbest: 0.0515823 (606)\ttotal: 3.63s\tremaining: 54.3s\n",
      "626:\tlearn: 0.0008623\ttest: 0.0515910\tbest: 0.0515823 (606)\ttotal: 3.63s\tremaining: 54.4s\n",
      "627:\tlearn: 0.0008564\ttest: 0.0515923\tbest: 0.0515823 (606)\ttotal: 3.64s\tremaining: 54.4s\n",
      "628:\tlearn: 0.0008529\ttest: 0.0515932\tbest: 0.0515823 (606)\ttotal: 3.65s\tremaining: 54.4s\n",
      "629:\tlearn: 0.0008454\ttest: 0.0515903\tbest: 0.0515823 (606)\ttotal: 3.65s\tremaining: 54.4s\n",
      "630:\tlearn: 0.0008393\ttest: 0.0515888\tbest: 0.0515823 (606)\ttotal: 3.66s\tremaining: 54.4s\n",
      "631:\tlearn: 0.0008346\ttest: 0.0515882\tbest: 0.0515823 (606)\ttotal: 3.67s\tremaining: 54.4s\n",
      "632:\tlearn: 0.0008285\ttest: 0.0515862\tbest: 0.0515823 (606)\ttotal: 3.67s\tremaining: 54.4s\n",
      "633:\tlearn: 0.0008208\ttest: 0.0515841\tbest: 0.0515823 (606)\ttotal: 3.68s\tremaining: 54.4s\n",
      "634:\tlearn: 0.0008173\ttest: 0.0515844\tbest: 0.0515823 (606)\ttotal: 3.69s\tremaining: 54.4s\n",
      "635:\tlearn: 0.0008124\ttest: 0.0515843\tbest: 0.0515823 (606)\ttotal: 3.7s\tremaining: 54.4s\n",
      "636:\tlearn: 0.0008078\ttest: 0.0515850\tbest: 0.0515823 (606)\ttotal: 3.7s\tremaining: 54.4s\n",
      "637:\tlearn: 0.0008070\ttest: 0.0515851\tbest: 0.0515823 (606)\ttotal: 3.71s\tremaining: 54.4s\n",
      "638:\tlearn: 0.0008025\ttest: 0.0515862\tbest: 0.0515823 (606)\ttotal: 3.72s\tremaining: 54.4s\n",
      "639:\tlearn: 0.0007987\ttest: 0.0515857\tbest: 0.0515823 (606)\ttotal: 3.72s\tremaining: 54.4s\n",
      "640:\tlearn: 0.0007945\ttest: 0.0515880\tbest: 0.0515823 (606)\ttotal: 3.73s\tremaining: 54.4s\n",
      "641:\tlearn: 0.0007885\ttest: 0.0515864\tbest: 0.0515823 (606)\ttotal: 3.73s\tremaining: 54.5s\n",
      "642:\tlearn: 0.0007823\ttest: 0.0515831\tbest: 0.0515823 (606)\ttotal: 3.74s\tremaining: 54.4s\n",
      "643:\tlearn: 0.0007815\ttest: 0.0515832\tbest: 0.0515823 (606)\ttotal: 3.75s\tremaining: 54.4s\n",
      "644:\tlearn: 0.0007748\ttest: 0.0515833\tbest: 0.0515823 (606)\ttotal: 3.75s\tremaining: 54.4s\n",
      "645:\tlearn: 0.0007707\ttest: 0.0515860\tbest: 0.0515823 (606)\ttotal: 3.76s\tremaining: 54.4s\n",
      "646:\tlearn: 0.0007640\ttest: 0.0515841\tbest: 0.0515823 (606)\ttotal: 3.77s\tremaining: 54.4s\n",
      "647:\tlearn: 0.0007562\ttest: 0.0515841\tbest: 0.0515823 (606)\ttotal: 3.77s\tremaining: 54.4s\n",
      "648:\tlearn: 0.0007497\ttest: 0.0515825\tbest: 0.0515823 (606)\ttotal: 3.78s\tremaining: 54.4s\n",
      "649:\tlearn: 0.0007435\ttest: 0.0515818\tbest: 0.0515818 (649)\ttotal: 3.78s\tremaining: 54.4s\n",
      "650:\tlearn: 0.0007394\ttest: 0.0515829\tbest: 0.0515818 (649)\ttotal: 3.79s\tremaining: 54.5s\n",
      "651:\tlearn: 0.0007331\ttest: 0.0515831\tbest: 0.0515818 (649)\ttotal: 3.8s\tremaining: 54.5s\n",
      "652:\tlearn: 0.0007260\ttest: 0.0515861\tbest: 0.0515818 (649)\ttotal: 3.81s\tremaining: 54.5s\n",
      "653:\tlearn: 0.0007204\ttest: 0.0515859\tbest: 0.0515818 (649)\ttotal: 3.81s\tremaining: 54.5s\n",
      "654:\tlearn: 0.0007194\ttest: 0.0515863\tbest: 0.0515818 (649)\ttotal: 3.82s\tremaining: 54.5s\n",
      "655:\tlearn: 0.0007186\ttest: 0.0515858\tbest: 0.0515818 (649)\ttotal: 3.83s\tremaining: 54.5s\n",
      "656:\tlearn: 0.0007120\ttest: 0.0515857\tbest: 0.0515818 (649)\ttotal: 3.84s\tremaining: 54.6s\n",
      "657:\tlearn: 0.0007071\ttest: 0.0515844\tbest: 0.0515818 (649)\ttotal: 3.84s\tremaining: 54.6s\n",
      "658:\tlearn: 0.0007037\ttest: 0.0515848\tbest: 0.0515818 (649)\ttotal: 3.85s\tremaining: 54.6s\n",
      "659:\tlearn: 0.0006998\ttest: 0.0515848\tbest: 0.0515818 (649)\ttotal: 3.86s\tremaining: 54.6s\n",
      "660:\tlearn: 0.0006943\ttest: 0.0515870\tbest: 0.0515818 (649)\ttotal: 3.87s\tremaining: 54.6s\n",
      "661:\tlearn: 0.0006905\ttest: 0.0515842\tbest: 0.0515818 (649)\ttotal: 3.87s\tremaining: 54.6s\n",
      "662:\tlearn: 0.0006839\ttest: 0.0515855\tbest: 0.0515818 (649)\ttotal: 3.88s\tremaining: 54.6s\n",
      "663:\tlearn: 0.0006799\ttest: 0.0515824\tbest: 0.0515818 (649)\ttotal: 3.89s\tremaining: 54.7s\n",
      "664:\tlearn: 0.0006738\ttest: 0.0515821\tbest: 0.0515818 (649)\ttotal: 3.89s\tremaining: 54.7s\n",
      "665:\tlearn: 0.0006683\ttest: 0.0515799\tbest: 0.0515799 (665)\ttotal: 3.9s\tremaining: 54.7s\n",
      "666:\tlearn: 0.0006664\ttest: 0.0515809\tbest: 0.0515799 (665)\ttotal: 3.91s\tremaining: 54.7s\n",
      "667:\tlearn: 0.0006621\ttest: 0.0515801\tbest: 0.0515799 (665)\ttotal: 3.92s\tremaining: 54.7s\n",
      "668:\tlearn: 0.0006559\ttest: 0.0515808\tbest: 0.0515799 (665)\ttotal: 3.92s\tremaining: 54.7s\n",
      "669:\tlearn: 0.0006511\ttest: 0.0515813\tbest: 0.0515799 (665)\ttotal: 3.93s\tremaining: 54.7s\n",
      "670:\tlearn: 0.0006466\ttest: 0.0515808\tbest: 0.0515799 (665)\ttotal: 3.94s\tremaining: 54.7s\n",
      "671:\tlearn: 0.0006418\ttest: 0.0515790\tbest: 0.0515790 (671)\ttotal: 3.94s\tremaining: 54.7s\n",
      "672:\tlearn: 0.0006352\ttest: 0.0515767\tbest: 0.0515767 (672)\ttotal: 3.95s\tremaining: 54.7s\n",
      "673:\tlearn: 0.0006313\ttest: 0.0515765\tbest: 0.0515765 (673)\ttotal: 3.96s\tremaining: 54.8s\n",
      "674:\tlearn: 0.0006254\ttest: 0.0515766\tbest: 0.0515765 (673)\ttotal: 3.96s\tremaining: 54.8s\n",
      "675:\tlearn: 0.0006215\ttest: 0.0515779\tbest: 0.0515765 (673)\ttotal: 3.97s\tremaining: 54.8s\n",
      "676:\tlearn: 0.0006164\ttest: 0.0515766\tbest: 0.0515765 (673)\ttotal: 3.98s\tremaining: 54.8s\n",
      "677:\tlearn: 0.0006156\ttest: 0.0515763\tbest: 0.0515763 (677)\ttotal: 3.99s\tremaining: 54.8s\n",
      "678:\tlearn: 0.0006099\ttest: 0.0515740\tbest: 0.0515740 (678)\ttotal: 3.99s\tremaining: 54.8s\n",
      "679:\tlearn: 0.0006064\ttest: 0.0515757\tbest: 0.0515740 (678)\ttotal: 4s\tremaining: 54.8s\n",
      "680:\tlearn: 0.0005993\ttest: 0.0515758\tbest: 0.0515740 (678)\ttotal: 4.01s\tremaining: 54.9s\n",
      "681:\tlearn: 0.0005947\ttest: 0.0515751\tbest: 0.0515740 (678)\ttotal: 4.01s\tremaining: 54.9s\n",
      "682:\tlearn: 0.0005907\ttest: 0.0515751\tbest: 0.0515740 (678)\ttotal: 4.02s\tremaining: 54.9s\n",
      "683:\tlearn: 0.0005900\ttest: 0.0515756\tbest: 0.0515740 (678)\ttotal: 4.03s\tremaining: 54.9s\n",
      "684:\tlearn: 0.0005849\ttest: 0.0515764\tbest: 0.0515740 (678)\ttotal: 4.04s\tremaining: 54.9s\n",
      "685:\tlearn: 0.0005841\ttest: 0.0515767\tbest: 0.0515740 (678)\ttotal: 4.04s\tremaining: 54.9s\n",
      "686:\tlearn: 0.0005784\ttest: 0.0515784\tbest: 0.0515740 (678)\ttotal: 4.05s\tremaining: 54.9s\n",
      "687:\tlearn: 0.0005724\ttest: 0.0515807\tbest: 0.0515740 (678)\ttotal: 4.06s\tremaining: 54.9s\n",
      "688:\tlearn: 0.0005716\ttest: 0.0515813\tbest: 0.0515740 (678)\ttotal: 4.07s\tremaining: 54.9s\n",
      "689:\tlearn: 0.0005676\ttest: 0.0515805\tbest: 0.0515740 (678)\ttotal: 4.07s\tremaining: 54.9s\n",
      "690:\tlearn: 0.0005612\ttest: 0.0515794\tbest: 0.0515740 (678)\ttotal: 4.08s\tremaining: 55s\n",
      "691:\tlearn: 0.0005585\ttest: 0.0515792\tbest: 0.0515740 (678)\ttotal: 4.09s\tremaining: 55s\n",
      "692:\tlearn: 0.0005553\ttest: 0.0515806\tbest: 0.0515740 (678)\ttotal: 4.09s\tremaining: 55s\n",
      "693:\tlearn: 0.0005529\ttest: 0.0515794\tbest: 0.0515740 (678)\ttotal: 4.1s\tremaining: 55s\n",
      "694:\tlearn: 0.0005474\ttest: 0.0515789\tbest: 0.0515740 (678)\ttotal: 4.11s\tremaining: 55s\n",
      "695:\tlearn: 0.0005434\ttest: 0.0515800\tbest: 0.0515740 (678)\ttotal: 4.11s\tremaining: 55s\n",
      "696:\tlearn: 0.0005391\ttest: 0.0515781\tbest: 0.0515740 (678)\ttotal: 4.12s\tremaining: 55s\n",
      "697:\tlearn: 0.0005360\ttest: 0.0515781\tbest: 0.0515740 (678)\ttotal: 4.13s\tremaining: 55s\n",
      "698:\tlearn: 0.0005341\ttest: 0.0515788\tbest: 0.0515740 (678)\ttotal: 4.13s\tremaining: 55s\n",
      "699:\tlearn: 0.0005312\ttest: 0.0515796\tbest: 0.0515740 (678)\ttotal: 4.14s\tremaining: 55s\n",
      "700:\tlearn: 0.0005273\ttest: 0.0515790\tbest: 0.0515740 (678)\ttotal: 4.15s\tremaining: 55s\n",
      "701:\tlearn: 0.0005233\ttest: 0.0515794\tbest: 0.0515740 (678)\ttotal: 4.16s\tremaining: 55s\n",
      "702:\tlearn: 0.0005198\ttest: 0.0515804\tbest: 0.0515740 (678)\ttotal: 4.16s\tremaining: 55.1s\n",
      "703:\tlearn: 0.0005194\ttest: 0.0515801\tbest: 0.0515740 (678)\ttotal: 4.17s\tremaining: 55.1s\n",
      "704:\tlearn: 0.0005163\ttest: 0.0515828\tbest: 0.0515740 (678)\ttotal: 4.18s\tremaining: 55.1s\n",
      "705:\tlearn: 0.0005126\ttest: 0.0515823\tbest: 0.0515740 (678)\ttotal: 4.18s\tremaining: 55.1s\n",
      "706:\tlearn: 0.0005077\ttest: 0.0515815\tbest: 0.0515740 (678)\ttotal: 4.19s\tremaining: 55.1s\n",
      "707:\tlearn: 0.0005042\ttest: 0.0515817\tbest: 0.0515740 (678)\ttotal: 4.2s\tremaining: 55.1s\n",
      "708:\tlearn: 0.0005006\ttest: 0.0515804\tbest: 0.0515740 (678)\ttotal: 4.21s\tremaining: 55.1s\n",
      "709:\tlearn: 0.0004979\ttest: 0.0515800\tbest: 0.0515740 (678)\ttotal: 4.21s\tremaining: 55.1s\n",
      "710:\tlearn: 0.0004946\ttest: 0.0515778\tbest: 0.0515740 (678)\ttotal: 4.22s\tremaining: 55.2s\n",
      "711:\tlearn: 0.0004896\ttest: 0.0515773\tbest: 0.0515740 (678)\ttotal: 4.23s\tremaining: 55.2s\n",
      "712:\tlearn: 0.0004887\ttest: 0.0515768\tbest: 0.0515740 (678)\ttotal: 4.24s\tremaining: 55.2s\n",
      "713:\tlearn: 0.0004862\ttest: 0.0515772\tbest: 0.0515740 (678)\ttotal: 4.24s\tremaining: 55.2s\n",
      "714:\tlearn: 0.0004819\ttest: 0.0515755\tbest: 0.0515740 (678)\ttotal: 4.25s\tremaining: 55.2s\n",
      "715:\tlearn: 0.0004800\ttest: 0.0515756\tbest: 0.0515740 (678)\ttotal: 4.26s\tremaining: 55.2s\n",
      "716:\tlearn: 0.0004762\ttest: 0.0515748\tbest: 0.0515740 (678)\ttotal: 4.27s\tremaining: 55.2s\n",
      "717:\tlearn: 0.0004739\ttest: 0.0515746\tbest: 0.0515740 (678)\ttotal: 4.27s\tremaining: 55.3s\n",
      "718:\tlearn: 0.0004723\ttest: 0.0515750\tbest: 0.0515740 (678)\ttotal: 4.28s\tremaining: 55.3s\n",
      "719:\tlearn: 0.0004684\ttest: 0.0515743\tbest: 0.0515740 (678)\ttotal: 4.29s\tremaining: 55.3s\n",
      "720:\tlearn: 0.0004654\ttest: 0.0515747\tbest: 0.0515740 (678)\ttotal: 4.3s\tremaining: 55.3s\n",
      "721:\tlearn: 0.0004631\ttest: 0.0515751\tbest: 0.0515740 (678)\ttotal: 4.31s\tremaining: 55.4s\n",
      "722:\tlearn: 0.0004596\ttest: 0.0515739\tbest: 0.0515739 (722)\ttotal: 4.32s\tremaining: 55.4s\n",
      "723:\tlearn: 0.0004590\ttest: 0.0515738\tbest: 0.0515738 (723)\ttotal: 4.33s\tremaining: 55.5s\n",
      "724:\tlearn: 0.0004561\ttest: 0.0515736\tbest: 0.0515736 (724)\ttotal: 4.34s\tremaining: 55.5s\n",
      "725:\tlearn: 0.0004540\ttest: 0.0515742\tbest: 0.0515736 (724)\ttotal: 4.34s\tremaining: 55.5s\n",
      "726:\tlearn: 0.0004498\ttest: 0.0515723\tbest: 0.0515723 (726)\ttotal: 4.35s\tremaining: 55.5s\n",
      "727:\tlearn: 0.0004470\ttest: 0.0515730\tbest: 0.0515723 (726)\ttotal: 4.36s\tremaining: 55.5s\n",
      "728:\tlearn: 0.0004436\ttest: 0.0515731\tbest: 0.0515723 (726)\ttotal: 4.37s\tremaining: 55.6s\n",
      "729:\tlearn: 0.0004399\ttest: 0.0515714\tbest: 0.0515714 (729)\ttotal: 4.38s\tremaining: 55.6s\n",
      "730:\tlearn: 0.0004363\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 4.38s\tremaining: 55.6s\n",
      "731:\tlearn: 0.0004327\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 4.39s\tremaining: 55.6s\n",
      "732:\tlearn: 0.0004299\ttest: 0.0515748\tbest: 0.0515714 (729)\ttotal: 4.4s\tremaining: 55.6s\n",
      "733:\tlearn: 0.0004272\ttest: 0.0515747\tbest: 0.0515714 (729)\ttotal: 4.41s\tremaining: 55.6s\n",
      "734:\tlearn: 0.0004266\ttest: 0.0515751\tbest: 0.0515714 (729)\ttotal: 4.42s\tremaining: 55.7s\n",
      "735:\tlearn: 0.0004259\ttest: 0.0515751\tbest: 0.0515714 (729)\ttotal: 4.42s\tremaining: 55.7s\n",
      "736:\tlearn: 0.0004216\ttest: 0.0515769\tbest: 0.0515714 (729)\ttotal: 4.43s\tremaining: 55.7s\n",
      "737:\tlearn: 0.0004181\ttest: 0.0515772\tbest: 0.0515714 (729)\ttotal: 4.44s\tremaining: 55.7s\n",
      "738:\tlearn: 0.0004170\ttest: 0.0515771\tbest: 0.0515714 (729)\ttotal: 4.45s\tremaining: 55.7s\n",
      "739:\tlearn: 0.0004140\ttest: 0.0515778\tbest: 0.0515714 (729)\ttotal: 4.45s\tremaining: 55.7s\n",
      "740:\tlearn: 0.0004136\ttest: 0.0515774\tbest: 0.0515714 (729)\ttotal: 4.46s\tremaining: 55.7s\n",
      "741:\tlearn: 0.0004130\ttest: 0.0515772\tbest: 0.0515714 (729)\ttotal: 4.47s\tremaining: 55.7s\n",
      "742:\tlearn: 0.0004099\ttest: 0.0515785\tbest: 0.0515714 (729)\ttotal: 4.47s\tremaining: 55.8s\n",
      "743:\tlearn: 0.0004073\ttest: 0.0515780\tbest: 0.0515714 (729)\ttotal: 4.48s\tremaining: 55.8s\n",
      "744:\tlearn: 0.0004050\ttest: 0.0515781\tbest: 0.0515714 (729)\ttotal: 4.49s\tremaining: 55.8s\n",
      "745:\tlearn: 0.0004010\ttest: 0.0515772\tbest: 0.0515714 (729)\ttotal: 4.5s\tremaining: 55.8s\n",
      "746:\tlearn: 0.0003976\ttest: 0.0515770\tbest: 0.0515714 (729)\ttotal: 4.51s\tremaining: 55.8s\n",
      "747:\tlearn: 0.0003950\ttest: 0.0515774\tbest: 0.0515714 (729)\ttotal: 4.52s\tremaining: 55.9s\n",
      "748:\tlearn: 0.0003918\ttest: 0.0515759\tbest: 0.0515714 (729)\ttotal: 4.53s\tremaining: 55.9s\n",
      "749:\tlearn: 0.0003886\ttest: 0.0515762\tbest: 0.0515714 (729)\ttotal: 4.53s\tremaining: 55.9s\n",
      "750:\tlearn: 0.0003859\ttest: 0.0515768\tbest: 0.0515714 (729)\ttotal: 4.54s\tremaining: 55.9s\n",
      "751:\tlearn: 0.0003826\ttest: 0.0515763\tbest: 0.0515714 (729)\ttotal: 4.55s\tremaining: 56s\n",
      "752:\tlearn: 0.0003821\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 4.56s\tremaining: 56s\n",
      "753:\tlearn: 0.0003792\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 4.57s\tremaining: 56s\n",
      "754:\tlearn: 0.0003773\ttest: 0.0515768\tbest: 0.0515714 (729)\ttotal: 4.57s\tremaining: 56s\n",
      "755:\tlearn: 0.0003750\ttest: 0.0515771\tbest: 0.0515714 (729)\ttotal: 4.58s\tremaining: 56s\n",
      "756:\tlearn: 0.0003729\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 4.59s\tremaining: 56s\n",
      "757:\tlearn: 0.0003712\ttest: 0.0515766\tbest: 0.0515714 (729)\ttotal: 4.6s\tremaining: 56s\n",
      "758:\tlearn: 0.0003679\ttest: 0.0515761\tbest: 0.0515714 (729)\ttotal: 4.6s\tremaining: 56.1s\n",
      "759:\tlearn: 0.0003645\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 4.61s\tremaining: 56.1s\n",
      "760:\tlearn: 0.0003611\ttest: 0.0515760\tbest: 0.0515714 (729)\ttotal: 4.62s\tremaining: 56.1s\n",
      "761:\tlearn: 0.0003591\ttest: 0.0515756\tbest: 0.0515714 (729)\ttotal: 4.63s\tremaining: 56.1s\n",
      "762:\tlearn: 0.0003587\ttest: 0.0515755\tbest: 0.0515714 (729)\ttotal: 4.63s\tremaining: 56.1s\n",
      "763:\tlearn: 0.0003580\ttest: 0.0515759\tbest: 0.0515714 (729)\ttotal: 4.64s\tremaining: 56.1s\n",
      "764:\tlearn: 0.0003542\ttest: 0.0515763\tbest: 0.0515714 (729)\ttotal: 4.65s\tremaining: 56.1s\n",
      "765:\tlearn: 0.0003516\ttest: 0.0515771\tbest: 0.0515714 (729)\ttotal: 4.66s\tremaining: 56.1s\n",
      "766:\tlearn: 0.0003483\ttest: 0.0515774\tbest: 0.0515714 (729)\ttotal: 4.66s\tremaining: 56.1s\n",
      "767:\tlearn: 0.0003450\ttest: 0.0515786\tbest: 0.0515714 (729)\ttotal: 4.67s\tremaining: 56.1s\n",
      "768:\tlearn: 0.0003415\ttest: 0.0515774\tbest: 0.0515714 (729)\ttotal: 4.68s\tremaining: 56.1s\n",
      "769:\tlearn: 0.0003395\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 4.68s\tremaining: 56.2s\n",
      "770:\tlearn: 0.0003370\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 4.69s\tremaining: 56.2s\n",
      "771:\tlearn: 0.0003351\ttest: 0.0515767\tbest: 0.0515714 (729)\ttotal: 4.7s\tremaining: 56.2s\n",
      "772:\tlearn: 0.0003327\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 4.71s\tremaining: 56.2s\n",
      "773:\tlearn: 0.0003298\ttest: 0.0515763\tbest: 0.0515714 (729)\ttotal: 4.71s\tremaining: 56.2s\n",
      "774:\tlearn: 0.0003264\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 4.72s\tremaining: 56.2s\n",
      "775:\tlearn: 0.0003249\ttest: 0.0515759\tbest: 0.0515714 (729)\ttotal: 4.73s\tremaining: 56.2s\n",
      "776:\tlearn: 0.0003226\ttest: 0.0515758\tbest: 0.0515714 (729)\ttotal: 4.74s\tremaining: 56.2s\n",
      "777:\tlearn: 0.0003223\ttest: 0.0515758\tbest: 0.0515714 (729)\ttotal: 4.74s\tremaining: 56.2s\n",
      "778:\tlearn: 0.0003220\ttest: 0.0515761\tbest: 0.0515714 (729)\ttotal: 4.75s\tremaining: 56.2s\n",
      "779:\tlearn: 0.0003195\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 4.76s\tremaining: 56.2s\n",
      "780:\tlearn: 0.0003180\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 4.77s\tremaining: 56.3s\n",
      "781:\tlearn: 0.0003156\ttest: 0.0515778\tbest: 0.0515714 (729)\ttotal: 4.77s\tremaining: 56.3s\n",
      "782:\tlearn: 0.0003152\ttest: 0.0515778\tbest: 0.0515714 (729)\ttotal: 4.78s\tremaining: 56.3s\n",
      "783:\tlearn: 0.0003132\ttest: 0.0515780\tbest: 0.0515714 (729)\ttotal: 4.79s\tremaining: 56.3s\n",
      "784:\tlearn: 0.0003126\ttest: 0.0515785\tbest: 0.0515714 (729)\ttotal: 4.79s\tremaining: 56.3s\n",
      "785:\tlearn: 0.0003101\ttest: 0.0515776\tbest: 0.0515714 (729)\ttotal: 4.8s\tremaining: 56.3s\n",
      "786:\tlearn: 0.0003084\ttest: 0.0515775\tbest: 0.0515714 (729)\ttotal: 4.81s\tremaining: 56.3s\n",
      "787:\tlearn: 0.0003051\ttest: 0.0515785\tbest: 0.0515714 (729)\ttotal: 4.82s\tremaining: 56.3s\n",
      "788:\tlearn: 0.0003029\ttest: 0.0515792\tbest: 0.0515714 (729)\ttotal: 4.83s\tremaining: 56.3s\n",
      "789:\tlearn: 0.0003001\ttest: 0.0515804\tbest: 0.0515714 (729)\ttotal: 4.83s\tremaining: 56.3s\n",
      "790:\tlearn: 0.0002988\ttest: 0.0515802\tbest: 0.0515714 (729)\ttotal: 4.84s\tremaining: 56.3s\n",
      "791:\tlearn: 0.0002963\ttest: 0.0515800\tbest: 0.0515714 (729)\ttotal: 4.85s\tremaining: 56.4s\n",
      "792:\tlearn: 0.0002931\ttest: 0.0515791\tbest: 0.0515714 (729)\ttotal: 4.86s\tremaining: 56.4s\n",
      "793:\tlearn: 0.0002922\ttest: 0.0515794\tbest: 0.0515714 (729)\ttotal: 4.86s\tremaining: 56.4s\n",
      "794:\tlearn: 0.0002896\ttest: 0.0515805\tbest: 0.0515714 (729)\ttotal: 4.87s\tremaining: 56.4s\n",
      "795:\tlearn: 0.0002868\ttest: 0.0515808\tbest: 0.0515714 (729)\ttotal: 4.88s\tremaining: 56.4s\n",
      "796:\tlearn: 0.0002864\ttest: 0.0515807\tbest: 0.0515714 (729)\ttotal: 4.89s\tremaining: 56.4s\n",
      "797:\tlearn: 0.0002849\ttest: 0.0515804\tbest: 0.0515714 (729)\ttotal: 4.89s\tremaining: 56.4s\n",
      "798:\tlearn: 0.0002831\ttest: 0.0515803\tbest: 0.0515714 (729)\ttotal: 4.9s\tremaining: 56.5s\n",
      "799:\tlearn: 0.0002808\ttest: 0.0515797\tbest: 0.0515714 (729)\ttotal: 4.91s\tremaining: 56.5s\n",
      "800:\tlearn: 0.0002781\ttest: 0.0515785\tbest: 0.0515714 (729)\ttotal: 4.92s\tremaining: 56.5s\n",
      "801:\tlearn: 0.0002778\ttest: 0.0515787\tbest: 0.0515714 (729)\ttotal: 4.93s\tremaining: 56.5s\n",
      "802:\tlearn: 0.0002773\ttest: 0.0515791\tbest: 0.0515714 (729)\ttotal: 4.93s\tremaining: 56.5s\n",
      "803:\tlearn: 0.0002750\ttest: 0.0515791\tbest: 0.0515714 (729)\ttotal: 4.94s\tremaining: 56.5s\n",
      "804:\tlearn: 0.0002740\ttest: 0.0515785\tbest: 0.0515714 (729)\ttotal: 4.95s\tremaining: 56.5s\n",
      "805:\tlearn: 0.0002718\ttest: 0.0515780\tbest: 0.0515714 (729)\ttotal: 4.96s\tremaining: 56.5s\n",
      "806:\tlearn: 0.0002692\ttest: 0.0515791\tbest: 0.0515714 (729)\ttotal: 4.96s\tremaining: 56.5s\n",
      "807:\tlearn: 0.0002671\ttest: 0.0515795\tbest: 0.0515714 (729)\ttotal: 4.97s\tremaining: 56.5s\n",
      "808:\tlearn: 0.0002656\ttest: 0.0515796\tbest: 0.0515714 (729)\ttotal: 4.98s\tremaining: 56.6s\n",
      "809:\tlearn: 0.0002637\ttest: 0.0515807\tbest: 0.0515714 (729)\ttotal: 4.99s\tremaining: 56.6s\n",
      "810:\tlearn: 0.0002614\ttest: 0.0515813\tbest: 0.0515714 (729)\ttotal: 4.99s\tremaining: 56.6s\n",
      "811:\tlearn: 0.0002602\ttest: 0.0515809\tbest: 0.0515714 (729)\ttotal: 5s\tremaining: 56.6s\n",
      "812:\tlearn: 0.0002599\ttest: 0.0515809\tbest: 0.0515714 (729)\ttotal: 5.01s\tremaining: 56.6s\n",
      "813:\tlearn: 0.0002580\ttest: 0.0515808\tbest: 0.0515714 (729)\ttotal: 5.01s\tremaining: 56.6s\n",
      "814:\tlearn: 0.0002556\ttest: 0.0515809\tbest: 0.0515714 (729)\ttotal: 5.02s\tremaining: 56.6s\n",
      "815:\tlearn: 0.0002543\ttest: 0.0515805\tbest: 0.0515714 (729)\ttotal: 5.03s\tremaining: 56.6s\n",
      "816:\tlearn: 0.0002529\ttest: 0.0515803\tbest: 0.0515714 (729)\ttotal: 5.04s\tremaining: 56.6s\n",
      "817:\tlearn: 0.0002508\ttest: 0.0515800\tbest: 0.0515714 (729)\ttotal: 5.04s\tremaining: 56.6s\n",
      "818:\tlearn: 0.0002503\ttest: 0.0515800\tbest: 0.0515714 (729)\ttotal: 5.05s\tremaining: 56.6s\n",
      "819:\tlearn: 0.0002481\ttest: 0.0515796\tbest: 0.0515714 (729)\ttotal: 5.06s\tremaining: 56.6s\n",
      "820:\tlearn: 0.0002477\ttest: 0.0515796\tbest: 0.0515714 (729)\ttotal: 5.07s\tremaining: 56.6s\n",
      "821:\tlearn: 0.0002461\ttest: 0.0515793\tbest: 0.0515714 (729)\ttotal: 5.07s\tremaining: 56.6s\n",
      "822:\tlearn: 0.0002444\ttest: 0.0515784\tbest: 0.0515714 (729)\ttotal: 5.08s\tremaining: 56.6s\n",
      "823:\tlearn: 0.0002433\ttest: 0.0515779\tbest: 0.0515714 (729)\ttotal: 5.09s\tremaining: 56.7s\n",
      "824:\tlearn: 0.0002416\ttest: 0.0515779\tbest: 0.0515714 (729)\ttotal: 5.09s\tremaining: 56.7s\n",
      "825:\tlearn: 0.0002398\ttest: 0.0515787\tbest: 0.0515714 (729)\ttotal: 5.1s\tremaining: 56.7s\n",
      "826:\tlearn: 0.0002379\ttest: 0.0515789\tbest: 0.0515714 (729)\ttotal: 5.11s\tremaining: 56.7s\n",
      "827:\tlearn: 0.0002364\ttest: 0.0515788\tbest: 0.0515714 (729)\ttotal: 5.12s\tremaining: 56.7s\n",
      "828:\tlearn: 0.0002344\ttest: 0.0515783\tbest: 0.0515714 (729)\ttotal: 5.12s\tremaining: 56.7s\n",
      "829:\tlearn: 0.0002320\ttest: 0.0515778\tbest: 0.0515714 (729)\ttotal: 5.13s\tremaining: 56.7s\n",
      "830:\tlearn: 0.0002302\ttest: 0.0515778\tbest: 0.0515714 (729)\ttotal: 5.14s\tremaining: 56.7s\n",
      "831:\tlearn: 0.0002286\ttest: 0.0515780\tbest: 0.0515714 (729)\ttotal: 5.14s\tremaining: 56.7s\n",
      "832:\tlearn: 0.0002272\ttest: 0.0515782\tbest: 0.0515714 (729)\ttotal: 5.15s\tremaining: 56.7s\n",
      "833:\tlearn: 0.0002270\ttest: 0.0515779\tbest: 0.0515714 (729)\ttotal: 5.16s\tremaining: 56.7s\n",
      "834:\tlearn: 0.0002258\ttest: 0.0515774\tbest: 0.0515714 (729)\ttotal: 5.17s\tremaining: 56.7s\n",
      "835:\tlearn: 0.0002246\ttest: 0.0515773\tbest: 0.0515714 (729)\ttotal: 5.17s\tremaining: 56.7s\n",
      "836:\tlearn: 0.0002233\ttest: 0.0515767\tbest: 0.0515714 (729)\ttotal: 5.18s\tremaining: 56.7s\n",
      "837:\tlearn: 0.0002215\ttest: 0.0515769\tbest: 0.0515714 (729)\ttotal: 5.19s\tremaining: 56.7s\n",
      "838:\tlearn: 0.0002198\ttest: 0.0515768\tbest: 0.0515714 (729)\ttotal: 5.2s\tremaining: 56.8s\n",
      "839:\tlearn: 0.0002191\ttest: 0.0515766\tbest: 0.0515714 (729)\ttotal: 5.21s\tremaining: 56.8s\n",
      "840:\tlearn: 0.0002171\ttest: 0.0515767\tbest: 0.0515714 (729)\ttotal: 5.21s\tremaining: 56.8s\n",
      "841:\tlearn: 0.0002156\ttest: 0.0515765\tbest: 0.0515714 (729)\ttotal: 5.22s\tremaining: 56.8s\n",
      "842:\tlearn: 0.0002135\ttest: 0.0515771\tbest: 0.0515714 (729)\ttotal: 5.23s\tremaining: 56.8s\n",
      "843:\tlearn: 0.0002117\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 5.24s\tremaining: 56.8s\n",
      "844:\tlearn: 0.0002109\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 5.25s\tremaining: 56.8s\n",
      "845:\tlearn: 0.0002100\ttest: 0.0515763\tbest: 0.0515714 (729)\ttotal: 5.25s\tremaining: 56.8s\n",
      "846:\tlearn: 0.0002088\ttest: 0.0515764\tbest: 0.0515714 (729)\ttotal: 5.26s\tremaining: 56.8s\n",
      "847:\tlearn: 0.0002084\ttest: 0.0515762\tbest: 0.0515714 (729)\ttotal: 5.27s\tremaining: 56.8s\n",
      "848:\tlearn: 0.0002069\ttest: 0.0515763\tbest: 0.0515714 (729)\ttotal: 5.27s\tremaining: 56.8s\n",
      "849:\tlearn: 0.0002062\ttest: 0.0515762\tbest: 0.0515714 (729)\ttotal: 5.28s\tremaining: 56.8s\n",
      "850:\tlearn: 0.0002048\ttest: 0.0515759\tbest: 0.0515714 (729)\ttotal: 5.29s\tremaining: 56.8s\n",
      "851:\tlearn: 0.0002037\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.29s\tremaining: 56.8s\n",
      "852:\tlearn: 0.0002016\ttest: 0.0515758\tbest: 0.0515714 (729)\ttotal: 5.3s\tremaining: 56.8s\n",
      "853:\tlearn: 0.0002002\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.31s\tremaining: 56.8s\n",
      "854:\tlearn: 0.0001986\ttest: 0.0515754\tbest: 0.0515714 (729)\ttotal: 5.31s\tremaining: 56.8s\n",
      "855:\tlearn: 0.0001975\ttest: 0.0515749\tbest: 0.0515714 (729)\ttotal: 5.32s\tremaining: 56.8s\n",
      "856:\tlearn: 0.0001962\ttest: 0.0515749\tbest: 0.0515714 (729)\ttotal: 5.33s\tremaining: 56.9s\n",
      "857:\tlearn: 0.0001947\ttest: 0.0515755\tbest: 0.0515714 (729)\ttotal: 5.34s\tremaining: 56.9s\n",
      "858:\tlearn: 0.0001931\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.35s\tremaining: 56.9s\n",
      "859:\tlearn: 0.0001913\ttest: 0.0515750\tbest: 0.0515714 (729)\ttotal: 5.36s\tremaining: 56.9s\n",
      "860:\tlearn: 0.0001899\ttest: 0.0515748\tbest: 0.0515714 (729)\ttotal: 5.37s\tremaining: 57s\n",
      "861:\tlearn: 0.0001887\ttest: 0.0515748\tbest: 0.0515714 (729)\ttotal: 5.37s\tremaining: 57s\n",
      "862:\tlearn: 0.0001880\ttest: 0.0515746\tbest: 0.0515714 (729)\ttotal: 5.38s\tremaining: 57s\n",
      "863:\tlearn: 0.0001868\ttest: 0.0515746\tbest: 0.0515714 (729)\ttotal: 5.39s\tremaining: 57s\n",
      "864:\tlearn: 0.0001855\ttest: 0.0515745\tbest: 0.0515714 (729)\ttotal: 5.4s\tremaining: 57s\n",
      "865:\tlearn: 0.0001839\ttest: 0.0515750\tbest: 0.0515714 (729)\ttotal: 5.41s\tremaining: 57s\n",
      "866:\tlearn: 0.0001836\ttest: 0.0515751\tbest: 0.0515714 (729)\ttotal: 5.42s\tremaining: 57.1s\n",
      "867:\tlearn: 0.0001825\ttest: 0.0515754\tbest: 0.0515714 (729)\ttotal: 5.42s\tremaining: 57.1s\n",
      "868:\tlearn: 0.0001823\ttest: 0.0515754\tbest: 0.0515714 (729)\ttotal: 5.43s\tremaining: 57.1s\n",
      "869:\tlearn: 0.0001811\ttest: 0.0515756\tbest: 0.0515714 (729)\ttotal: 5.44s\tremaining: 57.1s\n",
      "870:\tlearn: 0.0001800\ttest: 0.0515755\tbest: 0.0515714 (729)\ttotal: 5.45s\tremaining: 57.1s\n",
      "871:\tlearn: 0.0001797\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.45s\tremaining: 57.1s\n",
      "872:\tlearn: 0.0001796\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.46s\tremaining: 57.1s\n",
      "873:\tlearn: 0.0001794\ttest: 0.0515758\tbest: 0.0515714 (729)\ttotal: 5.47s\tremaining: 57.1s\n",
      "874:\tlearn: 0.0001779\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.48s\tremaining: 57.1s\n",
      "875:\tlearn: 0.0001766\ttest: 0.0515753\tbest: 0.0515714 (729)\ttotal: 5.48s\tremaining: 57.1s\n",
      "876:\tlearn: 0.0001764\ttest: 0.0515753\tbest: 0.0515714 (729)\ttotal: 5.49s\tremaining: 57.1s\n",
      "877:\tlearn: 0.0001755\ttest: 0.0515754\tbest: 0.0515714 (729)\ttotal: 5.5s\tremaining: 57.1s\n",
      "878:\tlearn: 0.0001742\ttest: 0.0515753\tbest: 0.0515714 (729)\ttotal: 5.51s\tremaining: 57.1s\n",
      "879:\tlearn: 0.0001724\ttest: 0.0515757\tbest: 0.0515714 (729)\ttotal: 5.51s\tremaining: 57.1s\n",
      "880:\tlearn: 0.0001723\ttest: 0.0515756\tbest: 0.0515714 (729)\ttotal: 5.52s\tremaining: 57.1s\n",
      "881:\tlearn: 0.0001713\ttest: 0.0515756\tbest: 0.0515714 (729)\ttotal: 5.53s\tremaining: 57.1s\n",
      "882:\tlearn: 0.0001700\ttest: 0.0515756\tbest: 0.0515714 (729)\ttotal: 5.54s\tremaining: 57.1s\n",
      "883:\tlearn: 0.0001697\ttest: 0.0515754\tbest: 0.0515714 (729)\ttotal: 5.54s\tremaining: 57.2s\n",
      "884:\tlearn: 0.0001682\ttest: 0.0515750\tbest: 0.0515714 (729)\ttotal: 5.55s\tremaining: 57.2s\n",
      "885:\tlearn: 0.0001675\ttest: 0.0515750\tbest: 0.0515714 (729)\ttotal: 5.56s\tremaining: 57.2s\n",
      "886:\tlearn: 0.0001663\ttest: 0.0515745\tbest: 0.0515714 (729)\ttotal: 5.57s\tremaining: 57.2s\n",
      "887:\tlearn: 0.0001661\ttest: 0.0515744\tbest: 0.0515714 (729)\ttotal: 5.57s\tremaining: 57.2s\n",
      "888:\tlearn: 0.0001659\ttest: 0.0515747\tbest: 0.0515714 (729)\ttotal: 5.58s\tremaining: 57.2s\n",
      "889:\tlearn: 0.0001657\ttest: 0.0515747\tbest: 0.0515714 (729)\ttotal: 5.59s\tremaining: 57.2s\n",
      "890:\tlearn: 0.0001646\ttest: 0.0515744\tbest: 0.0515714 (729)\ttotal: 5.6s\tremaining: 57.2s\n",
      "891:\tlearn: 0.0001630\ttest: 0.0515747\tbest: 0.0515714 (729)\ttotal: 5.61s\tremaining: 57.2s\n",
      "892:\tlearn: 0.0001629\ttest: 0.0515746\tbest: 0.0515714 (729)\ttotal: 5.61s\tremaining: 57.2s\n",
      "893:\tlearn: 0.0001613\ttest: 0.0515748\tbest: 0.0515714 (729)\ttotal: 5.62s\tremaining: 57.3s\n",
      "894:\tlearn: 0.0001596\ttest: 0.0515748\tbest: 0.0515714 (729)\ttotal: 5.63s\tremaining: 57.3s\n",
      "895:\tlearn: 0.0001585\ttest: 0.0515746\tbest: 0.0515714 (729)\ttotal: 5.63s\tremaining: 57.3s\n",
      "896:\tlearn: 0.0001568\ttest: 0.0515746\tbest: 0.0515714 (729)\ttotal: 5.64s\tremaining: 57.3s\n",
      "897:\tlearn: 0.0001566\ttest: 0.0515742\tbest: 0.0515714 (729)\ttotal: 5.65s\tremaining: 57.3s\n",
      "898:\tlearn: 0.0001555\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 5.66s\tremaining: 57.3s\n",
      "899:\tlearn: 0.0001551\ttest: 0.0515741\tbest: 0.0515714 (729)\ttotal: 5.67s\tremaining: 57.3s\n",
      "900:\tlearn: 0.0001539\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 5.67s\tremaining: 57.3s\n",
      "901:\tlearn: 0.0001526\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 5.68s\tremaining: 57.3s\n",
      "902:\tlearn: 0.0001518\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 5.69s\tremaining: 57.3s\n",
      "903:\tlearn: 0.0001507\ttest: 0.0515743\tbest: 0.0515714 (729)\ttotal: 5.7s\tremaining: 57.3s\n",
      "904:\tlearn: 0.0001492\ttest: 0.0515741\tbest: 0.0515714 (729)\ttotal: 5.7s\tremaining: 57.3s\n",
      "905:\tlearn: 0.0001484\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.71s\tremaining: 57.3s\n",
      "906:\tlearn: 0.0001477\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.72s\tremaining: 57.3s\n",
      "907:\tlearn: 0.0001465\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 5.73s\tremaining: 57.4s\n",
      "908:\tlearn: 0.0001454\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.73s\tremaining: 57.4s\n",
      "909:\tlearn: 0.0001439\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 5.74s\tremaining: 57.4s\n",
      "910:\tlearn: 0.0001434\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 5.75s\tremaining: 57.4s\n",
      "911:\tlearn: 0.0001424\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.76s\tremaining: 57.4s\n",
      "912:\tlearn: 0.0001410\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 5.77s\tremaining: 57.4s\n",
      "913:\tlearn: 0.0001403\ttest: 0.0515741\tbest: 0.0515714 (729)\ttotal: 5.77s\tremaining: 57.4s\n",
      "914:\tlearn: 0.0001393\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.78s\tremaining: 57.4s\n",
      "915:\tlearn: 0.0001387\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.79s\tremaining: 57.4s\n",
      "916:\tlearn: 0.0001385\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 5.8s\tremaining: 57.4s\n",
      "917:\tlearn: 0.0001384\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 5.8s\tremaining: 57.4s\n",
      "918:\tlearn: 0.0001375\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 5.81s\tremaining: 57.4s\n",
      "919:\tlearn: 0.0001374\ttest: 0.0515728\tbest: 0.0515714 (729)\ttotal: 5.82s\tremaining: 57.4s\n",
      "920:\tlearn: 0.0001363\ttest: 0.0515727\tbest: 0.0515714 (729)\ttotal: 5.83s\tremaining: 57.4s\n",
      "921:\tlearn: 0.0001361\ttest: 0.0515727\tbest: 0.0515714 (729)\ttotal: 5.83s\tremaining: 57.4s\n",
      "922:\tlearn: 0.0001348\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 5.84s\tremaining: 57.5s\n",
      "923:\tlearn: 0.0001340\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 5.85s\tremaining: 57.5s\n",
      "924:\tlearn: 0.0001328\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 5.86s\tremaining: 57.5s\n",
      "925:\tlearn: 0.0001327\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 5.87s\tremaining: 57.5s\n",
      "926:\tlearn: 0.0001326\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 5.87s\tremaining: 57.5s\n",
      "927:\tlearn: 0.0001318\ttest: 0.0515728\tbest: 0.0515714 (729)\ttotal: 5.88s\tremaining: 57.5s\n",
      "928:\tlearn: 0.0001317\ttest: 0.0515727\tbest: 0.0515714 (729)\ttotal: 5.89s\tremaining: 57.5s\n",
      "929:\tlearn: 0.0001307\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 5.9s\tremaining: 57.5s\n",
      "930:\tlearn: 0.0001304\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 5.9s\tremaining: 57.5s\n",
      "931:\tlearn: 0.0001293\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 5.91s\tremaining: 57.5s\n",
      "932:\tlearn: 0.0001285\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 5.92s\tremaining: 57.5s\n",
      "933:\tlearn: 0.0001276\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.93s\tremaining: 57.5s\n",
      "934:\tlearn: 0.0001275\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.94s\tremaining: 57.6s\n",
      "935:\tlearn: 0.0001271\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 5.95s\tremaining: 57.6s\n",
      "936:\tlearn: 0.0001266\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 5.95s\tremaining: 57.6s\n",
      "937:\tlearn: 0.0001253\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 5.96s\tremaining: 57.6s\n",
      "938:\tlearn: 0.0001243\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 5.97s\tremaining: 57.6s\n",
      "939:\tlearn: 0.0001234\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 5.98s\tremaining: 57.6s\n",
      "940:\tlearn: 0.0001225\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 5.99s\tremaining: 57.7s\n",
      "941:\tlearn: 0.0001224\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6s\tremaining: 57.7s\n",
      "942:\tlearn: 0.0001219\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.01s\tremaining: 57.7s\n",
      "943:\tlearn: 0.0001208\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 6.01s\tremaining: 57.7s\n",
      "944:\tlearn: 0.0001199\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.02s\tremaining: 57.7s\n",
      "945:\tlearn: 0.0001196\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.03s\tremaining: 57.7s\n",
      "946:\tlearn: 0.0001189\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.04s\tremaining: 57.7s\n",
      "947:\tlearn: 0.0001188\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.05s\tremaining: 57.7s\n",
      "948:\tlearn: 0.0001181\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.05s\tremaining: 57.7s\n",
      "949:\tlearn: 0.0001173\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.06s\tremaining: 57.8s\n",
      "950:\tlearn: 0.0001163\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 6.07s\tremaining: 57.8s\n",
      "951:\tlearn: 0.0001152\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.08s\tremaining: 57.8s\n",
      "952:\tlearn: 0.0001142\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.09s\tremaining: 57.8s\n",
      "953:\tlearn: 0.0001133\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.09s\tremaining: 57.8s\n",
      "954:\tlearn: 0.0001131\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.1s\tremaining: 57.8s\n",
      "955:\tlearn: 0.0001124\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.11s\tremaining: 57.8s\n",
      "956:\tlearn: 0.0001123\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.12s\tremaining: 57.8s\n",
      "957:\tlearn: 0.0001122\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.13s\tremaining: 57.8s\n",
      "958:\tlearn: 0.0001115\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.13s\tremaining: 57.8s\n",
      "959:\tlearn: 0.0001112\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.14s\tremaining: 57.8s\n",
      "960:\tlearn: 0.0001102\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 6.15s\tremaining: 57.8s\n",
      "961:\tlearn: 0.0001096\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.16s\tremaining: 57.8s\n",
      "962:\tlearn: 0.0001095\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.16s\tremaining: 57.8s\n",
      "963:\tlearn: 0.0001093\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.17s\tremaining: 57.8s\n",
      "964:\tlearn: 0.0001092\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.18s\tremaining: 57.8s\n",
      "965:\tlearn: 0.0001091\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.19s\tremaining: 57.9s\n",
      "966:\tlearn: 0.0001090\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.19s\tremaining: 57.9s\n",
      "967:\tlearn: 0.0001089\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.2s\tremaining: 57.9s\n",
      "968:\tlearn: 0.0001087\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.21s\tremaining: 57.9s\n",
      "969:\tlearn: 0.0001078\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.22s\tremaining: 57.9s\n",
      "970:\tlearn: 0.0001077\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.22s\tremaining: 57.9s\n",
      "971:\tlearn: 0.0001068\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.23s\tremaining: 57.9s\n",
      "972:\tlearn: 0.0001061\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.24s\tremaining: 57.9s\n",
      "973:\tlearn: 0.0001051\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.25s\tremaining: 57.9s\n",
      "974:\tlearn: 0.0001043\ttest: 0.0515730\tbest: 0.0515714 (729)\ttotal: 6.26s\tremaining: 57.9s\n",
      "975:\tlearn: 0.0001035\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.26s\tremaining: 57.9s\n",
      "976:\tlearn: 0.0001026\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.27s\tremaining: 57.9s\n",
      "977:\tlearn: 0.0001025\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.28s\tremaining: 58s\n",
      "978:\tlearn: 0.0001022\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.29s\tremaining: 58s\n",
      "979:\tlearn: 0.0001014\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.3s\tremaining: 58s\n",
      "980:\tlearn: 0.0001005\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 6.31s\tremaining: 58s\n",
      "981:\tlearn: 0.0001003\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 6.32s\tremaining: 58.1s\n",
      "982:\tlearn: 0.0000995\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 6.33s\tremaining: 58.1s\n",
      "983:\tlearn: 0.0000991\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.34s\tremaining: 58.1s\n",
      "984:\tlearn: 0.0000983\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.35s\tremaining: 58.1s\n",
      "985:\tlearn: 0.0000979\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.35s\tremaining: 58.1s\n",
      "986:\tlearn: 0.0000972\ttest: 0.0515741\tbest: 0.0515714 (729)\ttotal: 6.36s\tremaining: 58.1s\n",
      "987:\tlearn: 0.0000966\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.37s\tremaining: 58.1s\n",
      "988:\tlearn: 0.0000959\ttest: 0.0515740\tbest: 0.0515714 (729)\ttotal: 6.38s\tremaining: 58.1s\n",
      "989:\tlearn: 0.0000952\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.39s\tremaining: 58.1s\n",
      "990:\tlearn: 0.0000951\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.4s\tremaining: 58.1s\n",
      "991:\tlearn: 0.0000945\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 6.41s\tremaining: 58.2s\n",
      "992:\tlearn: 0.0000940\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.41s\tremaining: 58.2s\n",
      "993:\tlearn: 0.0000931\ttest: 0.0515737\tbest: 0.0515714 (729)\ttotal: 6.42s\tremaining: 58.2s\n",
      "994:\tlearn: 0.0000926\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.43s\tremaining: 58.2s\n",
      "995:\tlearn: 0.0000918\ttest: 0.0515739\tbest: 0.0515714 (729)\ttotal: 6.44s\tremaining: 58.2s\n",
      "996:\tlearn: 0.0000917\ttest: 0.0515738\tbest: 0.0515714 (729)\ttotal: 6.45s\tremaining: 58.2s\n",
      "997:\tlearn: 0.0000907\ttest: 0.0515735\tbest: 0.0515714 (729)\ttotal: 6.46s\tremaining: 58.2s\n",
      "998:\tlearn: 0.0000898\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 6.46s\tremaining: 58.2s\n",
      "999:\tlearn: 0.0000897\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 6.47s\tremaining: 58.2s\n",
      "1000:\tlearn: 0.0000896\ttest: 0.0515736\tbest: 0.0515714 (729)\ttotal: 6.48s\tremaining: 58.2s\n",
      "1001:\tlearn: 0.0000891\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.49s\tremaining: 58.2s\n",
      "1002:\tlearn: 0.0000886\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.49s\tremaining: 58.3s\n",
      "1003:\tlearn: 0.0000886\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.5s\tremaining: 58.3s\n",
      "1004:\tlearn: 0.0000885\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.51s\tremaining: 58.3s\n",
      "1005:\tlearn: 0.0000875\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.51s\tremaining: 58.3s\n",
      "1006:\tlearn: 0.0000874\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.52s\tremaining: 58.3s\n",
      "1007:\tlearn: 0.0000874\ttest: 0.0515734\tbest: 0.0515714 (729)\ttotal: 6.53s\tremaining: 58.3s\n",
      "1008:\tlearn: 0.0000868\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.54s\tremaining: 58.3s\n",
      "1009:\tlearn: 0.0000867\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.54s\tremaining: 58.3s\n",
      "1010:\tlearn: 0.0000867\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.55s\tremaining: 58.3s\n",
      "1011:\tlearn: 0.0000866\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.56s\tremaining: 58.3s\n",
      "1012:\tlearn: 0.0000865\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.57s\tremaining: 58.3s\n",
      "1013:\tlearn: 0.0000864\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.57s\tremaining: 58.3s\n",
      "1014:\tlearn: 0.0000857\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.58s\tremaining: 58.3s\n",
      "1015:\tlearn: 0.0000852\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.59s\tremaining: 58.3s\n",
      "1016:\tlearn: 0.0000847\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 6.6s\tremaining: 58.3s\n",
      "1017:\tlearn: 0.0000840\ttest: 0.0515727\tbest: 0.0515714 (729)\ttotal: 6.6s\tremaining: 58.3s\n",
      "1018:\tlearn: 0.0000832\ttest: 0.0515728\tbest: 0.0515714 (729)\ttotal: 6.61s\tremaining: 58.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/CatBoost/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
      "\t-0.0516\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.68s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tDropped 0 of 128 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019:\tlearn: 0.0000826\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.62s\tremaining: 58.3s\n",
      "1020:\tlearn: 0.0000825\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.63s\tremaining: 58.3s\n",
      "1021:\tlearn: 0.0000818\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.63s\tremaining: 58.3s\n",
      "1022:\tlearn: 0.0000818\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.64s\tremaining: 58.3s\n",
      "1023:\tlearn: 0.0000811\ttest: 0.0515727\tbest: 0.0515714 (729)\ttotal: 6.65s\tremaining: 58.3s\n",
      "1024:\tlearn: 0.0000805\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 6.66s\tremaining: 58.3s\n",
      "1025:\tlearn: 0.0000799\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 6.67s\tremaining: 58.3s\n",
      "1026:\tlearn: 0.0000794\ttest: 0.0515729\tbest: 0.0515714 (729)\ttotal: 6.68s\tremaining: 58.4s\n",
      "1027:\tlearn: 0.0000788\ttest: 0.0515732\tbest: 0.0515714 (729)\ttotal: 6.69s\tremaining: 58.4s\n",
      "1028:\tlearn: 0.0000783\ttest: 0.0515733\tbest: 0.0515714 (729)\ttotal: 6.7s\tremaining: 58.4s\n",
      "1029:\tlearn: 0.0000774\ttest: 0.0515731\tbest: 0.0515714 (729)\ttotal: 6.71s\tremaining: 58.4s\n",
      "\n",
      "bestTest = 0.05157142504\n",
      "bestIteration = 729\n",
      "\n",
      "Shrink model to first 730 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting ExtraTreesMSE with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/ExtraTreesMSE/y_pred_proba_val.pkl\n",
      "\t-0.0512\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting NeuralNetFastAI with 'num_gpus': 0, 'num_cpus': 20\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 0/0 categorical features\n",
      "Using 128 cont features\n",
      "Automated batch size selection: 256\n",
      "TabularModel(\n",
      "  (embeds): ModuleList()\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=128, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Better model found at epoch 0 with _rmse value: 0.9627273678779602.\n",
      "Better model found at epoch 1 with _rmse value: 0.9504895210266113.\n",
      "Better model found at epoch 2 with _rmse value: 0.9326273202896118.\n",
      "Better model found at epoch 3 with _rmse value: 0.9165355563163757.\n",
      "Better model found at epoch 4 with _rmse value: 0.9117704629898071.\n",
      "Better model found at epoch 6 with _rmse value: 0.9056865572929382.\n",
      "Better model found at epoch 7 with _rmse value: 0.8852378129959106.\n",
      "Better model found at epoch 8 with _rmse value: 0.8732063174247742.\n",
      "No improvement since epoch 8: early stopping\n",
      "Model validation metrics: 0.8732063174247742\n",
      "Saving ./agModels-spvae2/models/NeuralNetFastAI/model.pkl\n",
      "Saving ./agModels-spvae2/models/NeuralNetFastAI/model-internals.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
      "\t-0.0526\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: XGBoost ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.10932\n",
      "[1]\tvalidation_0-rmse:0.10181\n",
      "[2]\tvalidation_0-rmse:0.09473\n",
      "[3]\tvalidation_0-rmse:0.08858\n",
      "[4]\tvalidation_0-rmse:0.08356\n",
      "[5]\tvalidation_0-rmse:0.07956\n",
      "[6]\tvalidation_0-rmse:0.07622\n",
      "[7]\tvalidation_0-rmse:0.07357\n",
      "[8]\tvalidation_0-rmse:0.07138\n",
      "[9]\tvalidation_0-rmse:0.06919\n",
      "[10]\tvalidation_0-rmse:0.06757\n",
      "[11]\tvalidation_0-rmse:0.06579\n",
      "[12]\tvalidation_0-rmse:0.06482\n",
      "[13]\tvalidation_0-rmse:0.06364\n",
      "[14]\tvalidation_0-rmse:0.06208\n",
      "[15]\tvalidation_0-rmse:0.06096\n",
      "[16]\tvalidation_0-rmse:0.06028\n",
      "[17]\tvalidation_0-rmse:0.05940\n",
      "[18]\tvalidation_0-rmse:0.05898\n",
      "[19]\tvalidation_0-rmse:0.05852\n",
      "[20]\tvalidation_0-rmse:0.05836\n",
      "[21]\tvalidation_0-rmse:0.05794\n",
      "[22]\tvalidation_0-rmse:0.05767\n",
      "[23]\tvalidation_0-rmse:0.05730\n",
      "[24]\tvalidation_0-rmse:0.05700\n",
      "[25]\tvalidation_0-rmse:0.05670\n",
      "[26]\tvalidation_0-rmse:0.05637\n",
      "[27]\tvalidation_0-rmse:0.05634\n",
      "[28]\tvalidation_0-rmse:0.05612\n",
      "[29]\tvalidation_0-rmse:0.05586\n",
      "[30]\tvalidation_0-rmse:0.05577\n",
      "[31]\tvalidation_0-rmse:0.05576\n",
      "[32]\tvalidation_0-rmse:0.05573\n",
      "[33]\tvalidation_0-rmse:0.05554\n",
      "[34]\tvalidation_0-rmse:0.05555\n",
      "[35]\tvalidation_0-rmse:0.05559\n",
      "[36]\tvalidation_0-rmse:0.05557\n",
      "[37]\tvalidation_0-rmse:0.05552\n",
      "[38]\tvalidation_0-rmse:0.05535\n",
      "[39]\tvalidation_0-rmse:0.05532\n",
      "[40]\tvalidation_0-rmse:0.05533\n",
      "[41]\tvalidation_0-rmse:0.05533\n",
      "[42]\tvalidation_0-rmse:0.05523\n",
      "[43]\tvalidation_0-rmse:0.05525\n",
      "[44]\tvalidation_0-rmse:0.05529\n",
      "[45]\tvalidation_0-rmse:0.05525\n",
      "[46]\tvalidation_0-rmse:0.05522\n",
      "[47]\tvalidation_0-rmse:0.05521\n",
      "[48]\tvalidation_0-rmse:0.05520\n",
      "[49]\tvalidation_0-rmse:0.05521\n",
      "[50]\tvalidation_0-rmse:0.05521\n",
      "[51]\tvalidation_0-rmse:0.05515\n",
      "[52]\tvalidation_0-rmse:0.05518\n",
      "[53]\tvalidation_0-rmse:0.05523\n",
      "[54]\tvalidation_0-rmse:0.05519\n",
      "[55]\tvalidation_0-rmse:0.05520\n",
      "[56]\tvalidation_0-rmse:0.05520\n",
      "[57]\tvalidation_0-rmse:0.05517\n",
      "[58]\tvalidation_0-rmse:0.05516\n",
      "[59]\tvalidation_0-rmse:0.05515\n",
      "[60]\tvalidation_0-rmse:0.05514\n",
      "[61]\tvalidation_0-rmse:0.05513\n",
      "[62]\tvalidation_0-rmse:0.05512\n",
      "[63]\tvalidation_0-rmse:0.05512\n",
      "[64]\tvalidation_0-rmse:0.05510\n",
      "[65]\tvalidation_0-rmse:0.05508\n",
      "[66]\tvalidation_0-rmse:0.05507\n",
      "[67]\tvalidation_0-rmse:0.05506\n",
      "[68]\tvalidation_0-rmse:0.05503\n",
      "[69]\tvalidation_0-rmse:0.05501\n",
      "[70]\tvalidation_0-rmse:0.05498\n",
      "[71]\tvalidation_0-rmse:0.05499\n",
      "[72]\tvalidation_0-rmse:0.05500\n",
      "[73]\tvalidation_0-rmse:0.05500\n",
      "[74]\tvalidation_0-rmse:0.05498\n",
      "[75]\tvalidation_0-rmse:0.05497\n",
      "[76]\tvalidation_0-rmse:0.05497\n",
      "[77]\tvalidation_0-rmse:0.05496\n",
      "[78]\tvalidation_0-rmse:0.05495\n",
      "[79]\tvalidation_0-rmse:0.05494\n",
      "[80]\tvalidation_0-rmse:0.05494\n",
      "[81]\tvalidation_0-rmse:0.05493\n",
      "[82]\tvalidation_0-rmse:0.05492\n",
      "[83]\tvalidation_0-rmse:0.05491\n",
      "[84]\tvalidation_0-rmse:0.05492\n",
      "[85]\tvalidation_0-rmse:0.05492\n",
      "[86]\tvalidation_0-rmse:0.05491\n",
      "[87]\tvalidation_0-rmse:0.05492\n",
      "[88]\tvalidation_0-rmse:0.05491\n",
      "[89]\tvalidation_0-rmse:0.05491\n",
      "[90]\tvalidation_0-rmse:0.05492\n",
      "[91]\tvalidation_0-rmse:0.05493\n",
      "[92]\tvalidation_0-rmse:0.05492\n",
      "[93]\tvalidation_0-rmse:0.05493\n",
      "[94]\tvalidation_0-rmse:0.05493\n",
      "[95]\tvalidation_0-rmse:0.05492\n",
      "[96]\tvalidation_0-rmse:0.05491\n",
      "[97]\tvalidation_0-rmse:0.05491\n",
      "[98]\tvalidation_0-rmse:0.05491\n",
      "[99]\tvalidation_0-rmse:0.05490\n",
      "[100]\tvalidation_0-rmse:0.05490\n",
      "[101]\tvalidation_0-rmse:0.05490\n",
      "[102]\tvalidation_0-rmse:0.05490\n",
      "[103]\tvalidation_0-rmse:0.05490\n",
      "[104]\tvalidation_0-rmse:0.05490\n",
      "[105]\tvalidation_0-rmse:0.05490\n",
      "[106]\tvalidation_0-rmse:0.05490\n",
      "[107]\tvalidation_0-rmse:0.05490\n",
      "[108]\tvalidation_0-rmse:0.05490\n",
      "[109]\tvalidation_0-rmse:0.05490\n",
      "[110]\tvalidation_0-rmse:0.05490\n",
      "[111]\tvalidation_0-rmse:0.05490\n",
      "[112]\tvalidation_0-rmse:0.05490\n",
      "[113]\tvalidation_0-rmse:0.05490\n",
      "[114]\tvalidation_0-rmse:0.05490\n",
      "[115]\tvalidation_0-rmse:0.05490\n",
      "[116]\tvalidation_0-rmse:0.05490\n",
      "[117]\tvalidation_0-rmse:0.05490\n",
      "[118]\tvalidation_0-rmse:0.05490\n",
      "[119]\tvalidation_0-rmse:0.05490\n",
      "[120]\tvalidation_0-rmse:0.05490\n",
      "[121]\tvalidation_0-rmse:0.05490\n",
      "[122]\tvalidation_0-rmse:0.05490\n",
      "[123]\tvalidation_0-rmse:0.05490\n",
      "[124]\tvalidation_0-rmse:0.05490\n",
      "[125]\tvalidation_0-rmse:0.05490\n",
      "[126]\tvalidation_0-rmse:0.05490\n",
      "[127]\tvalidation_0-rmse:0.05490\n",
      "[128]\tvalidation_0-rmse:0.05490\n",
      "[129]\tvalidation_0-rmse:0.05490\n",
      "[130]\tvalidation_0-rmse:0.05490\n",
      "[131]\tvalidation_0-rmse:0.05490\n",
      "[132]\tvalidation_0-rmse:0.05490\n",
      "[133]\tvalidation_0-rmse:0.05490\n",
      "[134]\tvalidation_0-rmse:0.05490\n",
      "[135]\tvalidation_0-rmse:0.05490\n",
      "[136]\tvalidation_0-rmse:0.05490\n",
      "[137]\tvalidation_0-rmse:0.05490\n",
      "[138]\tvalidation_0-rmse:0.05490\n",
      "[139]\tvalidation_0-rmse:0.05490\n",
      "[140]\tvalidation_0-rmse:0.05490\n",
      "[141]\tvalidation_0-rmse:0.05490\n",
      "[142]\tvalidation_0-rmse:0.05490\n",
      "[143]\tvalidation_0-rmse:0.05490\n",
      "[144]\tvalidation_0-rmse:0.05490\n",
      "[145]\tvalidation_0-rmse:0.05490\n",
      "[146]\tvalidation_0-rmse:0.05490\n",
      "[147]\tvalidation_0-rmse:0.05490\n",
      "[148]\tvalidation_0-rmse:0.05490\n",
      "[149]\tvalidation_0-rmse:0.05490\n",
      "[150]\tvalidation_0-rmse:0.05490\n",
      "[151]\tvalidation_0-rmse:0.05490\n",
      "[152]\tvalidation_0-rmse:0.05490\n",
      "[153]\tvalidation_0-rmse:0.05490\n",
      "[154]\tvalidation_0-rmse:0.05490\n",
      "[155]\tvalidation_0-rmse:0.05490\n",
      "[156]\tvalidation_0-rmse:0.05490\n",
      "[157]\tvalidation_0-rmse:0.05490\n",
      "[158]\tvalidation_0-rmse:0.05490\n",
      "[159]\tvalidation_0-rmse:0.05490\n",
      "[160]\tvalidation_0-rmse:0.05490\n",
      "[161]\tvalidation_0-rmse:0.05490\n",
      "[162]\tvalidation_0-rmse:0.05490\n",
      "[163]\tvalidation_0-rmse:0.05490\n",
      "[164]\tvalidation_0-rmse:0.05490\n",
      "[165]\tvalidation_0-rmse:0.05490\n",
      "[166]\tvalidation_0-rmse:0.05490\n",
      "[167]\tvalidation_0-rmse:0.05490\n",
      "[168]\tvalidation_0-rmse:0.05490\n",
      "[169]\tvalidation_0-rmse:0.05490\n",
      "[170]\tvalidation_0-rmse:0.05490\n",
      "[171]\tvalidation_0-rmse:0.05490\n",
      "[172]\tvalidation_0-rmse:0.05490\n",
      "[173]\tvalidation_0-rmse:0.05490\n",
      "[174]\tvalidation_0-rmse:0.05490\n",
      "[175]\tvalidation_0-rmse:0.05490\n",
      "[176]\tvalidation_0-rmse:0.05490\n",
      "[177]\tvalidation_0-rmse:0.05490\n",
      "[178]\tvalidation_0-rmse:0.05490\n",
      "[179]\tvalidation_0-rmse:0.05490\n",
      "[180]\tvalidation_0-rmse:0.05490\n",
      "[181]\tvalidation_0-rmse:0.05490\n",
      "[182]\tvalidation_0-rmse:0.05490\n",
      "[183]\tvalidation_0-rmse:0.05490\n",
      "[184]\tvalidation_0-rmse:0.05490\n",
      "[185]\tvalidation_0-rmse:0.05490\n",
      "[186]\tvalidation_0-rmse:0.05490\n",
      "[187]\tvalidation_0-rmse:0.05490\n",
      "[188]\tvalidation_0-rmse:0.05490\n",
      "[189]\tvalidation_0-rmse:0.05490\n",
      "[190]\tvalidation_0-rmse:0.05490\n",
      "[191]\tvalidation_0-rmse:0.05490\n",
      "[192]\tvalidation_0-rmse:0.05490\n",
      "[193]\tvalidation_0-rmse:0.05490\n",
      "[194]\tvalidation_0-rmse:0.05490\n",
      "[195]\tvalidation_0-rmse:0.05490\n",
      "[196]\tvalidation_0-rmse:0.05490\n",
      "[197]\tvalidation_0-rmse:0.05490\n",
      "[198]\tvalidation_0-rmse:0.05490\n",
      "[199]\tvalidation_0-rmse:0.05490\n",
      "[200]\tvalidation_0-rmse:0.05490\n",
      "[201]\tvalidation_0-rmse:0.05490\n",
      "[202]\tvalidation_0-rmse:0.05490\n",
      "[203]\tvalidation_0-rmse:0.05490\n",
      "[204]\tvalidation_0-rmse:0.05490\n",
      "[205]\tvalidation_0-rmse:0.05490\n",
      "[206]\tvalidation_0-rmse:0.05490\n",
      "[207]\tvalidation_0-rmse:0.05490\n",
      "[208]\tvalidation_0-rmse:0.05490\n",
      "[209]\tvalidation_0-rmse:0.05490\n",
      "[210]\tvalidation_0-rmse:0.05490\n",
      "[211]\tvalidation_0-rmse:0.05490\n",
      "[212]\tvalidation_0-rmse:0.05490\n",
      "[213]\tvalidation_0-rmse:0.05490\n",
      "[214]\tvalidation_0-rmse:0.05490\n",
      "[215]\tvalidation_0-rmse:0.05490\n",
      "[216]\tvalidation_0-rmse:0.05490\n",
      "[217]\tvalidation_0-rmse:0.05490\n",
      "[218]\tvalidation_0-rmse:0.05490\n",
      "[219]\tvalidation_0-rmse:0.05490\n",
      "[220]\tvalidation_0-rmse:0.05490\n",
      "[221]\tvalidation_0-rmse:0.05490\n",
      "[222]\tvalidation_0-rmse:0.05490\n",
      "[223]\tvalidation_0-rmse:0.05490\n",
      "[224]\tvalidation_0-rmse:0.05490\n",
      "[225]\tvalidation_0-rmse:0.05490\n",
      "[226]\tvalidation_0-rmse:0.05490\n",
      "[227]\tvalidation_0-rmse:0.05490\n",
      "[228]\tvalidation_0-rmse:0.05490\n",
      "[229]\tvalidation_0-rmse:0.05490\n",
      "[230]\tvalidation_0-rmse:0.05490\n",
      "[231]\tvalidation_0-rmse:0.05490\n",
      "[232]\tvalidation_0-rmse:0.05490\n",
      "[233]\tvalidation_0-rmse:0.05490\n",
      "[234]\tvalidation_0-rmse:0.05490\n",
      "[235]\tvalidation_0-rmse:0.05490\n",
      "[236]\tvalidation_0-rmse:0.05490\n",
      "[237]\tvalidation_0-rmse:0.05490\n",
      "[238]\tvalidation_0-rmse:0.05490\n",
      "[239]\tvalidation_0-rmse:0.05490\n",
      "[240]\tvalidation_0-rmse:0.05490\n",
      "[241]\tvalidation_0-rmse:0.05490\n",
      "[242]\tvalidation_0-rmse:0.05490\n",
      "[243]\tvalidation_0-rmse:0.05490\n",
      "[244]\tvalidation_0-rmse:0.05490\n",
      "[245]\tvalidation_0-rmse:0.05490\n",
      "[246]\tvalidation_0-rmse:0.05490\n",
      "[247]\tvalidation_0-rmse:0.05490\n",
      "[248]\tvalidation_0-rmse:0.05490\n",
      "[249]\tvalidation_0-rmse:0.05490\n",
      "[250]\tvalidation_0-rmse:0.05490\n",
      "[251]\tvalidation_0-rmse:0.05490\n",
      "[252]\tvalidation_0-rmse:0.05490\n",
      "[253]\tvalidation_0-rmse:0.05490\n",
      "[254]\tvalidation_0-rmse:0.05490\n",
      "[255]\tvalidation_0-rmse:0.05490\n",
      "[256]\tvalidation_0-rmse:0.05490\n",
      "[257]\tvalidation_0-rmse:0.05490\n",
      "[258]\tvalidation_0-rmse:0.05490\n",
      "[259]\tvalidation_0-rmse:0.05490\n",
      "[260]\tvalidation_0-rmse:0.05490\n",
      "[261]\tvalidation_0-rmse:0.05490\n",
      "[262]\tvalidation_0-rmse:0.05490\n",
      "[263]\tvalidation_0-rmse:0.05490\n",
      "[264]\tvalidation_0-rmse:0.05490\n",
      "[265]\tvalidation_0-rmse:0.05490\n",
      "[266]\tvalidation_0-rmse:0.05490\n",
      "[267]\tvalidation_0-rmse:0.05490\n",
      "[268]\tvalidation_0-rmse:0.05490\n",
      "[269]\tvalidation_0-rmse:0.05490\n",
      "[270]\tvalidation_0-rmse:0.05490\n",
      "[271]\tvalidation_0-rmse:0.05490\n",
      "[272]\tvalidation_0-rmse:0.05490\n",
      "[273]\tvalidation_0-rmse:0.05490\n",
      "[274]\tvalidation_0-rmse:0.05490\n",
      "[275]\tvalidation_0-rmse:0.05490\n",
      "[276]\tvalidation_0-rmse:0.05490\n",
      "[277]\tvalidation_0-rmse:0.05490\n",
      "[278]\tvalidation_0-rmse:0.05490\n",
      "[279]\tvalidation_0-rmse:0.05490\n",
      "[280]\tvalidation_0-rmse:0.05490\n",
      "[281]\tvalidation_0-rmse:0.05490\n",
      "[282]\tvalidation_0-rmse:0.05490\n",
      "[283]\tvalidation_0-rmse:0.05490\n",
      "[284]\tvalidation_0-rmse:0.05490\n",
      "[285]\tvalidation_0-rmse:0.05490\n",
      "[286]\tvalidation_0-rmse:0.05490\n",
      "[287]\tvalidation_0-rmse:0.05490\n",
      "[288]\tvalidation_0-rmse:0.05490\n",
      "[289]\tvalidation_0-rmse:0.05490\n",
      "[290]\tvalidation_0-rmse:0.05490\n",
      "[291]\tvalidation_0-rmse:0.05490\n",
      "[292]\tvalidation_0-rmse:0.05490\n",
      "[293]\tvalidation_0-rmse:0.05490\n",
      "[294]\tvalidation_0-rmse:0.05490\n",
      "[295]\tvalidation_0-rmse:0.05490\n",
      "[296]\tvalidation_0-rmse:0.05490\n",
      "[297]\tvalidation_0-rmse:0.05490\n",
      "[298]\tvalidation_0-rmse:0.05490\n",
      "[299]\tvalidation_0-rmse:0.05490\n",
      "[300]\tvalidation_0-rmse:0.05490\n",
      "[301]\tvalidation_0-rmse:0.05490\n",
      "[302]\tvalidation_0-rmse:0.05490\n",
      "[303]\tvalidation_0-rmse:0.05490\n",
      "[304]\tvalidation_0-rmse:0.05490\n",
      "[305]\tvalidation_0-rmse:0.05490\n",
      "[306]\tvalidation_0-rmse:0.05490\n",
      "[307]\tvalidation_0-rmse:0.05490\n",
      "[308]\tvalidation_0-rmse:0.05490\n",
      "[309]\tvalidation_0-rmse:0.05490\n",
      "[310]\tvalidation_0-rmse:0.05490\n",
      "[311]\tvalidation_0-rmse:0.05490\n",
      "[312]\tvalidation_0-rmse:0.05490\n",
      "[313]\tvalidation_0-rmse:0.05490\n",
      "[314]\tvalidation_0-rmse:0.05490\n",
      "[315]\tvalidation_0-rmse:0.05490\n",
      "[316]\tvalidation_0-rmse:0.05490\n",
      "[317]\tvalidation_0-rmse:0.05490\n",
      "[318]\tvalidation_0-rmse:0.05490\n",
      "[319]\tvalidation_0-rmse:0.05490\n",
      "[320]\tvalidation_0-rmse:0.05490\n",
      "[321]\tvalidation_0-rmse:0.05490\n",
      "[322]\tvalidation_0-rmse:0.05490\n",
      "[323]\tvalidation_0-rmse:0.05490\n",
      "[324]\tvalidation_0-rmse:0.05490\n",
      "[325]\tvalidation_0-rmse:0.05490\n",
      "[326]\tvalidation_0-rmse:0.05490\n",
      "[327]\tvalidation_0-rmse:0.05490\n",
      "[328]\tvalidation_0-rmse:0.05490\n",
      "[329]\tvalidation_0-rmse:0.05490\n",
      "[330]\tvalidation_0-rmse:0.05490\n",
      "[331]\tvalidation_0-rmse:0.05490\n",
      "[332]\tvalidation_0-rmse:0.05490\n",
      "[333]\tvalidation_0-rmse:0.05490\n",
      "[334]\tvalidation_0-rmse:0.05490\n",
      "[335]\tvalidation_0-rmse:0.05490\n",
      "[336]\tvalidation_0-rmse:0.05490\n",
      "[337]\tvalidation_0-rmse:0.05490\n",
      "[338]\tvalidation_0-rmse:0.05490\n",
      "[339]\tvalidation_0-rmse:0.05490\n",
      "[340]\tvalidation_0-rmse:0.05490\n",
      "[341]\tvalidation_0-rmse:0.05490\n",
      "[342]\tvalidation_0-rmse:0.05490\n",
      "[343]\tvalidation_0-rmse:0.05490\n",
      "[344]\tvalidation_0-rmse:0.05490\n",
      "[345]\tvalidation_0-rmse:0.05490\n",
      "[346]\tvalidation_0-rmse:0.05490\n",
      "[347]\tvalidation_0-rmse:0.05490\n",
      "[348]\tvalidation_0-rmse:0.05490\n",
      "[349]\tvalidation_0-rmse:0.05490\n",
      "[350]\tvalidation_0-rmse:0.05490\n",
      "[351]\tvalidation_0-rmse:0.05490\n",
      "[352]\tvalidation_0-rmse:0.05490\n",
      "[353]\tvalidation_0-rmse:0.05490\n",
      "[354]\tvalidation_0-rmse:0.05490\n",
      "[355]\tvalidation_0-rmse:0.05490\n",
      "[356]\tvalidation_0-rmse:0.05490\n",
      "[357]\tvalidation_0-rmse:0.05490\n",
      "[358]\tvalidation_0-rmse:0.05490\n",
      "[359]\tvalidation_0-rmse:0.05490\n",
      "[360]\tvalidation_0-rmse:0.05490\n",
      "[361]\tvalidation_0-rmse:0.05490\n",
      "[362]\tvalidation_0-rmse:0.05490\n",
      "[363]\tvalidation_0-rmse:0.05490\n",
      "[364]\tvalidation_0-rmse:0.05490\n",
      "[365]\tvalidation_0-rmse:0.05490\n",
      "[366]\tvalidation_0-rmse:0.05490\n",
      "[367]\tvalidation_0-rmse:0.05490\n",
      "[368]\tvalidation_0-rmse:0.05490\n",
      "[369]\tvalidation_0-rmse:0.05490\n",
      "[370]\tvalidation_0-rmse:0.05490\n",
      "[371]\tvalidation_0-rmse:0.05490\n",
      "[372]\tvalidation_0-rmse:0.05490\n",
      "[373]\tvalidation_0-rmse:0.05490\n",
      "[374]\tvalidation_0-rmse:0.05490\n",
      "[375]\tvalidation_0-rmse:0.05490\n",
      "[376]\tvalidation_0-rmse:0.05490\n",
      "[377]\tvalidation_0-rmse:0.05490\n",
      "[378]\tvalidation_0-rmse:0.05490\n",
      "[379]\tvalidation_0-rmse:0.05490\n",
      "[380]\tvalidation_0-rmse:0.05490\n",
      "[381]\tvalidation_0-rmse:0.05490\n",
      "[382]\tvalidation_0-rmse:0.05490\n",
      "[383]\tvalidation_0-rmse:0.05490\n",
      "[384]\tvalidation_0-rmse:0.05490\n",
      "[385]\tvalidation_0-rmse:0.05490\n",
      "[386]\tvalidation_0-rmse:0.05490\n",
      "[387]\tvalidation_0-rmse:0.05490\n",
      "[388]\tvalidation_0-rmse:0.05490\n",
      "[389]\tvalidation_0-rmse:0.05490\n",
      "[390]\tvalidation_0-rmse:0.05490\n",
      "[391]\tvalidation_0-rmse:0.05490\n",
      "[392]\tvalidation_0-rmse:0.05490\n",
      "[393]\tvalidation_0-rmse:0.05490\n",
      "[394]\tvalidation_0-rmse:0.05490\n",
      "[395]\tvalidation_0-rmse:0.05490\n",
      "[396]\tvalidation_0-rmse:0.05490\n",
      "[397]\tvalidation_0-rmse:0.05490\n",
      "[398]\tvalidation_0-rmse:0.05490\n",
      "[399]\tvalidation_0-rmse:0.05490\n",
      "[400]\tvalidation_0-rmse:0.05490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/XGBoost/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
      "\t-0.0549\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 20\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"dim_1\",\n",
      "        \"dim_2\",\n",
      "        \"dim_3\",\n",
      "        \"dim_4\",\n",
      "        \"dim_5\",\n",
      "        \"dim_6\",\n",
      "        \"dim_7\",\n",
      "        \"dim_8\",\n",
      "        \"dim_9\",\n",
      "        \"dim_10\",\n",
      "        \"dim_11\",\n",
      "        \"dim_12\",\n",
      "        \"dim_13\",\n",
      "        \"dim_14\",\n",
      "        \"dim_15\",\n",
      "        \"dim_16\",\n",
      "        \"dim_17\",\n",
      "        \"dim_18\",\n",
      "        \"dim_19\",\n",
      "        \"dim_20\",\n",
      "        \"dim_21\",\n",
      "        \"dim_22\",\n",
      "        \"dim_23\",\n",
      "        \"dim_24\",\n",
      "        \"dim_25\",\n",
      "        \"dim_26\",\n",
      "        \"dim_27\",\n",
      "        \"dim_28\",\n",
      "        \"dim_29\",\n",
      "        \"dim_30\",\n",
      "        \"dim_31\",\n",
      "        \"dim_32\",\n",
      "        \"dim_33\",\n",
      "        \"dim_34\",\n",
      "        \"dim_35\",\n",
      "        \"dim_36\",\n",
      "        \"dim_37\",\n",
      "        \"dim_38\",\n",
      "        \"dim_39\",\n",
      "        \"dim_40\",\n",
      "        \"dim_41\",\n",
      "        \"dim_42\",\n",
      "        \"dim_43\",\n",
      "        \"dim_44\",\n",
      "        \"dim_45\",\n",
      "        \"dim_46\",\n",
      "        \"dim_47\",\n",
      "        \"dim_48\",\n",
      "        \"dim_49\",\n",
      "        \"dim_50\",\n",
      "        \"dim_51\",\n",
      "        \"dim_52\",\n",
      "        \"dim_53\",\n",
      "        \"dim_54\",\n",
      "        \"dim_55\",\n",
      "        \"dim_56\",\n",
      "        \"dim_57\",\n",
      "        \"dim_58\",\n",
      "        \"dim_59\",\n",
      "        \"dim_60\",\n",
      "        \"dim_61\",\n",
      "        \"dim_62\",\n",
      "        \"dim_63\",\n",
      "        \"dim_64\",\n",
      "        \"dim_65\",\n",
      "        \"dim_66\",\n",
      "        \"dim_67\",\n",
      "        \"dim_68\",\n",
      "        \"dim_69\",\n",
      "        \"dim_70\",\n",
      "        \"dim_71\",\n",
      "        \"dim_72\",\n",
      "        \"dim_73\",\n",
      "        \"dim_74\",\n",
      "        \"dim_75\",\n",
      "        \"dim_76\",\n",
      "        \"dim_77\",\n",
      "        \"dim_78\",\n",
      "        \"dim_79\",\n",
      "        \"dim_80\",\n",
      "        \"dim_81\",\n",
      "        \"dim_82\",\n",
      "        \"dim_83\",\n",
      "        \"dim_84\",\n",
      "        \"dim_85\",\n",
      "        \"dim_86\",\n",
      "        \"dim_87\",\n",
      "        \"dim_88\",\n",
      "        \"dim_89\",\n",
      "        \"dim_90\",\n",
      "        \"dim_91\",\n",
      "        \"dim_92\",\n",
      "        \"dim_93\",\n",
      "        \"dim_94\",\n",
      "        \"dim_95\",\n",
      "        \"dim_96\",\n",
      "        \"dim_97\",\n",
      "        \"dim_98\",\n",
      "        \"dim_99\",\n",
      "        \"dim_100\",\n",
      "        \"dim_101\",\n",
      "        \"dim_102\",\n",
      "        \"dim_103\",\n",
      "        \"dim_104\",\n",
      "        \"dim_105\",\n",
      "        \"dim_106\",\n",
      "        \"dim_107\",\n",
      "        \"dim_108\",\n",
      "        \"dim_109\",\n",
      "        \"dim_110\",\n",
      "        \"dim_111\",\n",
      "        \"dim_112\",\n",
      "        \"dim_113\",\n",
      "        \"dim_114\",\n",
      "        \"dim_115\",\n",
      "        \"dim_116\",\n",
      "        \"dim_117\",\n",
      "        \"dim_118\",\n",
      "        \"dim_119\",\n",
      "        \"dim_120\",\n",
      "        \"dim_121\",\n",
      "        \"dim_122\",\n",
      "        \"dim_123\",\n",
      "        \"dim_124\",\n",
      "        \"dim_125\",\n",
      "        \"dim_126\",\n",
      "        \"dim_127\",\n",
      "        \"dim_128\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 280 examples, 128 features (128 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training tabular neural network for up to 500 epochs...\n",
      "Epoch 1 (Update 8).\tTrain loss: 0.0514, Val root_mean_squared_error: -0.0619, Best Epoch: 1\n",
      "Epoch 2 (Update 16).\tTrain loss: 0.0518, Val root_mean_squared_error: -0.0603, Best Epoch: 2\n",
      "Epoch 3 (Update 24).\tTrain loss: 0.0476, Val root_mean_squared_error: -0.059, Best Epoch: 3\n",
      "Epoch 4 (Update 32).\tTrain loss: 0.0482, Val root_mean_squared_error: -0.0582, Best Epoch: 4\n",
      "Epoch 5 (Update 40).\tTrain loss: 0.0468, Val root_mean_squared_error: -0.0575, Best Epoch: 5\n",
      "Epoch 6 (Update 48).\tTrain loss: 0.046, Val root_mean_squared_error: -0.057, Best Epoch: 6\n",
      "Epoch 7 (Update 56).\tTrain loss: 0.0443, Val root_mean_squared_error: -0.0563, Best Epoch: 7\n",
      "Epoch 8 (Update 64).\tTrain loss: 0.0435, Val root_mean_squared_error: -0.0558, Best Epoch: 8\n",
      "Epoch 9 (Update 72).\tTrain loss: 0.0431, Val root_mean_squared_error: -0.0553, Best Epoch: 9\n",
      "Epoch 10 (Update 80).\tTrain loss: 0.0415, Val root_mean_squared_error: -0.0552, Best Epoch: 10\n",
      "Epoch 11 (Update 88).\tTrain loss: 0.0407, Val root_mean_squared_error: -0.0542, Best Epoch: 11\n",
      "Epoch 12 (Update 96).\tTrain loss: 0.0388, Val root_mean_squared_error: -0.0536, Best Epoch: 12\n",
      "Epoch 13 (Update 104).\tTrain loss: 0.0375, Val root_mean_squared_error: -0.0533, Best Epoch: 13\n",
      "Epoch 14 (Update 112).\tTrain loss: 0.037, Val root_mean_squared_error: -0.0529, Best Epoch: 14\n",
      "Epoch 15 (Update 120).\tTrain loss: 0.0354, Val root_mean_squared_error: -0.0529, Best Epoch: 15\n",
      "Epoch 16 (Update 128).\tTrain loss: 0.0331, Val root_mean_squared_error: -0.0528, Best Epoch: 16\n",
      "Epoch 17 (Update 136).\tTrain loss: 0.0317, Val root_mean_squared_error: -0.0535, Best Epoch: 16\n",
      "Epoch 18 (Update 144).\tTrain loss: 0.0314, Val root_mean_squared_error: -0.0527, Best Epoch: 18\n",
      "Epoch 19 (Update 152).\tTrain loss: 0.0294, Val root_mean_squared_error: -0.0539, Best Epoch: 18\n",
      "Epoch 20 (Update 160).\tTrain loss: 0.0297, Val root_mean_squared_error: -0.052, Best Epoch: 20\n",
      "Epoch 21 (Update 168).\tTrain loss: 0.0271, Val root_mean_squared_error: -0.053, Best Epoch: 20\n",
      "Epoch 22 (Update 176).\tTrain loss: 0.0281, Val root_mean_squared_error: -0.0522, Best Epoch: 20\n",
      "Epoch 23 (Update 184).\tTrain loss: 0.0248, Val root_mean_squared_error: -0.0534, Best Epoch: 20\n",
      "Epoch 24 (Update 192).\tTrain loss: 0.025, Val root_mean_squared_error: -0.0544, Best Epoch: 20\n",
      "Epoch 25 (Update 200).\tTrain loss: 0.0254, Val root_mean_squared_error: -0.0531, Best Epoch: 20\n",
      "Epoch 26 (Update 208).\tTrain loss: 0.0233, Val root_mean_squared_error: -0.054, Best Epoch: 20\n",
      "Epoch 27 (Update 216).\tTrain loss: 0.0228, Val root_mean_squared_error: -0.0543, Best Epoch: 20\n",
      "Epoch 28 (Update 224).\tTrain loss: 0.0224, Val root_mean_squared_error: -0.0554, Best Epoch: 20\n",
      "Epoch 29 (Update 232).\tTrain loss: 0.0225, Val root_mean_squared_error: -0.0556, Best Epoch: 20\n",
      "Epoch 30 (Update 240).\tTrain loss: 0.0222, Val root_mean_squared_error: -0.0557, Best Epoch: 20\n",
      "Epoch 31 (Update 248).\tTrain loss: 0.02, Val root_mean_squared_error: -0.0544, Best Epoch: 20\n",
      "Epoch 32 (Update 256).\tTrain loss: 0.0191, Val root_mean_squared_error: -0.055, Best Epoch: 20\n",
      "Epoch 33 (Update 264).\tTrain loss: 0.0192, Val root_mean_squared_error: -0.0546, Best Epoch: 20\n",
      "Epoch 34 (Update 272).\tTrain loss: 0.0201, Val root_mean_squared_error: -0.0562, Best Epoch: 20\n",
      "Epoch 35 (Update 280).\tTrain loss: 0.0205, Val root_mean_squared_error: -0.0551, Best Epoch: 20\n",
      "Epoch 36 (Update 288).\tTrain loss: 0.0199, Val root_mean_squared_error: -0.0564, Best Epoch: 20\n",
      "Epoch 37 (Update 296).\tTrain loss: 0.0184, Val root_mean_squared_error: -0.0546, Best Epoch: 20\n",
      "Epoch 38 (Update 304).\tTrain loss: 0.0191, Val root_mean_squared_error: -0.0549, Best Epoch: 20\n",
      "Epoch 39 (Update 312).\tTrain loss: 0.019, Val root_mean_squared_error: -0.0546, Best Epoch: 20\n",
      "Epoch 40 (Update 320).\tTrain loss: 0.0176, Val root_mean_squared_error: -0.0558, Best Epoch: 20\n",
      "Best model found on Epoch 20 (Update 160). Val root_mean_squared_error: -0.05203120410442352\n",
      "Saving ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t-0.052\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBMLarge with 'num_gpus': 0, 'num_cpus': 20\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's rmse: 0.0581641\n",
      "[2]\tvalid_set's rmse: 0.057737\n",
      "[3]\tvalid_set's rmse: 0.0574427\n",
      "[4]\tvalid_set's rmse: 0.0572017\n",
      "[5]\tvalid_set's rmse: 0.0570175\n",
      "[6]\tvalid_set's rmse: 0.0568971\n",
      "[7]\tvalid_set's rmse: 0.0566864\n",
      "[8]\tvalid_set's rmse: 0.0565631\n",
      "[9]\tvalid_set's rmse: 0.0563735\n",
      "[10]\tvalid_set's rmse: 0.0559786\n",
      "[11]\tvalid_set's rmse: 0.0555541\n",
      "[12]\tvalid_set's rmse: 0.0553156\n",
      "[13]\tvalid_set's rmse: 0.0551184\n",
      "[14]\tvalid_set's rmse: 0.0547604\n",
      "[15]\tvalid_set's rmse: 0.0544081\n",
      "[16]\tvalid_set's rmse: 0.0541422\n",
      "[17]\tvalid_set's rmse: 0.0538648\n",
      "[18]\tvalid_set's rmse: 0.053436\n",
      "[19]\tvalid_set's rmse: 0.0534053\n",
      "[20]\tvalid_set's rmse: 0.0534636\n",
      "[21]\tvalid_set's rmse: 0.0533307\n",
      "[22]\tvalid_set's rmse: 0.0531558\n",
      "[23]\tvalid_set's rmse: 0.0531692\n",
      "[24]\tvalid_set's rmse: 0.0529134\n",
      "[25]\tvalid_set's rmse: 0.0529872\n",
      "[26]\tvalid_set's rmse: 0.0529593\n",
      "[27]\tvalid_set's rmse: 0.0529545\n",
      "[28]\tvalid_set's rmse: 0.0528616\n",
      "[29]\tvalid_set's rmse: 0.0526544\n",
      "[30]\tvalid_set's rmse: 0.0525338\n",
      "[31]\tvalid_set's rmse: 0.0525347\n",
      "[32]\tvalid_set's rmse: 0.052653\n",
      "[33]\tvalid_set's rmse: 0.0524327\n",
      "[34]\tvalid_set's rmse: 0.0523807\n",
      "[35]\tvalid_set's rmse: 0.0522826\n",
      "[36]\tvalid_set's rmse: 0.052163\n",
      "[37]\tvalid_set's rmse: 0.0521352\n",
      "[38]\tvalid_set's rmse: 0.0520403\n",
      "[39]\tvalid_set's rmse: 0.0519329\n",
      "[40]\tvalid_set's rmse: 0.0518582\n",
      "[41]\tvalid_set's rmse: 0.05181\n",
      "[42]\tvalid_set's rmse: 0.0518593\n",
      "[43]\tvalid_set's rmse: 0.0518325\n",
      "[44]\tvalid_set's rmse: 0.0517996\n",
      "[45]\tvalid_set's rmse: 0.0516735\n",
      "[46]\tvalid_set's rmse: 0.0515273\n",
      "[47]\tvalid_set's rmse: 0.0515038\n",
      "[48]\tvalid_set's rmse: 0.0514562\n",
      "[49]\tvalid_set's rmse: 0.0514268\n",
      "[50]\tvalid_set's rmse: 0.051466\n",
      "[51]\tvalid_set's rmse: 0.0514948\n",
      "[52]\tvalid_set's rmse: 0.0515112\n",
      "[53]\tvalid_set's rmse: 0.0515109\n",
      "[54]\tvalid_set's rmse: 0.0515707\n",
      "[55]\tvalid_set's rmse: 0.0515719\n",
      "[56]\tvalid_set's rmse: 0.0516363\n",
      "[57]\tvalid_set's rmse: 0.0516543\n",
      "[58]\tvalid_set's rmse: 0.0516492\n",
      "[59]\tvalid_set's rmse: 0.0516733\n",
      "[60]\tvalid_set's rmse: 0.0516676\n",
      "[61]\tvalid_set's rmse: 0.0516474\n",
      "[62]\tvalid_set's rmse: 0.0516407\n",
      "[63]\tvalid_set's rmse: 0.0516666\n",
      "[64]\tvalid_set's rmse: 0.0516557\n",
      "[65]\tvalid_set's rmse: 0.0516859\n",
      "[66]\tvalid_set's rmse: 0.0517589\n",
      "[67]\tvalid_set's rmse: 0.0517918\n",
      "[68]\tvalid_set's rmse: 0.0518014\n",
      "[69]\tvalid_set's rmse: 0.0518761\n",
      "[70]\tvalid_set's rmse: 0.0519017\n",
      "[71]\tvalid_set's rmse: 0.0518298\n",
      "[72]\tvalid_set's rmse: 0.0518384\n",
      "[73]\tvalid_set's rmse: 0.0517751\n",
      "[74]\tvalid_set's rmse: 0.0517541\n",
      "[75]\tvalid_set's rmse: 0.0517045\n",
      "[76]\tvalid_set's rmse: 0.0517017\n",
      "[77]\tvalid_set's rmse: 0.0516781\n",
      "[78]\tvalid_set's rmse: 0.0516552\n",
      "[79]\tvalid_set's rmse: 0.0516753\n",
      "[80]\tvalid_set's rmse: 0.0516684\n",
      "[81]\tvalid_set's rmse: 0.0516414\n",
      "[82]\tvalid_set's rmse: 0.0516512\n",
      "[83]\tvalid_set's rmse: 0.0516388\n",
      "[84]\tvalid_set's rmse: 0.0516288\n",
      "[85]\tvalid_set's rmse: 0.0516301\n",
      "[86]\tvalid_set's rmse: 0.0516065\n",
      "[87]\tvalid_set's rmse: 0.0516126\n",
      "[88]\tvalid_set's rmse: 0.0516198\n",
      "[89]\tvalid_set's rmse: 0.0516642\n",
      "[90]\tvalid_set's rmse: 0.0516511\n",
      "[91]\tvalid_set's rmse: 0.0516083\n",
      "[92]\tvalid_set's rmse: 0.0515947\n",
      "[93]\tvalid_set's rmse: 0.0516247\n",
      "[94]\tvalid_set's rmse: 0.0516399\n",
      "[95]\tvalid_set's rmse: 0.051636\n",
      "[96]\tvalid_set's rmse: 0.0516798\n",
      "[97]\tvalid_set's rmse: 0.051701\n",
      "[98]\tvalid_set's rmse: 0.0517183\n",
      "[99]\tvalid_set's rmse: 0.0517079\n",
      "[100]\tvalid_set's rmse: 0.0517107\n",
      "[101]\tvalid_set's rmse: 0.0517428\n",
      "[102]\tvalid_set's rmse: 0.0517446\n",
      "[103]\tvalid_set's rmse: 0.0517708\n",
      "[104]\tvalid_set's rmse: 0.0517564\n",
      "[105]\tvalid_set's rmse: 0.0517812\n",
      "[106]\tvalid_set's rmse: 0.051821\n",
      "[107]\tvalid_set's rmse: 0.0518246\n",
      "[108]\tvalid_set's rmse: 0.0518738\n",
      "[109]\tvalid_set's rmse: 0.0518884\n",
      "[110]\tvalid_set's rmse: 0.0518652\n",
      "[111]\tvalid_set's rmse: 0.0518739\n",
      "[112]\tvalid_set's rmse: 0.05187\n",
      "[113]\tvalid_set's rmse: 0.0518711\n",
      "[114]\tvalid_set's rmse: 0.0518671\n",
      "[115]\tvalid_set's rmse: 0.0518826\n",
      "[116]\tvalid_set's rmse: 0.0518385\n",
      "[117]\tvalid_set's rmse: 0.0518608\n",
      "[118]\tvalid_set's rmse: 0.0518558\n",
      "[119]\tvalid_set's rmse: 0.0518414\n",
      "[120]\tvalid_set's rmse: 0.0518719\n",
      "[121]\tvalid_set's rmse: 0.0518558\n",
      "[122]\tvalid_set's rmse: 0.0518565\n",
      "[123]\tvalid_set's rmse: 0.0518822\n",
      "[124]\tvalid_set's rmse: 0.05189\n",
      "[125]\tvalid_set's rmse: 0.0518661\n",
      "[126]\tvalid_set's rmse: 0.0518655\n",
      "[127]\tvalid_set's rmse: 0.0518841\n",
      "[128]\tvalid_set's rmse: 0.051901\n",
      "[129]\tvalid_set's rmse: 0.0518879\n",
      "[130]\tvalid_set's rmse: 0.0518979\n",
      "[131]\tvalid_set's rmse: 0.0519018\n",
      "[132]\tvalid_set's rmse: 0.0518944\n",
      "[133]\tvalid_set's rmse: 0.0519039\n",
      "[134]\tvalid_set's rmse: 0.051891\n",
      "[135]\tvalid_set's rmse: 0.0518936\n",
      "[136]\tvalid_set's rmse: 0.0518764\n",
      "[137]\tvalid_set's rmse: 0.0519042\n",
      "[138]\tvalid_set's rmse: 0.0518895\n",
      "[139]\tvalid_set's rmse: 0.0518814\n",
      "[140]\tvalid_set's rmse: 0.0518684\n",
      "[141]\tvalid_set's rmse: 0.0518685\n",
      "[142]\tvalid_set's rmse: 0.0518752\n",
      "[143]\tvalid_set's rmse: 0.0518686\n",
      "[144]\tvalid_set's rmse: 0.0518712\n",
      "[145]\tvalid_set's rmse: 0.0518835\n",
      "[146]\tvalid_set's rmse: 0.0518953\n",
      "[147]\tvalid_set's rmse: 0.0518973\n",
      "[148]\tvalid_set's rmse: 0.0519009\n",
      "[149]\tvalid_set's rmse: 0.051883\n",
      "[150]\tvalid_set's rmse: 0.0518816\n",
      "[151]\tvalid_set's rmse: 0.0518747\n",
      "[152]\tvalid_set's rmse: 0.0518806\n",
      "[153]\tvalid_set's rmse: 0.0518733\n",
      "[154]\tvalid_set's rmse: 0.0518708\n",
      "[155]\tvalid_set's rmse: 0.0518671\n",
      "[156]\tvalid_set's rmse: 0.0518662\n",
      "[157]\tvalid_set's rmse: 0.0518521\n",
      "[158]\tvalid_set's rmse: 0.0518412\n",
      "[159]\tvalid_set's rmse: 0.0518511\n",
      "[160]\tvalid_set's rmse: 0.051843\n",
      "[161]\tvalid_set's rmse: 0.0518401\n",
      "[162]\tvalid_set's rmse: 0.0518448\n",
      "[163]\tvalid_set's rmse: 0.0518501\n",
      "[164]\tvalid_set's rmse: 0.0518599\n",
      "[165]\tvalid_set's rmse: 0.0518535\n",
      "[166]\tvalid_set's rmse: 0.0518543\n",
      "[167]\tvalid_set's rmse: 0.0518557\n",
      "[168]\tvalid_set's rmse: 0.0518601\n",
      "[169]\tvalid_set's rmse: 0.0518612\n",
      "[170]\tvalid_set's rmse: 0.0518537\n",
      "[171]\tvalid_set's rmse: 0.0518478\n",
      "[172]\tvalid_set's rmse: 0.0518515\n",
      "[173]\tvalid_set's rmse: 0.0518355\n",
      "[174]\tvalid_set's rmse: 0.0518364\n",
      "[175]\tvalid_set's rmse: 0.0518317\n",
      "[176]\tvalid_set's rmse: 0.0518371\n",
      "[177]\tvalid_set's rmse: 0.0518364\n",
      "[178]\tvalid_set's rmse: 0.0518448\n",
      "[179]\tvalid_set's rmse: 0.0518333\n",
      "[180]\tvalid_set's rmse: 0.0518272\n",
      "[181]\tvalid_set's rmse: 0.0518239\n",
      "[182]\tvalid_set's rmse: 0.0518306\n",
      "[183]\tvalid_set's rmse: 0.0518125\n",
      "[184]\tvalid_set's rmse: 0.0518204\n",
      "[185]\tvalid_set's rmse: 0.0518227\n",
      "[186]\tvalid_set's rmse: 0.0518341\n",
      "[187]\tvalid_set's rmse: 0.0518254\n",
      "[188]\tvalid_set's rmse: 0.0518217\n",
      "[189]\tvalid_set's rmse: 0.0518272\n",
      "[190]\tvalid_set's rmse: 0.0518246\n",
      "[191]\tvalid_set's rmse: 0.0518312\n",
      "[192]\tvalid_set's rmse: 0.0518311\n",
      "[193]\tvalid_set's rmse: 0.0518426\n",
      "[194]\tvalid_set's rmse: 0.0518303\n",
      "[195]\tvalid_set's rmse: 0.0518354\n",
      "[196]\tvalid_set's rmse: 0.0518398\n",
      "[197]\tvalid_set's rmse: 0.0518402\n",
      "[198]\tvalid_set's rmse: 0.0518456\n",
      "[199]\tvalid_set's rmse: 0.0518509\n",
      "[200]\tvalid_set's rmse: 0.0518395\n",
      "[201]\tvalid_set's rmse: 0.0518319\n",
      "[202]\tvalid_set's rmse: 0.0518366\n",
      "[203]\tvalid_set's rmse: 0.0518349\n",
      "[204]\tvalid_set's rmse: 0.0518401\n",
      "[205]\tvalid_set's rmse: 0.0518401\n",
      "[206]\tvalid_set's rmse: 0.0518376\n",
      "[207]\tvalid_set's rmse: 0.0518385\n",
      "[208]\tvalid_set's rmse: 0.051834\n",
      "[209]\tvalid_set's rmse: 0.0518392\n",
      "[210]\tvalid_set's rmse: 0.0518325\n",
      "[211]\tvalid_set's rmse: 0.051844\n",
      "[212]\tvalid_set's rmse: 0.0518476\n",
      "[213]\tvalid_set's rmse: 0.0518398\n",
      "[214]\tvalid_set's rmse: 0.0518412\n",
      "[215]\tvalid_set's rmse: 0.0518354\n",
      "[216]\tvalid_set's rmse: 0.0518384\n",
      "[217]\tvalid_set's rmse: 0.0518414\n",
      "[218]\tvalid_set's rmse: 0.0518458\n",
      "[219]\tvalid_set's rmse: 0.051856\n",
      "[220]\tvalid_set's rmse: 0.0518646\n",
      "[221]\tvalid_set's rmse: 0.0518636\n",
      "[222]\tvalid_set's rmse: 0.0518611\n",
      "[223]\tvalid_set's rmse: 0.0518647\n",
      "[224]\tvalid_set's rmse: 0.0518603\n",
      "[225]\tvalid_set's rmse: 0.0518561\n",
      "[226]\tvalid_set's rmse: 0.0518394\n",
      "[227]\tvalid_set's rmse: 0.0518366\n",
      "[228]\tvalid_set's rmse: 0.0518347\n",
      "[229]\tvalid_set's rmse: 0.051825\n",
      "[230]\tvalid_set's rmse: 0.0518254\n",
      "[231]\tvalid_set's rmse: 0.0518197\n",
      "[232]\tvalid_set's rmse: 0.0518219\n",
      "[233]\tvalid_set's rmse: 0.051827\n",
      "[234]\tvalid_set's rmse: 0.0518301\n",
      "[235]\tvalid_set's rmse: 0.0518254\n",
      "[236]\tvalid_set's rmse: 0.0518363\n",
      "[237]\tvalid_set's rmse: 0.0518298\n",
      "[238]\tvalid_set's rmse: 0.0518278\n",
      "[239]\tvalid_set's rmse: 0.0518267\n",
      "[240]\tvalid_set's rmse: 0.0518309\n",
      "[241]\tvalid_set's rmse: 0.0518354\n",
      "[242]\tvalid_set's rmse: 0.051835\n",
      "[243]\tvalid_set's rmse: 0.0518302\n",
      "[244]\tvalid_set's rmse: 0.0518234\n",
      "[245]\tvalid_set's rmse: 0.0518229\n",
      "[246]\tvalid_set's rmse: 0.0518274\n",
      "[247]\tvalid_set's rmse: 0.0518233\n",
      "[248]\tvalid_set's rmse: 0.0518268\n",
      "[249]\tvalid_set's rmse: 0.0518239\n",
      "[250]\tvalid_set's rmse: 0.0518193\n",
      "[251]\tvalid_set's rmse: 0.0518169\n",
      "[252]\tvalid_set's rmse: 0.0518193\n",
      "[253]\tvalid_set's rmse: 0.0518141\n",
      "[254]\tvalid_set's rmse: 0.0518171\n",
      "[255]\tvalid_set's rmse: 0.051817\n",
      "[256]\tvalid_set's rmse: 0.0518231\n",
      "[257]\tvalid_set's rmse: 0.0518269\n",
      "[258]\tvalid_set's rmse: 0.0518258\n",
      "[259]\tvalid_set's rmse: 0.051826\n",
      "[260]\tvalid_set's rmse: 0.0518184\n",
      "[261]\tvalid_set's rmse: 0.0518204\n",
      "[262]\tvalid_set's rmse: 0.0518151\n",
      "[263]\tvalid_set's rmse: 0.0518164\n",
      "[264]\tvalid_set's rmse: 0.0518166\n",
      "[265]\tvalid_set's rmse: 0.0518139\n",
      "[266]\tvalid_set's rmse: 0.0518246\n",
      "[267]\tvalid_set's rmse: 0.0518241\n",
      "[268]\tvalid_set's rmse: 0.0518223\n",
      "[269]\tvalid_set's rmse: 0.0518227\n",
      "[270]\tvalid_set's rmse: 0.0518172\n",
      "[271]\tvalid_set's rmse: 0.0518251\n",
      "[272]\tvalid_set's rmse: 0.0518163\n",
      "[273]\tvalid_set's rmse: 0.0518227\n",
      "[274]\tvalid_set's rmse: 0.0518178\n",
      "[275]\tvalid_set's rmse: 0.0518103\n",
      "[276]\tvalid_set's rmse: 0.0518133\n",
      "[277]\tvalid_set's rmse: 0.05182\n",
      "[278]\tvalid_set's rmse: 0.0518153\n",
      "[279]\tvalid_set's rmse: 0.0518152\n",
      "[280]\tvalid_set's rmse: 0.0518124\n",
      "[281]\tvalid_set's rmse: 0.0518154\n",
      "[282]\tvalid_set's rmse: 0.0518059\n",
      "[283]\tvalid_set's rmse: 0.0518079\n",
      "[284]\tvalid_set's rmse: 0.051805\n",
      "[285]\tvalid_set's rmse: 0.0518063\n",
      "[286]\tvalid_set's rmse: 0.0518025\n",
      "[287]\tvalid_set's rmse: 0.0518028\n",
      "[288]\tvalid_set's rmse: 0.0518058\n",
      "[289]\tvalid_set's rmse: 0.0518114\n",
      "[290]\tvalid_set's rmse: 0.0518113\n",
      "[291]\tvalid_set's rmse: 0.051802\n",
      "[292]\tvalid_set's rmse: 0.0518007\n",
      "[293]\tvalid_set's rmse: 0.0518036\n",
      "[294]\tvalid_set's rmse: 0.0518116\n",
      "[295]\tvalid_set's rmse: 0.051808\n",
      "[296]\tvalid_set's rmse: 0.0518047\n",
      "[297]\tvalid_set's rmse: 0.0517976\n",
      "[298]\tvalid_set's rmse: 0.0517974\n",
      "[299]\tvalid_set's rmse: 0.0518034\n",
      "[300]\tvalid_set's rmse: 0.0518055\n",
      "[301]\tvalid_set's rmse: 0.0518056\n",
      "[302]\tvalid_set's rmse: 0.0518069\n",
      "[303]\tvalid_set's rmse: 0.0518058\n",
      "[304]\tvalid_set's rmse: 0.0518024\n",
      "[305]\tvalid_set's rmse: 0.0517936\n",
      "[306]\tvalid_set's rmse: 0.0517941\n",
      "[307]\tvalid_set's rmse: 0.0518004\n",
      "[308]\tvalid_set's rmse: 0.0518024\n",
      "[309]\tvalid_set's rmse: 0.0518001\n",
      "[310]\tvalid_set's rmse: 0.0518023\n",
      "[311]\tvalid_set's rmse: 0.0518036\n",
      "[312]\tvalid_set's rmse: 0.0517999\n",
      "[313]\tvalid_set's rmse: 0.0518061\n",
      "[314]\tvalid_set's rmse: 0.0517974\n",
      "[315]\tvalid_set's rmse: 0.0517978\n",
      "[316]\tvalid_set's rmse: 0.0517941\n",
      "[317]\tvalid_set's rmse: 0.0517985\n",
      "[318]\tvalid_set's rmse: 0.0518001\n",
      "[319]\tvalid_set's rmse: 0.0517981\n",
      "[320]\tvalid_set's rmse: 0.0517993\n",
      "[321]\tvalid_set's rmse: 0.0517999\n",
      "[322]\tvalid_set's rmse: 0.0517979\n",
      "[323]\tvalid_set's rmse: 0.0518001\n",
      "[324]\tvalid_set's rmse: 0.0518004\n",
      "[325]\tvalid_set's rmse: 0.0517933\n",
      "[326]\tvalid_set's rmse: 0.0517974\n",
      "[327]\tvalid_set's rmse: 0.0518033\n",
      "[328]\tvalid_set's rmse: 0.0518013\n",
      "[329]\tvalid_set's rmse: 0.0518026\n",
      "[330]\tvalid_set's rmse: 0.0518016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Saving ./agModels-spvae2/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
      "\t-0.0514\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/KNeighborsDist/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/ExtraTreesMSE/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/KNeighborsUnif/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/RandomForestMSE/y_pred_proba_val.pkl\n",
      "Loading: ./agModels-spvae2/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae2/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331]\tvalid_set's rmse: 0.0518035\n",
      "[332]\tvalid_set's rmse: 0.051803\n",
      "[333]\tvalid_set's rmse: 0.0518032\n",
      "[334]\tvalid_set's rmse: 0.0518036\n",
      "[335]\tvalid_set's rmse: 0.0518089\n",
      "[336]\tvalid_set's rmse: 0.0518111\n",
      "[337]\tvalid_set's rmse: 0.0518112\n",
      "[338]\tvalid_set's rmse: 0.0518065\n",
      "[339]\tvalid_set's rmse: 0.0518036\n",
      "[340]\tvalid_set's rmse: 0.0518054\n",
      "[341]\tvalid_set's rmse: 0.0518051\n",
      "[342]\tvalid_set's rmse: 0.0518031\n",
      "[343]\tvalid_set's rmse: 0.051804\n",
      "[344]\tvalid_set's rmse: 0.0518043\n",
      "[345]\tvalid_set's rmse: 0.0518026\n",
      "[346]\tvalid_set's rmse: 0.051803\n",
      "[347]\tvalid_set's rmse: 0.0518062\n",
      "[348]\tvalid_set's rmse: 0.0518071\n",
      "[349]\tvalid_set's rmse: 0.0518073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble size: 14\n",
      "Ensemble indices: [6, 9, 10, 6, 9, 10, 9, 10, 1, 10, 9, 6, 9, 10]\n",
      "Ensemble weights: \n",
      "[0.         0.07142857 0.         0.         0.         0.\n",
      " 0.21428571 0.         0.         0.35714286 0.35714286]\n",
      "Saving ./agModels-spvae2/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0503\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 18.59s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: ./agModels-spvae2/models/trainer.pkl\n",
      "Saving ./agModels-spvae2/models/trainer.pkl\n",
      "Saving ./agModels-spvae2/learner.pkl\n",
      "Saving ./agModels-spvae2/predictor.pkl\n",
      "Saving ./agModels-spvae2/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-spvae2/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-spvae2/\")\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import os\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "save_path = './agModels-all_parts2'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10], 5\n",
    "bag_sets = 3 #suggestion range [1, 20], 3\n",
    "stack_levels = 3 #suggestion range [0, 3], 3\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 18.67135715484619\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_119</th>\n",
       "      <th>dim_120</th>\n",
       "      <th>dim_121</th>\n",
       "      <th>dim_122</th>\n",
       "      <th>dim_123</th>\n",
       "      <th>dim_124</th>\n",
       "      <th>dim_125</th>\n",
       "      <th>dim_126</th>\n",
       "      <th>dim_127</th>\n",
       "      <th>dim_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.675357</td>\n",
       "      <td>0.774387</td>\n",
       "      <td>-2.380979</td>\n",
       "      <td>-0.728630</td>\n",
       "      <td>-1.412328</td>\n",
       "      <td>1.705713</td>\n",
       "      <td>-0.913276</td>\n",
       "      <td>-0.664502</td>\n",
       "      <td>-0.036643</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785418</td>\n",
       "      <td>-0.100383</td>\n",
       "      <td>-1.418045</td>\n",
       "      <td>-5.795298</td>\n",
       "      <td>-0.239288</td>\n",
       "      <td>-3.270577</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>2.296032</td>\n",
       "      <td>-0.461153</td>\n",
       "      <td>1.085652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.058659</td>\n",
       "      <td>0.094974</td>\n",
       "      <td>-0.148768</td>\n",
       "      <td>-1.709858</td>\n",
       "      <td>0.231730</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>-0.203162</td>\n",
       "      <td>0.288094</td>\n",
       "      <td>-0.420197</td>\n",
       "      <td>-2.209749</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.907042</td>\n",
       "      <td>0.220606</td>\n",
       "      <td>0.879496</td>\n",
       "      <td>-1.250059</td>\n",
       "      <td>-0.911256</td>\n",
       "      <td>2.207671</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>1.828314</td>\n",
       "      <td>-0.745860</td>\n",
       "      <td>-1.381517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.408514</td>\n",
       "      <td>-0.318794</td>\n",
       "      <td>-0.195711</td>\n",
       "      <td>-1.258788</td>\n",
       "      <td>-0.074261</td>\n",
       "      <td>-3.524118</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>-0.282567</td>\n",
       "      <td>0.518098</td>\n",
       "      <td>1.104262</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.164850</td>\n",
       "      <td>-2.873618</td>\n",
       "      <td>0.817046</td>\n",
       "      <td>1.877096</td>\n",
       "      <td>-1.402977</td>\n",
       "      <td>-0.992778</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>1.483371</td>\n",
       "      <td>0.380046</td>\n",
       "      <td>0.484612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.754269</td>\n",
       "      <td>-1.133549</td>\n",
       "      <td>-1.814455</td>\n",
       "      <td>0.036195</td>\n",
       "      <td>-0.159687</td>\n",
       "      <td>2.911953</td>\n",
       "      <td>-0.640023</td>\n",
       "      <td>-0.894014</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.164435</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.664808</td>\n",
       "      <td>1.762599</td>\n",
       "      <td>-0.071357</td>\n",
       "      <td>3.233031</td>\n",
       "      <td>-0.915575</td>\n",
       "      <td>2.781991</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>0.508250</td>\n",
       "      <td>-0.724321</td>\n",
       "      <td>-0.320688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-1.054854</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>0.473871</td>\n",
       "      <td>3.140375</td>\n",
       "      <td>-0.449581</td>\n",
       "      <td>2.196428</td>\n",
       "      <td>0.303511</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>0.375206</td>\n",
       "      <td>-0.866014</td>\n",
       "      <td>...</td>\n",
       "      <td>3.855908</td>\n",
       "      <td>0.273155</td>\n",
       "      <td>-2.094910</td>\n",
       "      <td>-3.537341</td>\n",
       "      <td>1.143077</td>\n",
       "      <td>-2.242801</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.217993</td>\n",
       "      <td>-0.597952</td>\n",
       "      <td>1.817741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "46  -1.675357  0.774387 -2.380979 -0.728630 -1.412328  1.705713 -0.913276   \n",
       "101 -0.058659  0.094974 -0.148768 -1.709858  0.231730  0.003423 -0.203162   \n",
       "175  0.408514 -0.318794 -0.195711 -1.258788 -0.074261 -3.524118  0.243094   \n",
       "9   -2.754269 -1.133549 -1.814455  0.036195 -0.159687  2.911953 -0.640023   \n",
       "136 -1.054854  0.100548  0.473871  3.140375 -0.449581  2.196428  0.303511   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_119   dim_120   dim_121  \\\n",
       "46  -0.664502 -0.036643  0.697300  ...  2.785418 -0.100383 -1.418045   \n",
       "101  0.288094 -0.420197 -2.209749  ... -2.907042  0.220606  0.879496   \n",
       "175 -0.282567  0.518098  1.104262  ... -2.164850 -2.873618  0.817046   \n",
       "9   -0.894014  0.440514  0.164435  ... -2.664808  1.762599 -0.071357   \n",
       "136 -0.011313  0.375206 -0.866014  ...  3.855908  0.273155 -2.094910   \n",
       "\n",
       "      dim_122   dim_123   dim_124   dim_125   dim_126   dim_127   dim_128  \n",
       "46  -5.795298 -0.239288 -3.270577  0.005218  2.296032 -0.461153  1.085652  \n",
       "101 -1.250059 -0.911256  2.207671 -0.007707  1.828314 -0.745860 -1.381517  \n",
       "175  1.877096 -1.402977 -0.992778 -0.002622  1.483371  0.380046  0.484612  \n",
       "9    3.233031 -0.915575  2.781991 -0.008800  0.508250 -0.724321 -0.320688  \n",
       "136 -3.537341  1.143077 -2.242801 -0.000889  0.217993 -0.597952  1.817741  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae2/predictor.pkl\n",
      "Loading: ./agModels-spvae2/learner.pkl\n",
      "Loading: ./agModels-spvae2/models/trainer.pkl\n",
      "Loading: ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/KNeighborsDist/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.052029913458336574\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.052029913458336574,\n",
      "    \"mean_squared_error\": -0.002707111894481993,\n",
      "    \"mean_absolute_error\": -0.03948913191665302,\n",
      "    \"r2\": 0.07940497909157618,\n",
      "    \"pearsonr\": 0.3018611278861623,\n",
      "    \"median_absolute_error\": -0.03252647447586057\n",
      "}\n",
      "Loading: ./agModels-spvae2/models/KNeighborsUnif/model.pkl\n",
      "Loading: ./agModels-spvae2/models/KNeighborsDist/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMXT/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBM/model.pkl\n",
      "Loading: ./agModels-spvae2/models/RandomForestMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/CatBoost/model.pkl\n",
      "Loading: ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetFastAI/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetFastAI/model-internals.pkl\n",
      "Loading: ./agModels-spvae2/models/XGBoost/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n",
      "/home/xli/anaconda3/envs/surrogate_autogluon/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Loading: ./agModels-spvae2/models/KNeighborsUnif/model.pkl\n",
      "Loading: ./agModels-spvae2/models/KNeighborsDist/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37827032804489136\n",
      "0.38917893171310425\n",
      "0.37587660551071167\n",
      "0.44189774990081787\n",
      "0.37875816226005554\n",
      "0.39651840925216675\n",
      "0.40124717354774475\n",
      "0.41791316866874695\n",
      "0.43207114934921265\n",
      "0.3840968906879425\n",
      "0.4002808928489685\n",
      "0.40972644090652466\n",
      "0.3700295090675354\n",
      "0.428059458732605\n",
      "0.3960338234901428\n",
      "0.4286670386791229\n",
      "0.3689090609550476\n",
      "0.4227966070175171\n",
      "0.40865519642829895\n",
      "0.36048954725265503\n",
      "0.43040257692337036\n",
      "0.41173142194747925\n",
      "0.3879980742931366\n",
      "0.38057172298431396\n",
      "0.4181513786315918\n",
      "0.3717370629310608\n",
      "0.41384339332580566\n",
      "0.38663816452026367\n",
      "0.3804423213005066\n",
      "0.3811838626861572\n",
      "0.42607587575912476\n",
      "0.3678780794143677\n",
      "0.40069785714149475\n",
      "0.4320749044418335\n",
      "0.38979214429855347\n",
      "0.37909385561943054\n",
      "0.37798306345939636\n",
      "0.3945416808128357\n",
      "0.38940465450286865\n",
      "0.38216638565063477\n",
      "0.43809235095977783\n",
      "0.3774615526199341\n",
      "0.4280720055103302\n",
      "0.4132728576660156\n",
      "0.4227043390274048\n",
      "0.42129242420196533\n",
      "0.36194470524787903\n",
      "0.3706870377063751\n",
      "0.4311797320842743\n",
      "0.4209950566291809\n",
      "0.3846205472946167\n",
      "0.3554178476333618\n",
      "0.3996891975402832\n",
      "0.3987707495689392\n",
      "0.37210512161254883\n",
      "0.3927472233772278\n",
      "0.3972650170326233\n",
      "0.3840867280960083\n",
      "0.41190260648727417\n",
      "0.3934358060359955\n",
      "0.3988819122314453\n",
      "0.4166586697101593\n",
      "0.36987221240997314\n",
      "0.3922364115715027\n",
      "0.38190850615501404\n",
      "0.4378635883331299\n",
      "0.38589048385620117\n",
      "0.3997667133808136\n",
      "0.37070661783218384\n",
      "0.36433282494544983\n",
      "0.3671126067638397\n",
      "0.3825869560241699\n",
      "0.3742908239364624\n",
      "0.3818489611148834\n",
      "0.37810802459716797\n",
      "0.4297342896461487\n",
      "0.40224289894104004\n",
      "0.37365037202835083\n",
      "0.4019010663032532\n",
      "0.4271131753921509\n",
      "0.4110907316207886\n",
      "0.4226844906806946\n",
      "0.3806142508983612\n",
      "0.3854581415653229\n",
      "0.4313127100467682\n",
      "0.4270803928375244\n",
      "0.3842257261276245\n",
      "0.4226515293121338\n",
      "Predictions:  \n",
      " 46     0.378270\n",
      "101    0.389179\n",
      "175    0.375877\n",
      "9      0.441898\n",
      "136    0.378758\n",
      "         ...   \n",
      "173    0.385458\n",
      "5      0.431313\n",
      "55     0.427080\n",
      "428    0.384226\n",
      "334    0.422652\n",
      "Name: drag, Length: 88, dtype: float32\n",
      "{'root_mean_squared_error': -0.052029913458336574, 'mean_squared_error': -0.002707111894481993, 'mean_absolute_error': -0.03948913191665302, 'r2': 0.07940497909157618, 'pearsonr': 0.3018611278861623, 'median_absolute_error': -0.03252647447586057}\n",
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.050320       0.414690  4.638084                0.000411           0.288564            2       True         12\n",
      "1         ExtraTreesMSE  -0.051178       0.129661  1.377134                0.129661           1.377134            1       True          7\n",
      "2         LightGBMLarge  -0.051427       0.002570  1.373143                0.002570           1.373143            1       True         11\n",
      "3              CatBoost  -0.051571       0.018890  7.675025                0.018890           7.675025            1       True          6\n",
      "4        NeuralNetTorch  -0.052031       0.014435  1.559055                0.014435           1.559055            1       True         10\n",
      "5            LightGBMXT  -0.052405       0.002457  0.552663                0.002457           0.552663            1       True          3\n",
      "6       NeuralNetFastAI  -0.052606       0.010792  0.888331                0.010792           0.888331            1       True          8\n",
      "7       RandomForestMSE  -0.052898       0.148623  1.271330                0.148623           1.271330            1       True          5\n",
      "8              LightGBM  -0.053291       0.002203  0.571628                0.002203           0.571628            1       True          4\n",
      "9               XGBoost  -0.054897       0.005693  1.487934                0.005693           1.487934            1       True          9\n",
      "10       KNeighborsDist  -0.055203       0.267614  0.040188                0.267614           0.040188            1       True          2\n",
      "11       KNeighborsUnif  -0.055804       0.159535  0.071019                0.159535           0.071019            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'XGBoostModel', 'XTModel', 'KNNModel', 'CatBoostModel', 'RFModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -0.05580429632909087, 'KNeighborsDist': -0.05520292732220133, 'LightGBMXT': -0.052405192398850824, 'LightGBM': -0.053291459439489396, 'RandomForestMSE': -0.05289834104549659, 'CatBoost': -0.05157142697843243, 'ExtraTreesMSE': -0.05117793164331563, 'NeuralNetFastAI': -0.052606217727325905, 'XGBoost': -0.05489661067390613, 'NeuralNetTorch': -0.05203120366532546, 'LightGBMLarge': -0.0514267993934426, 'WeightedEnsemble_L2': -0.05032019574555271}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': './agModels-spvae2/models/KNeighborsUnif/', 'KNeighborsDist': './agModels-spvae2/models/KNeighborsDist/', 'LightGBMXT': './agModels-spvae2/models/LightGBMXT/', 'LightGBM': './agModels-spvae2/models/LightGBM/', 'RandomForestMSE': './agModels-spvae2/models/RandomForestMSE/', 'CatBoost': './agModels-spvae2/models/CatBoost/', 'ExtraTreesMSE': './agModels-spvae2/models/ExtraTreesMSE/', 'NeuralNetFastAI': './agModels-spvae2/models/NeuralNetFastAI/', 'XGBoost': './agModels-spvae2/models/XGBoost/', 'NeuralNetTorch': './agModels-spvae2/models/NeuralNetTorch/', 'LightGBMLarge': './agModels-spvae2/models/LightGBMLarge/', 'WeightedEnsemble_L2': './agModels-spvae2/models/WeightedEnsemble_L2/'}, 'model_fit_times': {'KNeighborsUnif': 0.07101917266845703, 'KNeighborsDist': 0.04018807411193848, 'LightGBMXT': 0.5526628494262695, 'LightGBM': 0.5716278553009033, 'RandomForestMSE': 1.2713303565979004, 'CatBoost': 7.675024509429932, 'ExtraTreesMSE': 1.3771343231201172, 'NeuralNetFastAI': 0.8883309364318848, 'XGBoost': 1.4879341125488281, 'NeuralNetTorch': 1.5590546131134033, 'LightGBMLarge': 1.373142957687378, 'WeightedEnsemble_L2': 0.28856444358825684}, 'model_pred_times': {'KNeighborsUnif': 0.15953469276428223, 'KNeighborsDist': 0.26761436462402344, 'LightGBMXT': 0.0024566650390625, 'LightGBM': 0.002203226089477539, 'RandomForestMSE': 0.14862322807312012, 'CatBoost': 0.0188901424407959, 'ExtraTreesMSE': 0.12966060638427734, 'NeuralNetFastAI': 0.010792016983032227, 'XGBoost': 0.0056934356689453125, 'NeuralNetTorch': 0.014434576034545898, 'LightGBMLarge': 0.002569913864135742, 'WeightedEnsemble_L2': 0.0004105567932128906}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val  fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.050320       0.414690  4.638084   \n",
      "1         ExtraTreesMSE  -0.051178       0.129661  1.377134   \n",
      "2         LightGBMLarge  -0.051427       0.002570  1.373143   \n",
      "3              CatBoost  -0.051571       0.018890  7.675025   \n",
      "4        NeuralNetTorch  -0.052031       0.014435  1.559055   \n",
      "5            LightGBMXT  -0.052405       0.002457  0.552663   \n",
      "6       NeuralNetFastAI  -0.052606       0.010792  0.888331   \n",
      "7       RandomForestMSE  -0.052898       0.148623  1.271330   \n",
      "8              LightGBM  -0.053291       0.002203  0.571628   \n",
      "9               XGBoost  -0.054897       0.005693  1.487934   \n",
      "10       KNeighborsDist  -0.055203       0.267614  0.040188   \n",
      "11       KNeighborsUnif  -0.055804       0.159535  0.071019   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000411           0.288564            2       True   \n",
      "1                 0.129661           1.377134            1       True   \n",
      "2                 0.002570           1.373143            1       True   \n",
      "3                 0.018890           7.675025            1       True   \n",
      "4                 0.014435           1.559055            1       True   \n",
      "5                 0.002457           0.552663            1       True   \n",
      "6                 0.010792           0.888331            1       True   \n",
      "7                 0.148623           1.271330            1       True   \n",
      "8                 0.002203           0.571628            1       True   \n",
      "9                 0.005693           1.487934            1       True   \n",
      "10                0.267614           0.040188            1       True   \n",
      "11                0.159535           0.071019            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1           7  \n",
      "2          11  \n",
      "3           6  \n",
      "4          10  \n",
      "5           3  \n",
      "6           8  \n",
      "7           5  \n",
      "8           4  \n",
      "9           9  \n",
      "10          2  \n",
      "11          1  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae2/models/LightGBMXT/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBM/model.pkl\n",
      "Loading: ./agModels-spvae2/models/RandomForestMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/CatBoost/model.pkl\n",
      "Loading: ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetFastAI/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetFastAI/model-internals.pkl\n",
      "Loading: ./agModels-spvae2/models/XGBoost/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n",
      "Model scores:\n",
      "{'KNeighborsUnif': -0.05882093005803317, 'KNeighborsDist': -0.05860647197655768, 'LightGBMXT': -0.05223789616202292, 'LightGBM': -0.05343261811298977, 'RandomForestMSE': -0.051955460753050076, 'CatBoost': -0.05194237651764605, 'ExtraTreesMSE': -0.051587911569212525, 'NeuralNetFastAI': -0.053240822438875304, 'XGBoost': -0.053715460090481025, 'NeuralNetTorch': -0.05619314359669742, 'LightGBMLarge': -0.051029898932232164, 'WeightedEnsemble_L2': -0.052029913458336574}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
      "0         LightGBMLarge   -0.051030  -0.051427        0.010416       0.002570   \n",
      "1         ExtraTreesMSE   -0.051588  -0.051178        0.153181       0.129661   \n",
      "2              CatBoost   -0.051942  -0.051571        0.027734       0.018890   \n",
      "3       RandomForestMSE   -0.051955  -0.052898        0.126400       0.148623   \n",
      "4   WeightedEnsemble_L2   -0.052030  -0.050320        0.270829       0.414690   \n",
      "5            LightGBMXT   -0.052238  -0.052405        0.046134       0.002457   \n",
      "6       NeuralNetFastAI   -0.053241  -0.052606        0.040828       0.010792   \n",
      "7              LightGBM   -0.053433  -0.053291        0.004919       0.002203   \n",
      "8               XGBoost   -0.053715  -0.054897        0.026154       0.005693   \n",
      "9        NeuralNetTorch   -0.056193  -0.052031        0.020953       0.014435   \n",
      "10       KNeighborsDist   -0.058606  -0.055203        0.075467       0.267614   \n",
      "11       KNeighborsUnif   -0.058821  -0.055804        0.028342       0.159535   \n",
      "\n",
      "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
      "0   1.373143                 0.010416                0.002570   \n",
      "1   1.377134                 0.153181                0.129661   \n",
      "2   7.675025                 0.027734                0.018890   \n",
      "3   1.271330                 0.126400                0.148623   \n",
      "4   4.638084                 0.010812                0.000411   \n",
      "5   0.552663                 0.046134                0.002457   \n",
      "6   0.888331                 0.040828                0.010792   \n",
      "7   0.571628                 0.004919                0.002203   \n",
      "8   1.487934                 0.026154                0.005693   \n",
      "9   1.559055                 0.020953                0.014435   \n",
      "10  0.040188                 0.075467                0.267614   \n",
      "11  0.071019                 0.028342                0.159535   \n",
      "\n",
      "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
      "0            1.373143            1       True         11  \n",
      "1            1.377134            1       True          7  \n",
      "2            7.675025            1       True          6  \n",
      "3            1.271330            1       True          5  \n",
      "4            0.288564            2       True         12  \n",
      "5            0.552663            1       True          3  \n",
      "6            0.888331            1       True          8  \n",
      "7            0.571628            1       True          4  \n",
      "8            1.487934            1       True          9  \n",
      "9            1.559055            1       True         10  \n",
      "10           0.040188            1       True          2  \n",
      "11           0.071019            1       True          1  \n"
     ]
    }
   ],
   "source": [
    "# %%capture log_output\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# %config Application.log_level = 'DEBUG'\n",
    "# %config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "# with open('./output_5040.log', 'w') as f:\n",
    "#     f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedEnsemble_L2\n"
     ]
    }
   ],
   "source": [
    "best_model = predictor.get_model_best()\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/KNeighborsDist/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-spvae2/models/ExtraTreesMSE/model.pkl\n",
      "Loading: ./agModels-spvae2/models/KNeighborsDist/model.pkl\n",
      "Loading: ./agModels-spvae2/models/LightGBMLarge/model.pkl\n",
      "Loading: ./agModels-spvae2/models/NeuralNetTorch/model.pkl\n",
      "Loading: ./agModels-spvae2/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model=best_model)\n",
    "test_data_pred = predictor.predict(test_data, model=best_model)\n",
    "\n",
    "import numpy as np\n",
    "#save np array y_train_hat to a csv file\n",
    "np.savetxt('./all_parts_vectors_y_test_hat_sdf.csv', test_data_pred, delimiter=',')\n",
    "np.savetxt('./all_parts_vectors_y_train_hat_sdf.csv', train_data_pred, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
