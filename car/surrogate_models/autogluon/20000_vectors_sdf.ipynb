{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate_autogluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_19992</th>\n",
       "      <th>dim_19993</th>\n",
       "      <th>dim_19994</th>\n",
       "      <th>dim_19995</th>\n",
       "      <th>dim_19996</th>\n",
       "      <th>dim_19997</th>\n",
       "      <th>dim_19998</th>\n",
       "      <th>dim_19999</th>\n",
       "      <th>dim_20000</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "61     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "354    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "358    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "275    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "18     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_19992  dim_19993  dim_19994  dim_19995  dim_19996  dim_19997  \\\n",
       "61   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "354  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "358  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "275  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "18   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     dim_19998  dim_19999  dim_20000   drag  \n",
       "61         0.0        0.0        0.0  0.375  \n",
       "354        0.0        0.0        0.0  0.374  \n",
       "358        0.0        0.0        0.0  0.435  \n",
       "275        0.0        0.0        0.0  0.437  \n",
       "18         0.0        0.0        0.0  0.367  \n",
       "\n",
       "[5 rows x 20001 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = '../../../../data_repo/part_aware_data/20000_vectors_drags_sdf.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-20000_sdf\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (351 samples, 56.17 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Saving ./agModels-20000_sdf/learner.pkl\n",
      "Saving ./agModels-20000_sdf/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-20000_sdf/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 20000\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    259424.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 56.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 16058 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t149.4s = Fit runtime\n",
      "\t\t\t16058 features in original data used to generate 16058 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t6.4s = Fit runtime\n",
      "\t\t\t16058 features in original data used to generate 16058 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t6.0s = Fit runtime\n",
      "\t\t\t16058 features in original data used to generate 16058 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t7.2s = Fit runtime\n",
      "\t\t\t16058 features in original data used to generate 16058 features in processed data.\n",
      "\tUseless Original Features (Count: 3942): ['dim_47', 'dim_67', 'dim_70', 'dim_87', 'dim_89', 'dim_90', 'dim_91', 'dim_107', 'dim_108', 'dim_109', 'dim_129', 'dim_130', 'dim_131', 'dim_132', 'dim_149', 'dim_151', 'dim_152', 'dim_153', 'dim_168', 'dim_169', 'dim_173', 'dim_188', 'dim_190', 'dim_193', 'dim_208', 'dim_209', 'dim_210', 'dim_213', 'dim_214', 'dim_229', 'dim_234', 'dim_249', 'dim_250', 'dim_254', 'dim_274', 'dim_275', 'dim_288', 'dim_294', 'dim_296', 'dim_313', 'dim_314', 'dim_315', 'dim_316', 'dim_317', 'dim_318', 'dim_333', 'dim_334', 'dim_335', 'dim_336', 'dim_338', 'dim_353', 'dim_354', 'dim_355', 'dim_373', 'dim_374', 'dim_375', 'dim_379', 'dim_389', 'dim_390', 'dim_392', 'dim_393', 'dim_394', 'dim_395', 'dim_409', 'dim_410', 'dim_412', 'dim_413', 'dim_414', 'dim_415', 'dim_429', 'dim_430', 'dim_431', 'dim_432', 'dim_433', 'dim_434', 'dim_435', 'dim_436', 'dim_438', 'dim_439', 'dim_449', 'dim_450', 'dim_451', 'dim_452', 'dim_453', 'dim_454', 'dim_455', 'dim_456', 'dim_457', 'dim_459', 'dim_460', 'dim_468', 'dim_469', 'dim_470', 'dim_471', 'dim_472', 'dim_476', 'dim_477', 'dim_478', 'dim_488', 'dim_489', 'dim_490', 'dim_491', 'dim_492', 'dim_499', 'dim_508', 'dim_509', 'dim_510', 'dim_511', 'dim_512', 'dim_519', 'dim_528', 'dim_529', 'dim_530', 'dim_531', 'dim_532', 'dim_534', 'dim_548', 'dim_549', 'dim_550', 'dim_551', 'dim_552', 'dim_569', 'dim_570', 'dim_571', 'dim_572', 'dim_573', 'dim_588', 'dim_589', 'dim_590', 'dim_591', 'dim_608', 'dim_609', 'dim_610', 'dim_611', 'dim_628', 'dim_629', 'dim_630', 'dim_631', 'dim_648', 'dim_649', 'dim_650', 'dim_668', 'dim_669', 'dim_670', 'dim_688', 'dim_689', 'dim_690', 'dim_692', 'dim_711', 'dim_712', 'dim_732', 'dim_733', 'dim_734', 'dim_753', 'dim_772', 'dim_773', 'dim_774', 'dim_775', 'dim_776', 'dim_777', 'dim_788', 'dim_789', 'dim_790', 'dim_791', 'dim_792', 'dim_793', 'dim_794', 'dim_795', 'dim_796', 'dim_797', 'dim_798', 'dim_799', 'dim_808', 'dim_809', 'dim_810', 'dim_811', 'dim_813', 'dim_814', 'dim_815', 'dim_816', 'dim_817', 'dim_818', 'dim_819', 'dim_820', 'dim_828', 'dim_829', 'dim_830', 'dim_831', 'dim_832', 'dim_833', 'dim_834', 'dim_835', 'dim_838', 'dim_839', 'dim_840', 'dim_848', 'dim_849', 'dim_850', 'dim_851', 'dim_852', 'dim_853', 'dim_854', 'dim_855', 'dim_856', 'dim_857', 'dim_868', 'dim_869', 'dim_870', 'dim_871', 'dim_872', 'dim_873', 'dim_874', 'dim_888', 'dim_889', 'dim_890', 'dim_891', 'dim_892', 'dim_975', 'dim_977', 'dim_978', 'dim_1071', 'dim_1254', 'dim_1255', 'dim_1295', 'dim_1297', 'dim_1314', 'dim_1315', 'dim_1317', 'dim_1334', 'dim_1336', 'dim_1354', 'dim_1355', 'dim_1374', 'dim_1375', 'dim_1378', 'dim_1379', 'dim_1394', 'dim_1395', 'dim_1399', 'dim_1414', 'dim_1415', 'dim_1434', 'dim_1435', 'dim_1436', 'dim_1438', 'dim_1439', 'dim_1440', 'dim_1454', 'dim_1457', 'dim_1459', 'dim_1460', 'dim_1474', 'dim_1475', 'dim_1476', 'dim_1477', 'dim_1478', 'dim_1498', 'dim_1515', 'dim_1518', 'dim_1560', 'dim_1620', 'dim_1734', 'dim_1754', 'dim_1755', 'dim_1756', 'dim_1774', 'dim_1775', 'dim_1776', 'dim_1777', 'dim_1778', 'dim_1794', 'dim_1795', 'dim_1796', 'dim_1797', 'dim_1798', 'dim_1799', 'dim_1800', 'dim_1813', 'dim_1814', 'dim_1815', 'dim_1817', 'dim_1818', 'dim_1819', 'dim_1820', 'dim_1833', 'dim_1834', 'dim_1835', 'dim_1836', 'dim_1837', 'dim_1838', 'dim_1839', 'dim_1840', 'dim_1855', 'dim_1856', 'dim_1873', 'dim_1874', 'dim_1892', 'dim_1938', 'dim_2275', 'dim_2298', 'dim_2378', 'dim_2379', 'dim_2396', 'dim_2399', 'dim_2436', 'dim_2437', 'dim_2438', 'dim_2439', 'dim_2440', 'dim_2456', 'dim_2459', 'dim_2460', 'dim_2476', 'dim_2477', 'dim_2496', 'dim_2516', 'dim_2557', 'dim_2558', 'dim_2559', 'dim_2577', 'dim_2578', 'dim_2580', 'dim_2598', 'dim_2599', 'dim_2600', 'dim_2619', 'dim_2620', 'dim_2639', 'dim_2640', 'dim_2658', 'dim_2659', 'dim_2660', 'dim_2679', 'dim_2680', 'dim_2700', 'dim_2715', 'dim_2734', 'dim_2735', 'dim_2736', 'dim_2754', 'dim_2755', 'dim_2756', 'dim_2757', 'dim_2759', 'dim_2774', 'dim_2775', 'dim_2776', 'dim_2777', 'dim_2778', 'dim_2779', 'dim_2780', 'dim_2796', 'dim_2797', 'dim_2798', 'dim_2799', 'dim_2800', 'dim_2814', 'dim_2815', 'dim_2816', 'dim_2817', 'dim_2818', 'dim_2819', 'dim_2834', 'dim_2835', 'dim_2836', 'dim_2837', 'dim_2838', 'dim_2839', 'dim_2840', 'dim_2854', 'dim_2855', 'dim_2874', 'dim_2897', 'dim_2898', 'dim_2899', 'dim_2900', 'dim_2953', 'dim_2954', 'dim_2955', 'dim_2956', 'dim_3380', 'dim_3398', 'dim_3418', 'dim_3420', 'dim_3458', 'dim_3459', 'dim_3460', 'dim_3499', 'dim_3558', 'dim_3560', 'dim_3580', 'dim_3598', 'dim_3599', 'dim_3600', 'dim_3617', 'dim_3618', 'dim_3619', 'dim_3620', 'dim_3637', 'dim_3638', 'dim_3639', 'dim_3640', 'dim_3657', 'dim_3658', 'dim_3659', 'dim_3660', 'dim_3678', 'dim_3679', 'dim_3680', 'dim_3697', 'dim_3699', 'dim_3700', 'dim_3717', 'dim_3720', 'dim_3736', 'dim_3738', 'dim_3739', 'dim_3740', 'dim_3755', 'dim_3756', 'dim_3757', 'dim_3760', 'dim_3775', 'dim_3776', 'dim_3777', 'dim_3778', 'dim_3779', 'dim_3780', 'dim_3794', 'dim_3795', 'dim_3796', 'dim_3797', 'dim_3798', 'dim_3799', 'dim_3800', 'dim_3814', 'dim_3815', 'dim_3816', 'dim_3817', 'dim_3819', 'dim_3820', 'dim_3836', 'dim_3837', 'dim_3838', 'dim_3839', 'dim_3840', 'dim_3856', 'dim_3857', 'dim_3917', 'dim_3918', 'dim_3919', 'dim_3933', 'dim_4029', 'dim_4049', 'dim_4191', 'dim_4210', 'dim_4211', 'dim_4230', 'dim_4231', 'dim_4250', 'dim_4251', 'dim_4252', 'dim_4271', 'dim_4272', 'dim_4292', 'dim_4299', 'dim_4300', 'dim_4312', 'dim_4331', 'dim_4332', 'dim_4340', 'dim_4341', 'dim_4342', 'dim_4348', 'dim_4351', 'dim_4352', 'dim_4361', 'dim_4362', 'dim_4368', 'dim_4369', 'dim_4370', 'dim_4371', 'dim_4372', 'dim_4379', 'dim_4389', 'dim_4390', 'dim_4391', 'dim_4392', 'dim_4400', 'dim_4409', 'dim_4410', 'dim_4411', 'dim_4412', 'dim_4420', 'dim_4429', 'dim_4430', 'dim_4431', 'dim_4432', 'dim_4440', 'dim_4449', 'dim_4450', 'dim_4451', 'dim_4452', 'dim_4459', 'dim_4460', 'dim_4469', 'dim_4470', 'dim_4471', 'dim_4472', 'dim_4489', 'dim_4490', 'dim_4491', 'dim_4492', 'dim_4499', 'dim_4509', 'dim_4510', 'dim_4511', 'dim_4512', 'dim_4520', 'dim_4528', 'dim_4529', 'dim_4530', 'dim_4531', 'dim_4532', 'dim_4539', 'dim_4540', 'dim_4548', 'dim_4549', 'dim_4550', 'dim_4551', 'dim_4552', 'dim_4560', 'dim_4568', 'dim_4569', 'dim_4570', 'dim_4571', 'dim_4572', 'dim_4580', 'dim_4589', 'dim_4590', 'dim_4591', 'dim_4592', 'dim_4599', 'dim_4600', 'dim_4608', 'dim_4609', 'dim_4610', 'dim_4611', 'dim_4612', 'dim_4619', 'dim_4620', 'dim_4628', 'dim_4629', 'dim_4630', 'dim_4631', 'dim_4632', 'dim_4639', 'dim_4640', 'dim_4648', 'dim_4649', 'dim_4650', 'dim_4651', 'dim_4659', 'dim_4660', 'dim_4668', 'dim_4669', 'dim_4670', 'dim_4671', 'dim_4679', 'dim_4680', 'dim_4688', 'dim_4689', 'dim_4690', 'dim_4698', 'dim_4699', 'dim_4700', 'dim_4708', 'dim_4709', 'dim_4710', 'dim_4711', 'dim_4717', 'dim_4718', 'dim_4720', 'dim_4728', 'dim_4729', 'dim_4730', 'dim_4731', 'dim_4737', 'dim_4740', 'dim_4750', 'dim_4751', 'dim_4756', 'dim_4757', 'dim_4758', 'dim_4770', 'dim_4771', 'dim_4775', 'dim_4776', 'dim_4777', 'dim_4778', 'dim_4779', 'dim_4780', 'dim_4790', 'dim_4791', 'dim_4794', 'dim_4795', 'dim_4796', 'dim_4797', 'dim_4798', 'dim_4799', 'dim_4800', 'dim_4808', 'dim_4809', 'dim_4810', 'dim_4811', 'dim_4814', 'dim_4815', 'dim_4816', 'dim_4817', 'dim_4818', 'dim_4828', 'dim_4829', 'dim_4830', 'dim_4831', 'dim_4838', 'dim_4848', 'dim_4849', 'dim_4850', 'dim_4937', 'dim_4938', 'dim_4939', 'dim_4940', 'dim_4955', 'dim_4956', 'dim_5009', 'dim_5028', 'dim_5029', 'dim_5048', 'dim_5049', 'dim_5210', 'dim_5211', 'dim_5221', 'dim_5222', 'dim_5230', 'dim_5231', 'dim_5232', 'dim_5241', 'dim_5242', 'dim_5243', 'dim_5249', 'dim_5250', 'dim_5251', 'dim_5252', 'dim_5263', 'dim_5268', 'dim_5269', 'dim_5270', 'dim_5271', 'dim_5272', 'dim_5279', 'dim_5288', 'dim_5289', 'dim_5290', 'dim_5291', 'dim_5292', 'dim_5299', 'dim_5300', 'dim_5302', 'dim_5308', 'dim_5309', 'dim_5310', 'dim_5311', 'dim_5312', 'dim_5320', 'dim_5321', 'dim_5322', 'dim_5329', 'dim_5330', 'dim_5331', 'dim_5332', 'dim_5341', 'dim_5349', 'dim_5350', 'dim_5351', 'dim_5352', 'dim_5360', 'dim_5361', 'dim_5363', 'dim_5368', 'dim_5369', 'dim_5370', 'dim_5371', 'dim_5372', 'dim_5373', 'dim_5380', 'dim_5389', 'dim_5390', 'dim_5391', 'dim_5392', 'dim_5393', 'dim_5409', 'dim_5410', 'dim_5411', 'dim_5412', 'dim_5413', 'dim_5420', 'dim_5429', 'dim_5430', 'dim_5431', 'dim_5432', 'dim_5433', 'dim_5439', 'dim_5440', 'dim_5449', 'dim_5450', 'dim_5451', 'dim_5452', 'dim_5453', 'dim_5460', 'dim_5469', 'dim_5470', 'dim_5471', 'dim_5472', 'dim_5473', 'dim_5489', 'dim_5490', 'dim_5491', 'dim_5492', 'dim_5493', 'dim_5500', 'dim_5509', 'dim_5510', 'dim_5511', 'dim_5512', 'dim_5513', 'dim_5520', 'dim_5528', 'dim_5529', 'dim_5530', 'dim_5531', 'dim_5532', 'dim_5533', 'dim_5540', 'dim_5548', 'dim_5549', 'dim_5550', 'dim_5551', 'dim_5552', 'dim_5553', 'dim_5568', 'dim_5569', 'dim_5570', 'dim_5571', 'dim_5572', 'dim_5573', 'dim_5580', 'dim_5590', 'dim_5591', 'dim_5592', 'dim_5599', 'dim_5600', 'dim_5609', 'dim_5610', 'dim_5611', 'dim_5612', 'dim_5619', 'dim_5620', 'dim_5629', 'dim_5630', 'dim_5631', 'dim_5632', 'dim_5639', 'dim_5640', 'dim_5648', 'dim_5649', 'dim_5650', 'dim_5651', 'dim_5652', 'dim_5659', 'dim_5660', 'dim_5669', 'dim_5670', 'dim_5671', 'dim_5672', 'dim_5679', 'dim_5680', 'dim_5688', 'dim_5689', 'dim_5690', 'dim_5691', 'dim_5698', 'dim_5699', 'dim_5700', 'dim_5702', 'dim_5703', 'dim_5708', 'dim_5709', 'dim_5710', 'dim_5711', 'dim_5718', 'dim_5719', 'dim_5720', 'dim_5721', 'dim_5728', 'dim_5729', 'dim_5730', 'dim_5731', 'dim_5737', 'dim_5738', 'dim_5739', 'dim_5740', 'dim_5741', 'dim_5742', 'dim_5743', 'dim_5748', 'dim_5749', 'dim_5750', 'dim_5751', 'dim_5757', 'dim_5758', 'dim_5759', 'dim_5760', 'dim_5761', 'dim_5762', 'dim_5763', 'dim_5768', 'dim_5769', 'dim_5770', 'dim_5771', 'dim_5776', 'dim_5777', 'dim_5778', 'dim_5779', 'dim_5780', 'dim_5781', 'dim_5782', 'dim_5783', 'dim_5788', 'dim_5789', 'dim_5790', 'dim_5791', 'dim_5795', 'dim_5796', 'dim_5797', 'dim_5798', 'dim_5799', 'dim_5800', 'dim_5802', 'dim_5803', 'dim_5808', 'dim_5809', 'dim_5810', 'dim_5811', 'dim_5814', 'dim_5815', 'dim_5816', 'dim_5817', 'dim_5818', 'dim_5819', 'dim_5820', 'dim_5823', 'dim_5828', 'dim_5829', 'dim_5830', 'dim_5831', 'dim_5834', 'dim_5835', 'dim_5836', 'dim_5837', 'dim_5841', 'dim_5843', 'dim_5848', 'dim_5849', 'dim_5850', 'dim_5854', 'dim_5855', 'dim_5894', 'dim_5895', 'dim_5915', 'dim_5916', 'dim_5920', 'dim_5934', 'dim_5935', 'dim_5936', 'dim_5937', 'dim_5938', 'dim_5939', 'dim_5940', 'dim_5969', 'dim_5970', 'dim_6009', 'dim_6028', 'dim_6029', 'dim_6048', 'dim_6191', 'dim_6210', 'dim_6211', 'dim_6230', 'dim_6231', 'dim_6232', 'dim_6241', 'dim_6242', 'dim_6249', 'dim_6250', 'dim_6251', 'dim_6252', 'dim_6261', 'dim_6262', 'dim_6263', 'dim_6269', 'dim_6270', 'dim_6271', 'dim_6272', 'dim_6281', 'dim_6282', 'dim_6283', 'dim_6289', 'dim_6290', 'dim_6291', 'dim_6292', 'dim_6301', 'dim_6302', 'dim_6303', 'dim_6309', 'dim_6310', 'dim_6311', 'dim_6312', 'dim_6323', 'dim_6329', 'dim_6330', 'dim_6331', 'dim_6332', 'dim_6341', 'dim_6343', 'dim_6349', 'dim_6350', 'dim_6351', 'dim_6352', 'dim_6361', 'dim_6362', 'dim_6363', 'dim_6369', 'dim_6370', 'dim_6371', 'dim_6372', 'dim_6389', 'dim_6390', 'dim_6391', 'dim_6392', 'dim_6409', 'dim_6410', 'dim_6411', 'dim_6412', 'dim_6413', 'dim_6429', 'dim_6430', 'dim_6431', 'dim_6432', 'dim_6433', 'dim_6440', 'dim_6449', 'dim_6450', 'dim_6451', 'dim_6452', 'dim_6453', 'dim_6460', 'dim_6469', 'dim_6470', 'dim_6471', 'dim_6472', 'dim_6473', 'dim_6474', 'dim_6480', 'dim_6489', 'dim_6490', 'dim_6491', 'dim_6492', 'dim_6493', 'dim_6494', 'dim_6500', 'dim_6509', 'dim_6510', 'dim_6511', 'dim_6512', 'dim_6513', 'dim_6514', 'dim_6520', 'dim_6529', 'dim_6530', 'dim_6531', 'dim_6532', 'dim_6533', 'dim_6534', 'dim_6539', 'dim_6540', 'dim_6549', 'dim_6550', 'dim_6551', 'dim_6552', 'dim_6553', 'dim_6559', 'dim_6560', 'dim_6568', 'dim_6569', 'dim_6570', 'dim_6571', 'dim_6572', 'dim_6573', 'dim_6579', 'dim_6589', 'dim_6590', 'dim_6591', 'dim_6592', 'dim_6599', 'dim_6600', 'dim_6609', 'dim_6610', 'dim_6611', 'dim_6612', 'dim_6619', 'dim_6620', 'dim_6629', 'dim_6630', 'dim_6631', 'dim_6632', 'dim_6639', 'dim_6640', 'dim_6649', 'dim_6650', 'dim_6651', 'dim_6652', 'dim_6659', 'dim_6660', 'dim_6663', 'dim_6669', 'dim_6670', 'dim_6671', 'dim_6672', 'dim_6679', 'dim_6680', 'dim_6681', 'dim_6682', 'dim_6689', 'dim_6690', 'dim_6691', 'dim_6692', 'dim_6699', 'dim_6700', 'dim_6701', 'dim_6703', 'dim_6708', 'dim_6709', 'dim_6710', 'dim_6711', 'dim_6718', 'dim_6719', 'dim_6720', 'dim_6721', 'dim_6722', 'dim_6723', 'dim_6728', 'dim_6729', 'dim_6730', 'dim_6731', 'dim_6737', 'dim_6738', 'dim_6739', 'dim_6740', 'dim_6748', 'dim_6749', 'dim_6750', 'dim_6751', 'dim_6757', 'dim_6758', 'dim_6759', 'dim_6760', 'dim_6768', 'dim_6769', 'dim_6770', 'dim_6771', 'dim_6776', 'dim_6777', 'dim_6778', 'dim_6779', 'dim_6780', 'dim_6781', 'dim_6782', 'dim_6783', 'dim_6788', 'dim_6789', 'dim_6790', 'dim_6791', 'dim_6795', 'dim_6796', 'dim_6797', 'dim_6798', 'dim_6799', 'dim_6800', 'dim_6801', 'dim_6803', 'dim_6808', 'dim_6809', 'dim_6810', 'dim_6811', 'dim_6814', 'dim_6815', 'dim_6816', 'dim_6817', 'dim_6818', 'dim_6819', 'dim_6820', 'dim_6821', 'dim_6823', 'dim_6828', 'dim_6829', 'dim_6830', 'dim_6831', 'dim_6834', 'dim_6835', 'dim_6836', 'dim_6837', 'dim_6838', 'dim_6839', 'dim_6840', 'dim_6841', 'dim_6842', 'dim_6848', 'dim_6849', 'dim_6850', 'dim_6854', 'dim_6855', 'dim_6856', 'dim_6857', 'dim_6861', 'dim_6869', 'dim_6874', 'dim_6878', 'dim_6879', 'dim_6880', 'dim_6895', 'dim_6897', 'dim_6898', 'dim_6899', 'dim_6900', 'dim_6917', 'dim_6918', 'dim_6919', 'dim_6920', 'dim_6938', 'dim_6939', 'dim_6940', 'dim_6959', 'dim_6969', 'dim_6970', 'dim_6990', 'dim_7029', 'dim_7182', 'dim_7183', 'dim_7191', 'dim_7210', 'dim_7211', 'dim_7230', 'dim_7231', 'dim_7232', 'dim_7242', 'dim_7250', 'dim_7251', 'dim_7252', 'dim_7261', 'dim_7263', 'dim_7270', 'dim_7271', 'dim_7272', 'dim_7281', 'dim_7282', 'dim_7283', 'dim_7290', 'dim_7291', 'dim_7292', 'dim_7301', 'dim_7303', 'dim_7310', 'dim_7311', 'dim_7312', 'dim_7321', 'dim_7323', 'dim_7330', 'dim_7331', 'dim_7332', 'dim_7340', 'dim_7343', 'dim_7349', 'dim_7350', 'dim_7351', 'dim_7352', 'dim_7362', 'dim_7363', 'dim_7369', 'dim_7370', 'dim_7371', 'dim_7372', 'dim_7382', 'dim_7383', 'dim_7389', 'dim_7390', 'dim_7391', 'dim_7392', 'dim_7400', 'dim_7403', 'dim_7409', 'dim_7410', 'dim_7411', 'dim_7412', 'dim_7413', 'dim_7420', 'dim_7429', 'dim_7430', 'dim_7431', 'dim_7432', 'dim_7433', 'dim_7440', 'dim_7443', 'dim_7449', 'dim_7450', 'dim_7451', 'dim_7452', 'dim_7453', 'dim_7460', 'dim_7463', 'dim_7469', 'dim_7470', 'dim_7471', 'dim_7472', 'dim_7473', 'dim_7480', 'dim_7483', 'dim_7489', 'dim_7490', 'dim_7491', 'dim_7492', 'dim_7493', 'dim_7494', 'dim_7500', 'dim_7503', 'dim_7509', 'dim_7510', 'dim_7511', 'dim_7512', 'dim_7513', 'dim_7514', 'dim_7520', 'dim_7529', 'dim_7530', 'dim_7531', 'dim_7532', 'dim_7533', 'dim_7534', 'dim_7539', 'dim_7540', 'dim_7543', 'dim_7549', 'dim_7550', 'dim_7551', 'dim_7552', 'dim_7553', 'dim_7554', 'dim_7559', 'dim_7560', 'dim_7563', 'dim_7568', 'dim_7569', 'dim_7570', 'dim_7571', 'dim_7572', 'dim_7573', 'dim_7579', 'dim_7580', 'dim_7583', 'dim_7589', 'dim_7590', 'dim_7591', 'dim_7592', 'dim_7599', 'dim_7600', 'dim_7603', 'dim_7609', 'dim_7610', 'dim_7611', 'dim_7612', 'dim_7619', 'dim_7620', 'dim_7623', 'dim_7629', 'dim_7630', 'dim_7631', 'dim_7632', 'dim_7639', 'dim_7640', 'dim_7642', 'dim_7643', 'dim_7649', 'dim_7650', 'dim_7651', 'dim_7652', 'dim_7659', 'dim_7660', 'dim_7661', 'dim_7662', 'dim_7663', 'dim_7669', 'dim_7670', 'dim_7671', 'dim_7672', 'dim_7679', 'dim_7680', 'dim_7681', 'dim_7682', 'dim_7683', 'dim_7688', 'dim_7689', 'dim_7690', 'dim_7691', 'dim_7692', 'dim_7699', 'dim_7700', 'dim_7701', 'dim_7702', 'dim_7703', 'dim_7709', 'dim_7710', 'dim_7711', 'dim_7718', 'dim_7719', 'dim_7720', 'dim_7728', 'dim_7731', 'dim_7737', 'dim_7738', 'dim_7739', 'dim_7740', 'dim_7748', 'dim_7749', 'dim_7750', 'dim_7751', 'dim_7757', 'dim_7758', 'dim_7759', 'dim_7760', 'dim_7762', 'dim_7763', 'dim_7768', 'dim_7769', 'dim_7770', 'dim_7771', 'dim_7776', 'dim_7777', 'dim_7778', 'dim_7779', 'dim_7780', 'dim_7781', 'dim_7783', 'dim_7788', 'dim_7789', 'dim_7790', 'dim_7791', 'dim_7795', 'dim_7796', 'dim_7797', 'dim_7798', 'dim_7799', 'dim_7800', 'dim_7801', 'dim_7802', 'dim_7803', 'dim_7808', 'dim_7809', 'dim_7810', 'dim_7811', 'dim_7814', 'dim_7815', 'dim_7816', 'dim_7817', 'dim_7818', 'dim_7819', 'dim_7820', 'dim_7823', 'dim_7828', 'dim_7829', 'dim_7830', 'dim_7831', 'dim_7834', 'dim_7835', 'dim_7836', 'dim_7837', 'dim_7838', 'dim_7839', 'dim_7840', 'dim_7841', 'dim_7842', 'dim_7848', 'dim_7849', 'dim_7850', 'dim_7854', 'dim_7855', 'dim_7856', 'dim_7857', 'dim_7858', 'dim_7860', 'dim_7869', 'dim_7870', 'dim_7874', 'dim_7879', 'dim_7899', 'dim_7900', 'dim_7913', 'dim_7917', 'dim_7919', 'dim_7920', 'dim_7969', 'dim_7970', 'dim_7973', 'dim_7990', 'dim_8051', 'dim_8144', 'dim_8145', 'dim_8163', 'dim_8170', 'dim_8171', 'dim_8181', 'dim_8182', 'dim_8183', 'dim_8189', 'dim_8190', 'dim_8191', 'dim_8203', 'dim_8210', 'dim_8211', 'dim_8223', 'dim_8231', 'dim_8232', 'dim_8241', 'dim_8242', 'dim_8243', 'dim_8250', 'dim_8251', 'dim_8252', 'dim_8261', 'dim_8262', 'dim_8263', 'dim_8270', 'dim_8271', 'dim_8272', 'dim_8281', 'dim_8282', 'dim_8283', 'dim_8290', 'dim_8291', 'dim_8292', 'dim_8302', 'dim_8303', 'dim_8310', 'dim_8311', 'dim_8312', 'dim_8321', 'dim_8323', 'dim_8329', 'dim_8330', 'dim_8331', 'dim_8332', 'dim_8340', 'dim_8341', 'dim_8342', 'dim_8343', 'dim_8349', 'dim_8350', 'dim_8351', 'dim_8352', 'dim_8360', 'dim_8361', 'dim_8362', 'dim_8363', 'dim_8369', 'dim_8370', 'dim_8371', 'dim_8372', 'dim_8380', 'dim_8381', 'dim_8382', 'dim_8383', 'dim_8389', 'dim_8390', 'dim_8391', 'dim_8392', 'dim_8400', 'dim_8401', 'dim_8402', 'dim_8403', 'dim_8409', 'dim_8410', 'dim_8411', 'dim_8412', 'dim_8420', 'dim_8422', 'dim_8423', 'dim_8429', 'dim_8430', 'dim_8431', 'dim_8432', 'dim_8440', 'dim_8441', 'dim_8442', 'dim_8443', 'dim_8449', 'dim_8450', 'dim_8451', 'dim_8452', 'dim_8460', 'dim_8461', 'dim_8462', 'dim_8463', 'dim_8469', 'dim_8470', 'dim_8471', 'dim_8472', 'dim_8473', 'dim_8480', 'dim_8481', 'dim_8482', 'dim_8483', 'dim_8489', 'dim_8490', 'dim_8491', 'dim_8492', 'dim_8493', 'dim_8501', 'dim_8502', 'dim_8503', 'dim_8509', 'dim_8510', 'dim_8511', 'dim_8512', 'dim_8513', 'dim_8514', 'dim_8520', 'dim_8522', 'dim_8523', 'dim_8529', 'dim_8530', 'dim_8531', 'dim_8532', 'dim_8533', 'dim_8534', 'dim_8539', 'dim_8540', 'dim_8549', 'dim_8550', 'dim_8551', 'dim_8552', 'dim_8553', 'dim_8554', 'dim_8559', 'dim_8560', 'dim_8568', 'dim_8569', 'dim_8570', 'dim_8571', 'dim_8572', 'dim_8573', 'dim_8579', 'dim_8580', 'dim_8581', 'dim_8582', 'dim_8583', 'dim_8589', 'dim_8590', 'dim_8591', 'dim_8592', 'dim_8599', 'dim_8600', 'dim_8601', 'dim_8602', 'dim_8603', 'dim_8609', 'dim_8610', 'dim_8611', 'dim_8612', 'dim_8619', 'dim_8620', 'dim_8621', 'dim_8622', 'dim_8623', 'dim_8629', 'dim_8630', 'dim_8631', 'dim_8632', 'dim_8639', 'dim_8640', 'dim_8641', 'dim_8649', 'dim_8650', 'dim_8651', 'dim_8652', 'dim_8659', 'dim_8660', 'dim_8661', 'dim_8662', 'dim_8663', 'dim_8669', 'dim_8670', 'dim_8671', 'dim_8672', 'dim_8679', 'dim_8680', 'dim_8681', 'dim_8682', 'dim_8683', 'dim_8688', 'dim_8689', 'dim_8690', 'dim_8691', 'dim_8692', 'dim_8699', 'dim_8700', 'dim_8701', 'dim_8709', 'dim_8710', 'dim_8711', 'dim_8718', 'dim_8719', 'dim_8720', 'dim_8721', 'dim_8722', 'dim_8723', 'dim_8728', 'dim_8729', 'dim_8730', 'dim_8731', 'dim_8737', 'dim_8738', 'dim_8739', 'dim_8740', 'dim_8741', 'dim_8742', 'dim_8743', 'dim_8749', 'dim_8750', 'dim_8751', 'dim_8757', 'dim_8758', 'dim_8759', 'dim_8760', 'dim_8761', 'dim_8762', 'dim_8763', 'dim_8768', 'dim_8769', 'dim_8770', 'dim_8771', 'dim_8776', 'dim_8777', 'dim_8778', 'dim_8779', 'dim_8780', 'dim_8781', 'dim_8782', 'dim_8783', 'dim_8788', 'dim_8789', 'dim_8790', 'dim_8791', 'dim_8795', 'dim_8796', 'dim_8797', 'dim_8798', 'dim_8799', 'dim_8800', 'dim_8801', 'dim_8802', 'dim_8803', 'dim_8808', 'dim_8809', 'dim_8810', 'dim_8811', 'dim_8814', 'dim_8815', 'dim_8816', 'dim_8817', 'dim_8818', 'dim_8819', 'dim_8820', 'dim_8823', 'dim_8828', 'dim_8829', 'dim_8830', 'dim_8831', 'dim_8834', 'dim_8835', 'dim_8836', 'dim_8837', 'dim_8838', 'dim_8839', 'dim_8840', 'dim_8841', 'dim_8842', 'dim_8843', 'dim_8848', 'dim_8849', 'dim_8850', 'dim_8854', 'dim_8855', 'dim_8856', 'dim_8857', 'dim_8858', 'dim_8859', 'dim_8860', 'dim_8863', 'dim_8869', 'dim_8870', 'dim_8874', 'dim_8875', 'dim_8876', 'dim_8877', 'dim_8878', 'dim_8894', 'dim_8895', 'dim_8913', 'dim_8914', 'dim_8934', 'dim_8989', 'dim_8990', 'dim_9009', 'dim_9029', 'dim_9163', 'dim_9169', 'dim_9170', 'dim_9171', 'dim_9182', 'dim_9183', 'dim_9189', 'dim_9190', 'dim_9191', 'dim_9201', 'dim_9202', 'dim_9203', 'dim_9210', 'dim_9211', 'dim_9222', 'dim_9223', 'dim_9231', 'dim_9232', 'dim_9241', 'dim_9242', 'dim_9243', 'dim_9251', 'dim_9252', 'dim_9261', 'dim_9262', 'dim_9263', 'dim_9271', 'dim_9272', 'dim_9281', 'dim_9282', 'dim_9283', 'dim_9290', 'dim_9291', 'dim_9292', 'dim_9301', 'dim_9302', 'dim_9303', 'dim_9310', 'dim_9311', 'dim_9312', 'dim_9321', 'dim_9322', 'dim_9323', 'dim_9329', 'dim_9330', 'dim_9331', 'dim_9332', 'dim_9341', 'dim_9342', 'dim_9343', 'dim_9349', 'dim_9350', 'dim_9351', 'dim_9352', 'dim_9360', 'dim_9361', 'dim_9362', 'dim_9363', 'dim_9369', 'dim_9370', 'dim_9371', 'dim_9372', 'dim_9380', 'dim_9381', 'dim_9382', 'dim_9383', 'dim_9389', 'dim_9390', 'dim_9391', 'dim_9392', 'dim_9400', 'dim_9401', 'dim_9402', 'dim_9403', 'dim_9409', 'dim_9410', 'dim_9411', 'dim_9412', 'dim_9420', 'dim_9421', 'dim_9422', 'dim_9423', 'dim_9429', 'dim_9430', 'dim_9431', 'dim_9432', 'dim_9440', 'dim_9441', 'dim_9442', 'dim_9443', 'dim_9449', 'dim_9450', 'dim_9451', 'dim_9452', 'dim_9460', 'dim_9461', 'dim_9462', 'dim_9463', 'dim_9469', 'dim_9470', 'dim_9471', 'dim_9472', 'dim_9473', 'dim_9481', 'dim_9482', 'dim_9483', 'dim_9489', 'dim_9490', 'dim_9491', 'dim_9492', 'dim_9493', 'dim_9501', 'dim_9503', 'dim_9509', 'dim_9510', 'dim_9511', 'dim_9512', 'dim_9513', 'dim_9520', 'dim_9529', 'dim_9530', 'dim_9531', 'dim_9532', 'dim_9533', 'dim_9534', 'dim_9539', 'dim_9540', 'dim_9548', 'dim_9549', 'dim_9550', 'dim_9551', 'dim_9552', 'dim_9553', 'dim_9554', 'dim_9559', 'dim_9560', 'dim_9561', 'dim_9562', 'dim_9563', 'dim_9568', 'dim_9569', 'dim_9570', 'dim_9571', 'dim_9572', 'dim_9573', 'dim_9579', 'dim_9580', 'dim_9581', 'dim_9582', 'dim_9583', 'dim_9589', 'dim_9590', 'dim_9591', 'dim_9592', 'dim_9599', 'dim_9600', 'dim_9601', 'dim_9602', 'dim_9603', 'dim_9609', 'dim_9610', 'dim_9611', 'dim_9612', 'dim_9619', 'dim_9620', 'dim_9629', 'dim_9630', 'dim_9631', 'dim_9632', 'dim_9639', 'dim_9640', 'dim_9641', 'dim_9642', 'dim_9643', 'dim_9649', 'dim_9650', 'dim_9651', 'dim_9652', 'dim_9659', 'dim_9660', 'dim_9661', 'dim_9662', 'dim_9663', 'dim_9669', 'dim_9670', 'dim_9671', 'dim_9672', 'dim_9679', 'dim_9680', 'dim_9681', 'dim_9682', 'dim_9683', 'dim_9688', 'dim_9689', 'dim_9690', 'dim_9691', 'dim_9692', 'dim_9699', 'dim_9700', 'dim_9701', 'dim_9702', 'dim_9703', 'dim_9708', 'dim_9709', 'dim_9710', 'dim_9711', 'dim_9718', 'dim_9719', 'dim_9720', 'dim_9721', 'dim_9722', 'dim_9723', 'dim_9728', 'dim_9729', 'dim_9730', 'dim_9731', 'dim_9737', 'dim_9738', 'dim_9739', 'dim_9740', 'dim_9741', 'dim_9742', 'dim_9743', 'dim_9749', 'dim_9750', 'dim_9751', 'dim_9757', 'dim_9758', 'dim_9759', 'dim_9760', 'dim_9761', 'dim_9762', 'dim_9763', 'dim_9768', 'dim_9769', 'dim_9770', 'dim_9771', 'dim_9776', 'dim_9777', 'dim_9778', 'dim_9779', 'dim_9780', 'dim_9781', 'dim_9782', 'dim_9783', 'dim_9788', 'dim_9789', 'dim_9790', 'dim_9791', 'dim_9795', 'dim_9796', 'dim_9797', 'dim_9798', 'dim_9799', 'dim_9800', 'dim_9801', 'dim_9802', 'dim_9803', 'dim_9808', 'dim_9809', 'dim_9810', 'dim_9811', 'dim_9815', 'dim_9816', 'dim_9817', 'dim_9818', 'dim_9819', 'dim_9820', 'dim_9821', 'dim_9822', 'dim_9823', 'dim_9828', 'dim_9829', 'dim_9830', 'dim_9831', 'dim_9835', 'dim_9836', 'dim_9837', 'dim_9838', 'dim_9839', 'dim_9840', 'dim_9841', 'dim_9842', 'dim_9843', 'dim_9848', 'dim_9849', 'dim_9850', 'dim_9854', 'dim_9855', 'dim_9856', 'dim_9857', 'dim_9858', 'dim_9859', 'dim_9860', 'dim_9861', 'dim_9862', 'dim_9863', 'dim_9869', 'dim_9870', 'dim_9874', 'dim_9875', 'dim_9876', 'dim_9877', 'dim_9878', 'dim_9879', 'dim_9880', 'dim_9894', 'dim_9895', 'dim_9896', 'dim_9913', 'dim_9914', 'dim_9989', 'dim_9990', 'dim_9991', 'dim_10031', 'dim_10051', 'dim_10163', 'dim_10169', 'dim_10170', 'dim_10171', 'dim_10182', 'dim_10183', 'dim_10189', 'dim_10190', 'dim_10191', 'dim_10201', 'dim_10202', 'dim_10203', 'dim_10210', 'dim_10211', 'dim_10221', 'dim_10222', 'dim_10223', 'dim_10231', 'dim_10232', 'dim_10241', 'dim_10242', 'dim_10243', 'dim_10251', 'dim_10252', 'dim_10261', 'dim_10262', 'dim_10263', 'dim_10271', 'dim_10272', 'dim_10281', 'dim_10282', 'dim_10283', 'dim_10290', 'dim_10291', 'dim_10292', 'dim_10301', 'dim_10302', 'dim_10303', 'dim_10310', 'dim_10311', 'dim_10312', 'dim_10321', 'dim_10322', 'dim_10323', 'dim_10329', 'dim_10330', 'dim_10331', 'dim_10332', 'dim_10340', 'dim_10341', 'dim_10342', 'dim_10343', 'dim_10349', 'dim_10350', 'dim_10351', 'dim_10352', 'dim_10360', 'dim_10361', 'dim_10362', 'dim_10363', 'dim_10369', 'dim_10370', 'dim_10371', 'dim_10372', 'dim_10380', 'dim_10381', 'dim_10382', 'dim_10383', 'dim_10389', 'dim_10390', 'dim_10391', 'dim_10392', 'dim_10400', 'dim_10401', 'dim_10402', 'dim_10403', 'dim_10409', 'dim_10410', 'dim_10411', 'dim_10412', 'dim_10420', 'dim_10421', 'dim_10422', 'dim_10423', 'dim_10429', 'dim_10430', 'dim_10431', 'dim_10432', 'dim_10440', 'dim_10441', 'dim_10442', 'dim_10443', 'dim_10449', 'dim_10450', 'dim_10451', 'dim_10452', 'dim_10460', 'dim_10461', 'dim_10462', 'dim_10463', 'dim_10469', 'dim_10470', 'dim_10471', 'dim_10472', 'dim_10473', 'dim_10481', 'dim_10482', 'dim_10483', 'dim_10489', 'dim_10490', 'dim_10491', 'dim_10492', 'dim_10493', 'dim_10500', 'dim_10501', 'dim_10509', 'dim_10510', 'dim_10511', 'dim_10512', 'dim_10513', 'dim_10520', 'dim_10529', 'dim_10530', 'dim_10531', 'dim_10532', 'dim_10533', 'dim_10534', 'dim_10539', 'dim_10540', 'dim_10548', 'dim_10549', 'dim_10550', 'dim_10551', 'dim_10552', 'dim_10553', 'dim_10554', 'dim_10559', 'dim_10560', 'dim_10561', 'dim_10562', 'dim_10563', 'dim_10568', 'dim_10569', 'dim_10570', 'dim_10571', 'dim_10572', 'dim_10573', 'dim_10579', 'dim_10580', 'dim_10582', 'dim_10583', 'dim_10589', 'dim_10590', 'dim_10591', 'dim_10592', 'dim_10593', 'dim_10599', 'dim_10600', 'dim_10601', 'dim_10602', 'dim_10603', 'dim_10609', 'dim_10610', 'dim_10611', 'dim_10612', 'dim_10613', 'dim_10619', 'dim_10620', 'dim_10629', 'dim_10630', 'dim_10631', 'dim_10632', 'dim_10639', 'dim_10640', 'dim_10641', 'dim_10642', 'dim_10643', 'dim_10649', 'dim_10650', 'dim_10651', 'dim_10652', 'dim_10659', 'dim_10660', 'dim_10661', 'dim_10662', 'dim_10663', 'dim_10669', 'dim_10670', 'dim_10671', 'dim_10672', 'dim_10679', 'dim_10680', 'dim_10681', 'dim_10682', 'dim_10683', 'dim_10688', 'dim_10689', 'dim_10690', 'dim_10691', 'dim_10692', 'dim_10699', 'dim_10700', 'dim_10701', 'dim_10702', 'dim_10703', 'dim_10708', 'dim_10709', 'dim_10710', 'dim_10711', 'dim_10718', 'dim_10719', 'dim_10720', 'dim_10721', 'dim_10722', 'dim_10723', 'dim_10728', 'dim_10729', 'dim_10730', 'dim_10731', 'dim_10737', 'dim_10738', 'dim_10739', 'dim_10740', 'dim_10741', 'dim_10742', 'dim_10743', 'dim_10749', 'dim_10750', 'dim_10751', 'dim_10757', 'dim_10759', 'dim_10760', 'dim_10761', 'dim_10762', 'dim_10763', 'dim_10768', 'dim_10769', 'dim_10770', 'dim_10771', 'dim_10776', 'dim_10777', 'dim_10779', 'dim_10780', 'dim_10781', 'dim_10782', 'dim_10783', 'dim_10788', 'dim_10789', 'dim_10790', 'dim_10791', 'dim_10795', 'dim_10796', 'dim_10797', 'dim_10799', 'dim_10800', 'dim_10801', 'dim_10802', 'dim_10803', 'dim_10808', 'dim_10809', 'dim_10810', 'dim_10811', 'dim_10815', 'dim_10816', 'dim_10817', 'dim_10818', 'dim_10819', 'dim_10820', 'dim_10821', 'dim_10822', 'dim_10823', 'dim_10828', 'dim_10829', 'dim_10830', 'dim_10831', 'dim_10835', 'dim_10836', 'dim_10837', 'dim_10838', 'dim_10839', 'dim_10840', 'dim_10841', 'dim_10842', 'dim_10843', 'dim_10848', 'dim_10849', 'dim_10850', 'dim_10854', 'dim_10855', 'dim_10856', 'dim_10857', 'dim_10858', 'dim_10859', 'dim_10860', 'dim_10861', 'dim_10862', 'dim_10863', 'dim_10869', 'dim_10870', 'dim_10874', 'dim_10875', 'dim_10876', 'dim_10877', 'dim_10878', 'dim_10879', 'dim_10894', 'dim_10895', 'dim_10989', 'dim_10990', 'dim_10991', 'dim_10992', 'dim_11009', 'dim_11010', 'dim_11029', 'dim_11030', 'dim_11031', 'dim_11050', 'dim_11051', 'dim_11170', 'dim_11171', 'dim_11183', 'dim_11189', 'dim_11190', 'dim_11191', 'dim_11201', 'dim_11202', 'dim_11203', 'dim_11210', 'dim_11211', 'dim_11221', 'dim_11223', 'dim_11231', 'dim_11232', 'dim_11241', 'dim_11242', 'dim_11243', 'dim_11251', 'dim_11252', 'dim_11261', 'dim_11263', 'dim_11270', 'dim_11271', 'dim_11272', 'dim_11281', 'dim_11282', 'dim_11283', 'dim_11290', 'dim_11292', 'dim_11301', 'dim_11302', 'dim_11303', 'dim_11310', 'dim_11311', 'dim_11312', 'dim_11321', 'dim_11322', 'dim_11323', 'dim_11330', 'dim_11331', 'dim_11332', 'dim_11340', 'dim_11341', 'dim_11342', 'dim_11343', 'dim_11349', 'dim_11350', 'dim_11351', 'dim_11352', 'dim_11360', 'dim_11361', 'dim_11362', 'dim_11363', 'dim_11369', 'dim_11370', 'dim_11371', 'dim_11372', 'dim_11381', 'dim_11382', 'dim_11383', 'dim_11389', 'dim_11390', 'dim_11391', 'dim_11392', 'dim_11401', 'dim_11402', 'dim_11403', 'dim_11409', 'dim_11410', 'dim_11411', 'dim_11412', 'dim_11420', 'dim_11421', 'dim_11422', 'dim_11423', 'dim_11429', 'dim_11430', 'dim_11431', 'dim_11432', 'dim_11440', 'dim_11442', 'dim_11443', 'dim_11449', 'dim_11450', 'dim_11451', 'dim_11452', 'dim_11460', 'dim_11461', 'dim_11462', 'dim_11463', 'dim_11469', 'dim_11470', 'dim_11471', 'dim_11472', 'dim_11473', 'dim_11481', 'dim_11482', 'dim_11483', 'dim_11489', 'dim_11490', 'dim_11491', 'dim_11492', 'dim_11493', 'dim_11500', 'dim_11501', 'dim_11502', 'dim_11503', 'dim_11509', 'dim_11510', 'dim_11511', 'dim_11512', 'dim_11513', 'dim_11514', 'dim_11520', 'dim_11521', 'dim_11522', 'dim_11523', 'dim_11529', 'dim_11530', 'dim_11531', 'dim_11532', 'dim_11533', 'dim_11534', 'dim_11539', 'dim_11540', 'dim_11541', 'dim_11542', 'dim_11543', 'dim_11548', 'dim_11549', 'dim_11550', 'dim_11551', 'dim_11552', 'dim_11553', 'dim_11554', 'dim_11559', 'dim_11560', 'dim_11568', 'dim_11569', 'dim_11570', 'dim_11571', 'dim_11572', 'dim_11573', 'dim_11579', 'dim_11580', 'dim_11589', 'dim_11590', 'dim_11591', 'dim_11592', 'dim_11599', 'dim_11600', 'dim_11609', 'dim_11610', 'dim_11611', 'dim_11612', 'dim_11619', 'dim_11620', 'dim_11621', 'dim_11623', 'dim_11629', 'dim_11630', 'dim_11631', 'dim_11632', 'dim_11639', 'dim_11640', 'dim_11649', 'dim_11650', 'dim_11651', 'dim_11652', 'dim_11659', 'dim_11660', 'dim_11661', 'dim_11669', 'dim_11670', 'dim_11671', 'dim_11672', 'dim_11679', 'dim_11680', 'dim_11681', 'dim_11682', 'dim_11683', 'dim_11688', 'dim_11689', 'dim_11690', 'dim_11691', 'dim_11692', 'dim_11699', 'dim_11700', 'dim_11701', 'dim_11702', 'dim_11703', 'dim_11709', 'dim_11710', 'dim_11711', 'dim_11718', 'dim_11719', 'dim_11720', 'dim_11721', 'dim_11722', 'dim_11723', 'dim_11728', 'dim_11729', 'dim_11730', 'dim_11731', 'dim_11737', 'dim_11738', 'dim_11739', 'dim_11740', 'dim_11741', 'dim_11742', 'dim_11743', 'dim_11749', 'dim_11750', 'dim_11751', 'dim_11758', 'dim_11759', 'dim_11760', 'dim_11762', 'dim_11763', 'dim_11768', 'dim_11769', 'dim_11770', 'dim_11771', 'dim_11776', 'dim_11778', 'dim_11779', 'dim_11780', 'dim_11781', 'dim_11782', 'dim_11783', 'dim_11788', 'dim_11789', 'dim_11790', 'dim_11791', 'dim_11795', 'dim_11796', 'dim_11797', 'dim_11798', 'dim_11799', 'dim_11800', 'dim_11801', 'dim_11802', 'dim_11803', 'dim_11808', 'dim_11809', 'dim_11810', 'dim_11811', 'dim_11814', 'dim_11815', 'dim_11816', 'dim_11817', 'dim_11819', 'dim_11820', 'dim_11821', 'dim_11822', 'dim_11823', 'dim_11828', 'dim_11829', 'dim_11830', 'dim_11831', 'dim_11834', 'dim_11835', 'dim_11836', 'dim_11837', 'dim_11838', 'dim_11839', 'dim_11840', 'dim_11841', 'dim_11842', 'dim_11843', 'dim_11849', 'dim_11850', 'dim_11854', 'dim_11855', 'dim_11856', 'dim_11857', 'dim_11858', 'dim_11859', 'dim_11860', 'dim_11863', 'dim_11869', 'dim_11870', 'dim_11874', 'dim_11875', 'dim_11876', 'dim_11955', 'dim_11975', 'dim_11991', 'dim_12009', 'dim_12029', 'dim_12051', 'dim_12171', 'dim_12191', 'dim_12203', 'dim_12210', 'dim_12211', 'dim_12223', 'dim_12230', 'dim_12231', 'dim_12232', 'dim_12241', 'dim_12242', 'dim_12243', 'dim_12250', 'dim_12251', 'dim_12252', 'dim_12261', 'dim_12262', 'dim_12263', 'dim_12270', 'dim_12271', 'dim_12272', 'dim_12281', 'dim_12282', 'dim_12290', 'dim_12291', 'dim_12292', 'dim_12301', 'dim_12302', 'dim_12303', 'dim_12310', 'dim_12311', 'dim_12312', 'dim_12321', 'dim_12322', 'dim_12323', 'dim_12330', 'dim_12331', 'dim_12332', 'dim_12341', 'dim_12342', 'dim_12343', 'dim_12349', 'dim_12350', 'dim_12351', 'dim_12352', 'dim_12361', 'dim_12362', 'dim_12363', 'dim_12369', 'dim_12370', 'dim_12371', 'dim_12372', 'dim_12389', 'dim_12390', 'dim_12391', 'dim_12392', 'dim_12401', 'dim_12402', 'dim_12403', 'dim_12409', 'dim_12410', 'dim_12411', 'dim_12412', 'dim_12413', 'dim_12420', 'dim_12421', 'dim_12422', 'dim_12423', 'dim_12429', 'dim_12430', 'dim_12431', 'dim_12432', 'dim_12433', 'dim_12440', 'dim_12443', 'dim_12449', 'dim_12450', 'dim_12451', 'dim_12452', 'dim_12453', 'dim_12460', 'dim_12462', 'dim_12469', 'dim_12470', 'dim_12471', 'dim_12472', 'dim_12473', 'dim_12480', 'dim_12482', 'dim_12483', 'dim_12489', 'dim_12490', 'dim_12491', 'dim_12492', 'dim_12493', 'dim_12494', 'dim_12500', 'dim_12502', 'dim_12503', 'dim_12509', 'dim_12510', 'dim_12511', 'dim_12512', 'dim_12513', 'dim_12514', 'dim_12520', 'dim_12522', 'dim_12523', 'dim_12529', 'dim_12530', 'dim_12531', 'dim_12532', 'dim_12533', 'dim_12534', 'dim_12539', 'dim_12540', 'dim_12542', 'dim_12543', 'dim_12548', 'dim_12549', 'dim_12550', 'dim_12551', 'dim_12553', 'dim_12554', 'dim_12559', 'dim_12560', 'dim_12568', 'dim_12569', 'dim_12570', 'dim_12571', 'dim_12572', 'dim_12573', 'dim_12579', 'dim_12580', 'dim_12589', 'dim_12590', 'dim_12591', 'dim_12599', 'dim_12600', 'dim_12609', 'dim_12610', 'dim_12611', 'dim_12612', 'dim_12619', 'dim_12620', 'dim_12629', 'dim_12630', 'dim_12631', 'dim_12632', 'dim_12639', 'dim_12640', 'dim_12649', 'dim_12650', 'dim_12651', 'dim_12652', 'dim_12659', 'dim_12660', 'dim_12661', 'dim_12662', 'dim_12663', 'dim_12669', 'dim_12670', 'dim_12671', 'dim_12672', 'dim_12679', 'dim_12680', 'dim_12681', 'dim_12682', 'dim_12683', 'dim_12688', 'dim_12689', 'dim_12690', 'dim_12691', 'dim_12692', 'dim_12699', 'dim_12700', 'dim_12701', 'dim_12703', 'dim_12709', 'dim_12710', 'dim_12711', 'dim_12718', 'dim_12719', 'dim_12720', 'dim_12721', 'dim_12722', 'dim_12723', 'dim_12728', 'dim_12729', 'dim_12730', 'dim_12731', 'dim_12738', 'dim_12739', 'dim_12740', 'dim_12741', 'dim_12742', 'dim_12743', 'dim_12748', 'dim_12749', 'dim_12750', 'dim_12751', 'dim_12758', 'dim_12759', 'dim_12760', 'dim_12762', 'dim_12763', 'dim_12769', 'dim_12770', 'dim_12771', 'dim_12776', 'dim_12778', 'dim_12781', 'dim_12782', 'dim_12783', 'dim_12789', 'dim_12790', 'dim_12791', 'dim_12795', 'dim_12796', 'dim_12798', 'dim_12799', 'dim_12802', 'dim_12803', 'dim_12809', 'dim_12810', 'dim_12811', 'dim_12814', 'dim_12815', 'dim_12816', 'dim_12817', 'dim_12818', 'dim_12819', 'dim_12820', 'dim_12821', 'dim_12822', 'dim_12823', 'dim_12828', 'dim_12829', 'dim_12830', 'dim_12831', 'dim_12834', 'dim_12835', 'dim_12836', 'dim_12837', 'dim_12838', 'dim_12839', 'dim_12840', 'dim_12841', 'dim_12842', 'dim_12843', 'dim_12849', 'dim_12850', 'dim_12854', 'dim_12855', 'dim_12856', 'dim_12857', 'dim_12858', 'dim_12859', 'dim_12861', 'dim_12869', 'dim_12870', 'dim_12874', 'dim_12875', 'dim_12934', 'dim_12935', 'dim_12970', 'dim_12971', 'dim_12977', 'dim_12990', 'dim_12991', 'dim_12996', 'dim_12998', 'dim_13010', 'dim_13029', 'dim_13030', 'dim_13050', 'dim_13051', 'dim_13070', 'dim_13191', 'dim_13210', 'dim_13211', 'dim_13230', 'dim_13231', 'dim_13232', 'dim_13243', 'dim_13249', 'dim_13250', 'dim_13251', 'dim_13252', 'dim_13261', 'dim_13262', 'dim_13263', 'dim_13269', 'dim_13270', 'dim_13271', 'dim_13272', 'dim_13280', 'dim_13281', 'dim_13282', 'dim_13283', 'dim_13289', 'dim_13290', 'dim_13291', 'dim_13292', 'dim_13301', 'dim_13302', 'dim_13303', 'dim_13309', 'dim_13310', 'dim_13311', 'dim_13312', 'dim_13321', 'dim_13322', 'dim_13323', 'dim_13329', 'dim_13330', 'dim_13331', 'dim_13332', 'dim_13341', 'dim_13342', 'dim_13343', 'dim_13349', 'dim_13350', 'dim_13351', 'dim_13352', 'dim_13361', 'dim_13363', 'dim_13369', 'dim_13370', 'dim_13371', 'dim_13372', 'dim_13373', 'dim_13389', 'dim_13390', 'dim_13391', 'dim_13392', 'dim_13393', 'dim_13409', 'dim_13410', 'dim_13411', 'dim_13412', 'dim_13413', 'dim_13429', 'dim_13430', 'dim_13431', 'dim_13432', 'dim_13433', 'dim_13440', 'dim_13449', 'dim_13450', 'dim_13451', 'dim_13452', 'dim_13453', 'dim_13460', 'dim_13469', 'dim_13470', 'dim_13471', 'dim_13472', 'dim_13473', 'dim_13474', 'dim_13480', 'dim_13489', 'dim_13490', 'dim_13491', 'dim_13492', 'dim_13493', 'dim_13494', 'dim_13500', 'dim_13509', 'dim_13510', 'dim_13511', 'dim_13512', 'dim_13513', 'dim_13514', 'dim_13520', 'dim_13529', 'dim_13530', 'dim_13531', 'dim_13532', 'dim_13533', 'dim_13534', 'dim_13539', 'dim_13540', 'dim_13548', 'dim_13549', 'dim_13550', 'dim_13551', 'dim_13552', 'dim_13553', 'dim_13559', 'dim_13560', 'dim_13563', 'dim_13568', 'dim_13569', 'dim_13570', 'dim_13571', 'dim_13572', 'dim_13573', 'dim_13579', 'dim_13580', 'dim_13589', 'dim_13590', 'dim_13591', 'dim_13592', 'dim_13599', 'dim_13600', 'dim_13603', 'dim_13609', 'dim_13610', 'dim_13611', 'dim_13612', 'dim_13619', 'dim_13623', 'dim_13629', 'dim_13630', 'dim_13631', 'dim_13632', 'dim_13639', 'dim_13640', 'dim_13649', 'dim_13650', 'dim_13651', 'dim_13652', 'dim_13659', 'dim_13660', 'dim_13669', 'dim_13670', 'dim_13671', 'dim_13672', 'dim_13679', 'dim_13680', 'dim_13681', 'dim_13682', 'dim_13683', 'dim_13688', 'dim_13689', 'dim_13690', 'dim_13691', 'dim_13692', 'dim_13699', 'dim_13700', 'dim_13702', 'dim_13703', 'dim_13708', 'dim_13709', 'dim_13710', 'dim_13711', 'dim_13718', 'dim_13719', 'dim_13720', 'dim_13728', 'dim_13729', 'dim_13730', 'dim_13731', 'dim_13738', 'dim_13741', 'dim_13742', 'dim_13748', 'dim_13749', 'dim_13750', 'dim_13751', 'dim_13763', 'dim_13768', 'dim_13769', 'dim_13770', 'dim_13771', 'dim_13776', 'dim_13782', 'dim_13788', 'dim_13789', 'dim_13790', 'dim_13791', 'dim_13795', 'dim_13796', 'dim_13797', 'dim_13798', 'dim_13801', 'dim_13803', 'dim_13808', 'dim_13809', 'dim_13810', 'dim_13811', 'dim_13814', 'dim_13815', 'dim_13816', 'dim_13818', 'dim_13822', 'dim_13823', 'dim_13828', 'dim_13829', 'dim_13830', 'dim_13831', 'dim_13834', 'dim_13835', 'dim_13836', 'dim_13837', 'dim_13838', 'dim_13839', 'dim_13840', 'dim_13841', 'dim_13842', 'dim_13843', 'dim_13849', 'dim_13850', 'dim_13854', 'dim_13855', 'dim_13856', 'dim_13861', 'dim_13869', 'dim_13934', 'dim_13935', 'dim_13936', 'dim_13937', 'dim_13938', 'dim_13939', 'dim_13940', 'dim_13953', 'dim_13954', 'dim_13955', 'dim_13956', 'dim_13957', 'dim_13969', 'dim_13970', 'dim_13989', 'dim_13990', 'dim_14010', 'dim_14029', 'dim_14030', 'dim_14050', 'dim_14051', 'dim_14183', 'dim_14191', 'dim_14210', 'dim_14211', 'dim_14222', 'dim_14230', 'dim_14231', 'dim_14249', 'dim_14250', 'dim_14251', 'dim_14252', 'dim_14268', 'dim_14269', 'dim_14271', 'dim_14272', 'dim_14279', 'dim_14291', 'dim_14292', 'dim_14299', 'dim_14302', 'dim_14303', 'dim_14309', 'dim_14310', 'dim_14311', 'dim_14312', 'dim_14320', 'dim_14328', 'dim_14329', 'dim_14330', 'dim_14331', 'dim_14332', 'dim_14339', 'dim_14340', 'dim_14341', 'dim_14342', 'dim_14343', 'dim_14349', 'dim_14350', 'dim_14351', 'dim_14352', 'dim_14353', 'dim_14359', 'dim_14360', 'dim_14361', 'dim_14368', 'dim_14369', 'dim_14370', 'dim_14371', 'dim_14372', 'dim_14373', 'dim_14380', 'dim_14389', 'dim_14390', 'dim_14391', 'dim_14392', 'dim_14393', 'dim_14400', 'dim_14409', 'dim_14410', 'dim_14411', 'dim_14412', 'dim_14413', 'dim_14429', 'dim_14430', 'dim_14431', 'dim_14432', 'dim_14433', 'dim_14449', 'dim_14450', 'dim_14451', 'dim_14452', 'dim_14453', 'dim_14469', 'dim_14470', 'dim_14471', 'dim_14472', 'dim_14473', 'dim_14489', 'dim_14490', 'dim_14491', 'dim_14492', 'dim_14493', 'dim_14500', 'dim_14509', 'dim_14510', 'dim_14511', 'dim_14512', 'dim_14513', 'dim_14519', 'dim_14520', 'dim_14528', 'dim_14529', 'dim_14530', 'dim_14531', 'dim_14532', 'dim_14533', 'dim_14539', 'dim_14540', 'dim_14548', 'dim_14549', 'dim_14550', 'dim_14551', 'dim_14552', 'dim_14553', 'dim_14559', 'dim_14560', 'dim_14568', 'dim_14569', 'dim_14570', 'dim_14571', 'dim_14572', 'dim_14573', 'dim_14579', 'dim_14580', 'dim_14589', 'dim_14590', 'dim_14591', 'dim_14592', 'dim_14599', 'dim_14609', 'dim_14610', 'dim_14611', 'dim_14612', 'dim_14619', 'dim_14629', 'dim_14630', 'dim_14631', 'dim_14632', 'dim_14639', 'dim_14640', 'dim_14649', 'dim_14650', 'dim_14651', 'dim_14652', 'dim_14659', 'dim_14660', 'dim_14669', 'dim_14670', 'dim_14671', 'dim_14672', 'dim_14679', 'dim_14680', 'dim_14688', 'dim_14689', 'dim_14690', 'dim_14691', 'dim_14698', 'dim_14699', 'dim_14700', 'dim_14703', 'dim_14708', 'dim_14709', 'dim_14710', 'dim_14711', 'dim_14728', 'dim_14729', 'dim_14730', 'dim_14731', 'dim_14741', 'dim_14742', 'dim_14748', 'dim_14749', 'dim_14750', 'dim_14751', 'dim_14761', 'dim_14762', 'dim_14763', 'dim_14768', 'dim_14769', 'dim_14770', 'dim_14771', 'dim_14776', 'dim_14782', 'dim_14783', 'dim_14788', 'dim_14789', 'dim_14790', 'dim_14791', 'dim_14795', 'dim_14796', 'dim_14797', 'dim_14801', 'dim_14803', 'dim_14808', 'dim_14809', 'dim_14810', 'dim_14811', 'dim_14814', 'dim_14815', 'dim_14816', 'dim_14817', 'dim_14818', 'dim_14823', 'dim_14828', 'dim_14829', 'dim_14830', 'dim_14834', 'dim_14835', 'dim_14836', 'dim_14837', 'dim_14838', 'dim_14841', 'dim_14842', 'dim_14849', 'dim_14850', 'dim_14854', 'dim_14856', 'dim_14857', 'dim_14858', 'dim_14859', 'dim_14860', 'dim_14914', 'dim_14916', 'dim_14934', 'dim_14935', 'dim_14936', 'dim_14938', 'dim_14939', 'dim_14940', 'dim_14954', 'dim_14957', 'dim_14958', 'dim_14959', 'dim_14969', 'dim_14970', 'dim_14971', 'dim_14976', 'dim_14977', 'dim_14978', 'dim_14979', 'dim_14980', 'dim_14989', 'dim_14990', 'dim_14991', 'dim_15030', 'dim_15049', 'dim_15050', 'dim_15210', 'dim_15211', 'dim_15230', 'dim_15231', 'dim_15249', 'dim_15250', 'dim_15251', 'dim_15252', 'dim_15270', 'dim_15271', 'dim_15272', 'dim_15292', 'dim_15312', 'dim_15320', 'dim_15331', 'dim_15332', 'dim_15339', 'dim_15340', 'dim_15341', 'dim_15342', 'dim_15348', 'dim_15351', 'dim_15352', 'dim_15360', 'dim_15368', 'dim_15369', 'dim_15370', 'dim_15371', 'dim_15372', 'dim_15389', 'dim_15390', 'dim_15391', 'dim_15392', 'dim_15400', 'dim_15409', 'dim_15410', 'dim_15411', 'dim_15412', 'dim_15420', 'dim_15429', 'dim_15430', 'dim_15431', 'dim_15432', 'dim_15440', 'dim_15449', 'dim_15450', 'dim_15451', 'dim_15452', 'dim_15459', 'dim_15460', 'dim_15469', 'dim_15470', 'dim_15471', 'dim_15472', 'dim_15479', 'dim_15489', 'dim_15490', 'dim_15491', 'dim_15492', 'dim_15509', 'dim_15510', 'dim_15511', 'dim_15512', 'dim_15519', 'dim_15520', 'dim_15528', 'dim_15529', 'dim_15530', 'dim_15531', 'dim_15532', 'dim_15539', 'dim_15540', 'dim_15548', 'dim_15549', 'dim_15550', 'dim_15551', 'dim_15552', 'dim_15559', 'dim_15560', 'dim_15568', 'dim_15569', 'dim_15570', 'dim_15571', 'dim_15572', 'dim_15579', 'dim_15580', 'dim_15589', 'dim_15590', 'dim_15591', 'dim_15592', 'dim_15599', 'dim_15600', 'dim_15609', 'dim_15610', 'dim_15611', 'dim_15612', 'dim_15620', 'dim_15628', 'dim_15629', 'dim_15630', 'dim_15631', 'dim_15632', 'dim_15639', 'dim_15640', 'dim_15648', 'dim_15649', 'dim_15650', 'dim_15651', 'dim_15659', 'dim_15660', 'dim_15668', 'dim_15669', 'dim_15670', 'dim_15671', 'dim_15679', 'dim_15680', 'dim_15688', 'dim_15689', 'dim_15690', 'dim_15691', 'dim_15708', 'dim_15709', 'dim_15710', 'dim_15711', 'dim_15728', 'dim_15729', 'dim_15730', 'dim_15731', 'dim_15748', 'dim_15749', 'dim_15750', 'dim_15751', 'dim_15770', 'dim_15771', 'dim_15775', 'dim_15790', 'dim_15791', 'dim_15794', 'dim_15795', 'dim_15796', 'dim_15810', 'dim_15811', 'dim_15814', 'dim_15815', 'dim_15816', 'dim_15817', 'dim_15830', 'dim_15831', 'dim_15834', 'dim_15835', 'dim_15849', 'dim_15850', 'dim_15877', 'dim_15878', 'dim_15879', 'dim_15880', 'dim_15914', 'dim_15915', 'dim_15916', 'dim_15917', 'dim_15918', 'dim_15919', 'dim_15920', 'dim_15940', 'dim_15951', 'dim_15956', 'dim_15957', 'dim_15958', 'dim_15959', 'dim_15960', 'dim_15970', 'dim_15971', 'dim_15974', 'dim_15977', 'dim_15978', 'dim_15979', 'dim_15980', 'dim_15989', 'dim_15991', 'dim_16000', 'dim_16029', 'dim_16318', 'dim_16319', 'dim_16320', 'dim_16378', 'dim_16418', 'dim_16419', 'dim_16438', 'dim_16439', 'dim_16478', 'dim_16539', 'dim_16559', 'dim_16560', 'dim_16578', 'dim_16579', 'dim_16580', 'dim_16598', 'dim_16599', 'dim_16619', 'dim_16637', 'dim_16695', 'dim_16755', 'dim_16775', 'dim_16794', 'dim_16795', 'dim_16814', 'dim_16815', 'dim_16816', 'dim_16916', 'dim_16917', 'dim_16936', 'dim_16937', 'dim_16938', 'dim_16940', 'dim_16951', 'dim_16956', 'dim_16957', 'dim_16958', 'dim_16959', 'dim_16960', 'dim_16979', 'dim_16980', 'dim_16991', 'dim_16997', 'dim_16998', 'dim_16999', 'dim_17010', 'dim_17030', 'dim_17296', 'dim_17298', 'dim_17316', 'dim_17317', 'dim_17318', 'dim_17320', 'dim_17337', 'dim_17338', 'dim_17357', 'dim_17378', 'dim_17416', 'dim_17418', 'dim_17419', 'dim_17420', 'dim_17436', 'dim_17439', 'dim_17440', 'dim_17456', 'dim_17457', 'dim_17476', 'dim_17477', 'dim_17478', 'dim_17479', 'dim_17480', 'dim_17518', 'dim_17578', 'dim_17579', 'dim_17580', 'dim_17735', 'dim_17754', 'dim_17755', 'dim_17776', 'dim_17878', 'dim_17880', 'dim_17950', 'dim_17951', 'dim_17957', 'dim_17958', 'dim_17959', 'dim_17960', 'dim_17978', 'dim_17979', 'dim_17980', 'dim_18000', 'dim_18091', 'dim_18111', 'dim_18112', 'dim_18275', 'dim_18276', 'dim_18294', 'dim_18295', 'dim_18296', 'dim_18297', 'dim_18314', 'dim_18315', 'dim_18317', 'dim_18318', 'dim_18334', 'dim_18335', 'dim_18338', 'dim_18354', 'dim_18355', 'dim_18374', 'dim_18375', 'dim_18378', 'dim_18394', 'dim_18395', 'dim_18414', 'dim_18415', 'dim_18418', 'dim_18419', 'dim_18434', 'dim_18435', 'dim_18436', 'dim_18439', 'dim_18454', 'dim_18455', 'dim_18457', 'dim_18458', 'dim_18474', 'dim_18476', 'dim_18480', 'dim_18519', 'dim_18754', 'dim_18755', 'dim_18775', 'dim_18776', 'dim_18854', 'dim_18855', 'dim_18856', 'dim_18857', 'dim_18858', 'dim_18898', 'dim_18899', 'dim_18900', 'dim_18929', 'dim_18930', 'dim_18951', 'dim_19049', 'dim_19069', 'dim_19070', 'dim_19089', 'dim_19090', 'dim_19091', 'dim_19109', 'dim_19110', 'dim_19111', 'dim_19129', 'dim_19130', 'dim_19151', 'dim_19152', 'dim_19169', 'dim_19172', 'dim_19173', 'dim_19188', 'dim_19189', 'dim_19191', 'dim_19193', 'dim_19208', 'dim_19209', 'dim_19211', 'dim_19213', 'dim_19229', 'dim_19231', 'dim_19234', 'dim_19249', 'dim_19254', 'dim_19271', 'dim_19274', 'dim_19275', 'dim_19276', 'dim_19288', 'dim_19296', 'dim_19298', 'dim_19313', 'dim_19316', 'dim_19333', 'dim_19353', 'dim_19355', 'dim_19358', 'dim_19359', 'dim_19373', 'dim_19374', 'dim_19375', 'dim_19389', 'dim_19390', 'dim_19392', 'dim_19393', 'dim_19394', 'dim_19395', 'dim_19409', 'dim_19410', 'dim_19412', 'dim_19413', 'dim_19414', 'dim_19415', 'dim_19420', 'dim_19429', 'dim_19430', 'dim_19431', 'dim_19432', 'dim_19433', 'dim_19434', 'dim_19435', 'dim_19436', 'dim_19437', 'dim_19440', 'dim_19449', 'dim_19450', 'dim_19451', 'dim_19452', 'dim_19453', 'dim_19454', 'dim_19455', 'dim_19457', 'dim_19458', 'dim_19459', 'dim_19468', 'dim_19469', 'dim_19470', 'dim_19471', 'dim_19472', 'dim_19473', 'dim_19475', 'dim_19476', 'dim_19478', 'dim_19479', 'dim_19488', 'dim_19489', 'dim_19490', 'dim_19491', 'dim_19492', 'dim_19508', 'dim_19509', 'dim_19510', 'dim_19511', 'dim_19512', 'dim_19513', 'dim_19528', 'dim_19529', 'dim_19530', 'dim_19531', 'dim_19532', 'dim_19533', 'dim_19548', 'dim_19549', 'dim_19550', 'dim_19551', 'dim_19552', 'dim_19553', 'dim_19568', 'dim_19569', 'dim_19570', 'dim_19571', 'dim_19572', 'dim_19588', 'dim_19589', 'dim_19590', 'dim_19591', 'dim_19592', 'dim_19593', 'dim_19608', 'dim_19609', 'dim_19610', 'dim_19611', 'dim_19612', 'dim_19628', 'dim_19629', 'dim_19630', 'dim_19631', 'dim_19648', 'dim_19649', 'dim_19650', 'dim_19651', 'dim_19652', 'dim_19668', 'dim_19669', 'dim_19670', 'dim_19671', 'dim_19672', 'dim_19688', 'dim_19689', 'dim_19690', 'dim_19691', 'dim_19708', 'dim_19709', 'dim_19710', 'dim_19711', 'dim_19712', 'dim_19728', 'dim_19729', 'dim_19730', 'dim_19731', 'dim_19732', 'dim_19748', 'dim_19749', 'dim_19751', 'dim_19752', 'dim_19753', 'dim_19754', 'dim_19773', 'dim_19774', 'dim_19776', 'dim_19793', 'dim_19794', 'dim_19813', 'dim_19815', 'dim_19833', 'dim_19835', 'dim_19836', 'dim_19851', 'dim_19854', 'dim_19856', 'dim_19868', 'dim_19869', 'dim_19870', 'dim_19871', 'dim_19879', 'dim_19888', 'dim_19889', 'dim_19890', 'dim_19891', 'dim_19908', 'dim_19909', 'dim_19911', 'dim_19931', 'dim_19948', 'dim_19949', 'dim_19950']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t243.4s = Fit runtime\n",
      "\t16058 features in original data used to generate 16058 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 252.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-20000_sdf/learner.pkl\n",
      "Saving ./agModels-20000_sdf/utils/data/X.pkl\n",
      "Saving ./agModels-20000_sdf/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 16058 of 16058 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 16058 of 16058 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0446\t = Validation score   (-root_mean_squared_error)\n",
      "\t78.97s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0446\t = Validation score   (-root_mean_squared_error)\n",
      "\t130.83s\t = Training   runtime\n",
      "\t2.48s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 16058 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.98s\t = Training   runtime\n",
      "\t3.79s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t5735.62s\t = Training   runtime\n",
      "\t23.57s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 16058 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.7s\t = Training   runtime\n",
      "\t2.64s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0466\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.44s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0469\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.63s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0446\t = Validation score   (-root_mean_squared_error)\n",
      "\t63.82s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 16058 features.\n",
      "\tDropped 0 of 16058 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16058 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0464\t = Validation score   (-root_mean_squared_error)\n",
      "\t288.39s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 2\n",
      "Ensemble indices: [7, 0]\n",
      "Ensemble weights: \n",
      "[0.5 0.  0.  0.  0.  0.  0.  0.5 0. ]\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0435\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0444\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.44s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0444\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.4s\t = Training   runtime\n",
      "\t1.84s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t27.91s\t = Training   runtime\n",
      "\t2.87s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0453\t = Validation score   (-root_mean_squared_error)\n",
      "\t505.71s\t = Training   runtime\n",
      "\t20.95s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0457\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.17s\t = Training   runtime\n",
      "\t2.85s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0449\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.58s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.0454\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.63s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0439\t = Validation score   (-root_mean_squared_error)\n",
      "\t72.3s\t = Training   runtime\n",
      "\t2.19s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0453\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.91s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 15\n",
      "Ensemble indices: [7, 0, 5, 7, 1, 5, 7, 0, 7, 5, 1, 7, 0, 5, 7]\n",
      "Ensemble weights: \n",
      "[0.2        0.13333333 0.         0.         0.         0.26666667\n",
      " 0.         0.4        0.        ]\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0433\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.0459\t = Validation score   (-root_mean_squared_error)\n",
      "\t61.12s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0459\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.34s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.046\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.06s\t = Training   runtime\n",
      "\t3.06s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0463\t = Validation score   (-root_mean_squared_error)\n",
      "\t639.36s\t = Training   runtime\n",
      "\t16.37s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0463\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.23s\t = Training   runtime\n",
      "\t2.81s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0452\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.97s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0471\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.73s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0439\t = Validation score   (-root_mean_squared_error)\n",
      "\t57.9s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0471\t = Validation score   (-root_mean_squared_error)\n",
      "\t169.13s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 21\n",
      "Ensemble indices: [7, 7, 5, 7, 1, 7, 5, 7, 7, 7, 5, 7, 7, 7, 1, 5, 7, 7, 7, 5, 7]\n",
      "Ensemble weights: \n",
      "[0.         0.0952381  0.         0.         0.         0.23809524\n",
      " 0.         0.66666667 0.        ]\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.0453\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.5s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.84s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.0456\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.06s\t = Training   runtime\n",
      "\t2.73s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0466\t = Validation score   (-root_mean_squared_error)\n",
      "\t315.74s\t = Training   runtime\n",
      "\t15.31s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 16067 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0461\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.81s\t = Training   runtime\n",
      "\t3.52s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.72s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0442\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.87s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0438\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.18s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 16067 features.\n",
      "\tDropped 0 of 16067 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 16067 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.99s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 12\n",
      "Ensemble indices: [7, 6, 5, 1, 7, 6, 7, 1, 7, 5, 6, 7]\n",
      "Ensemble weights: \n",
      "[0.         0.16666667 0.         0.         0.         0.16666667\n",
      " 0.25       0.41666667 0.        ]\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0433\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 10910.18s ... Best model: \"WeightedEnsemble_L5\"\n",
      "Loading: ./agModels-20000_sdf/models/trainer.pkl\n",
      "Saving ./agModels-20000_sdf/models/trainer.pkl\n",
      "Saving ./agModels-20000_sdf/learner.pkl\n",
      "Saving ./agModels-20000_sdf/predictor.pkl\n",
      "Saving ./agModels-20000_sdf/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-20000_sdf/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-20000_sdf/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-20000_sdf'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_19991</th>\n",
       "      <th>dim_19992</th>\n",
       "      <th>dim_19993</th>\n",
       "      <th>dim_19994</th>\n",
       "      <th>dim_19995</th>\n",
       "      <th>dim_19996</th>\n",
       "      <th>dim_19997</th>\n",
       "      <th>dim_19998</th>\n",
       "      <th>dim_19999</th>\n",
       "      <th>dim_20000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "46     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "101    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "175    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "9      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "136    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_19991  dim_19992  dim_19993  dim_19994  dim_19995  dim_19996  \\\n",
       "46   ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "101  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "175  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9    ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "136  ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     dim_19997  dim_19998  dim_19999  dim_20000  \n",
       "46         0.0        0.0        0.0        0.0  \n",
       "101        0.0        0.0        0.0        0.0  \n",
       "175        0.0        0.0        0.0        0.0  \n",
       "9          0.0        0.0        0.0        0.0  \n",
       "136        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-20000_sdf/predictor.pkl\n",
      "Loading: ./agModels-20000_sdf/learner.pkl\n",
      "Loading: ./agModels-20000_sdf/models/trainer.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.04528682111010329\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.04528682111010329,\n",
      "    \"mean_squared_error\": -0.002050896166258497,\n",
      "    \"mean_absolute_error\": -0.03324576616016301,\n",
      "    \"r2\": 0.3025612266318879,\n",
      "    \"pearsonr\": 0.5657264198336751,\n",
      "    \"median_absolute_error\": -0.024818419933319097\n",
      "}\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3858024477958679\n",
      "0.38262665271759033\n",
      "0.3744204640388489\n",
      "0.5213001370429993\n",
      "0.39365607500076294\n",
      "0.4229884743690491\n",
      "0.43686631321907043\n",
      "0.4890339970588684\n",
      "0.39392566680908203\n",
      "0.3345072865486145\n",
      "0.3631858229637146\n",
      "0.3926088809967041\n",
      "0.40933841466903687\n",
      "0.44797155261039734\n",
      "0.424248605966568\n",
      "0.427101194858551\n",
      "0.4012974500656128\n",
      "0.3940713405609131\n",
      "0.3674306869506836\n",
      "0.35109061002731323\n",
      "0.43597325682640076\n",
      "0.42184653878211975\n",
      "0.37662166357040405\n",
      "0.38488510251045227\n",
      "0.47100088000297546\n",
      "0.4221557676792145\n",
      "0.4398912191390991\n",
      "0.3816111087799072\n",
      "0.41505223512649536\n",
      "0.37894076108932495\n",
      "0.4778885841369629\n",
      "0.3548879623413086\n",
      "0.3895949721336365\n",
      "0.4204035997390747\n",
      "0.40566369891166687\n",
      "0.3859163522720337\n",
      "0.3805883526802063\n",
      "0.43534550070762634\n",
      "0.4153739809989929\n",
      "0.39666181802749634\n",
      "0.4922782778739929\n",
      "0.3455815017223358\n",
      "0.49643969535827637\n",
      "0.3665853440761566\n",
      "0.4202210605144501\n",
      "0.39128074049949646\n",
      "0.4230186641216278\n",
      "0.38633695244789124\n",
      "0.3817962408065796\n",
      "0.3537723422050476\n",
      "0.42362433671951294\n",
      "0.3545134663581848\n",
      "0.4249516427516937\n",
      "0.4422343969345093\n",
      "0.3917035460472107\n",
      "0.3881871700286865\n",
      "0.4039973318576813\n",
      "0.40225058794021606\n",
      "0.34700456261634827\n",
      "0.4401966333389282\n",
      "0.4087250530719757\n",
      "0.39738649129867554\n",
      "0.3484407961368561\n",
      "0.40220895409584045\n",
      "0.3845529854297638\n",
      "0.35924240946769714\n",
      "0.41756343841552734\n",
      "0.3487948179244995\n",
      "0.365009069442749\n",
      "0.421495258808136\n",
      "0.41484785079956055\n",
      "0.38446518778800964\n",
      "0.4018990993499756\n",
      "0.3698883652687073\n",
      "0.39943087100982666\n",
      "0.3604292869567871\n",
      "0.4022955894470215\n",
      "0.3648466467857361\n",
      "0.36689597368240356\n",
      "0.43410736322402954\n",
      "0.431831419467926\n",
      "0.4177059531211853\n",
      "0.34192901849746704\n",
      "0.3722902536392212\n",
      "0.37056803703308105\n",
      "0.4334661364555359\n",
      "0.4056133031845093\n",
      "0.373065710067749\n",
      "Predictions:  \n",
      " 46     0.385802\n",
      "101    0.382627\n",
      "175    0.374420\n",
      "9      0.521300\n",
      "136    0.393656\n",
      "         ...   \n",
      "173    0.372290\n",
      "5      0.370568\n",
      "55     0.433466\n",
      "428    0.405613\n",
      "334    0.373066\n",
      "Name: drag, Length: 88, dtype: float32\n",
      "{'root_mean_squared_error': -0.04528682111010329, 'mean_squared_error': -0.002050896166258497, 'mean_absolute_error': -0.03324576616016301, 'r2': 0.3025612266318879, 'pearsonr': 0.5657264198336751, 'median_absolute_error': -0.024818419933319097}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L5  -0.043252     112.053522  8612.280616                0.000883           0.382426            5       True         40\n",
      "1      WeightedEnsemble_L3  -0.043345      47.847604  6657.513572                0.000747           0.395843            3       True         20\n",
      "2      WeightedEnsemble_L2  -0.043484       2.953627   143.256142                0.000789           0.462322            2       True         10\n",
      "3      WeightedEnsemble_L4  -0.043761      81.095035  7479.056296                0.001058           0.407455            4       True         30\n",
      "4    NeuralNetTorch_BAG_L4  -0.043791     108.576984  8500.466241                1.516268          60.184516            4       True         38\n",
      "5    NeuralNetTorch_BAG_L2  -0.043858      41.984745  6519.696959                2.187198          72.302510            2       True         18\n",
      "6    NeuralNetTorch_BAG_L3  -0.043946      78.178292  7378.347852                1.486268          57.896591            3       True         28\n",
      "7          LightGBM_BAG_L4  -0.044178     108.398730  8467.123825                1.338013          26.842100            4       True         32\n",
      "8           XGBoost_BAG_L4  -0.044249     107.918606  8486.152726                0.857889          45.871001            4       True         37\n",
      "9        LightGBMXT_BAG_L2  -0.044422      41.590538  6484.833555                1.792992          37.439106            2       True         11\n",
      "10         LightGBM_BAG_L2  -0.044448      41.640159  6487.798438                1.842613          40.403989            2       True         12\n",
      "11   NeuralNetTorch_BAG_L1  -0.044576       1.125023    63.820650                1.125023          63.820650            1       True          8\n",
      "12       LightGBMXT_BAG_L1  -0.044580       1.827815    78.973169                1.827815          78.973169            1       True          1\n",
      "13         LightGBM_BAG_L1  -0.044580       2.484282   130.832081                2.484282         130.832081            1       True          2\n",
      "14  NeuralNetFastAI_BAG_L2  -0.044878      42.024055  6506.972123                2.226508          59.577674            2       True         16\n",
      "15    LightGBMLarge_BAG_L4  -0.045011     108.377305  8483.267102                1.316588          42.985377            4       True         39\n",
      "16  NeuralNetFastAI_BAG_L4  -0.045028     108.340470  8479.000573                1.279753          38.718848            4       True         36\n",
      "17  NeuralNetFastAI_BAG_L3  -0.045203      78.146859  7360.416564                1.454835          39.965303            3       True         26\n",
      "18    LightGBMLarge_BAG_L2  -0.045274      41.155009  6493.306702                1.357462          45.912254            2       True         19\n",
      "19       LightGBMXT_BAG_L4  -0.045292     108.632694  8498.783319                1.571977          58.501594            4       True         31\n",
      "20         CatBoost_BAG_L2  -0.045300      60.750852  6953.106361               20.953306         505.711912            2       True         14\n",
      "21          XGBoost_BAG_L2  -0.045373      40.611326  6507.022884                0.813780          59.628435            2       True         17\n",
      "22  RandomForestMSE_BAG_L4  -0.045602     109.786574  8464.339287                2.725857          24.057562            4       True         33\n",
      "23    ExtraTreesMSE_BAG_L2  -0.045732      42.650294  6471.562074                2.852747          24.167625            2       True         15\n",
      "24         LightGBM_BAG_L3  -0.045853      78.152874  7380.786946                1.460850          60.335685            3       True         22\n",
      "25       LightGBMXT_BAG_L3  -0.045869      78.100849  7381.571450                1.408824          61.120189            3       True         21\n",
      "26  RandomForestMSE_BAG_L3  -0.045953      79.752757  7344.506744                3.060732          24.055483            3       True         23\n",
      "27    ExtraTreesMSE_BAG_L4  -0.046126     110.582322  8464.092736                3.521605          23.811011            4       True         35\n",
      "28  RandomForestMSE_BAG_L2  -0.046202      42.665420  6475.307755                2.867873          27.913306            2       True         13\n",
      "29         CatBoost_BAG_L1  -0.046246      23.573318  5735.620720               23.573318        5735.620720            1       True          4\n",
      "30         CatBoost_BAG_L3  -0.046257      93.062087  7959.813192               16.370062         639.361931            3       True         24\n",
      "31    ExtraTreesMSE_BAG_L3  -0.046285      79.500334  7343.684960                2.808310          23.233699            3       True         25\n",
      "32    LightGBMLarge_BAG_L1  -0.046388       2.196350   288.391838                2.196350         288.391838            1       True          9\n",
      "33         CatBoost_BAG_L4  -0.046579     122.368549  8756.023974               15.307832         315.742249            4       True         34\n",
      "34  NeuralNetFastAI_BAG_L1  -0.046647       1.448232    40.444216                1.448232          40.444216            1       True          6\n",
      "35          XGBoost_BAG_L1  -0.046880       0.709320    46.630497                0.709320          46.630497            1       True          7\n",
      "36    LightGBMLarge_BAG_L3  -0.047083      78.122455  7489.584229                1.430431         169.132968            3       True         29\n",
      "37          XGBoost_BAG_L3  -0.047134      77.580405  7365.179877                0.888381          44.728616            3       True         27\n",
      "38  RandomForestMSE_BAG_L1  -0.047416       3.794174    38.983467                3.794174          38.983467            1       True          3\n",
      "39    ExtraTreesMSE_BAG_L1  -0.047448       2.639031    23.697812                2.639031          23.697812            1       True          5\n",
      "Number of models trained: 40\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 5 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('int', ['bool']) : 16058 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L2': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L2': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L2': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L2': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L3': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L3': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L3': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L3': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L3': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L3': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L3': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L3': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L3': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L3': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L4': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L4': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L4': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L4': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L4': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L4': 'StackerEnsembleModel_XT', 'NeuralNetFastAI_BAG_L4': 'StackerEnsembleModel_NNFastAiTabular', 'XGBoost_BAG_L4': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L4': 'StackerEnsembleModel_TabularNeuralNetTorch', 'LightGBMLarge_BAG_L4': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L5': 'WeightedEnsembleModel'}, 'model_performance': {'LightGBMXT_BAG_L1': -0.044579813223617974, 'LightGBM_BAG_L1': -0.04457981341533934, 'RandomForestMSE_BAG_L1': -0.047415687458340586, 'CatBoost_BAG_L1': -0.046245508305781585, 'ExtraTreesMSE_BAG_L1': -0.04744769971450827, 'NeuralNetFastAI_BAG_L1': -0.046647471520528165, 'XGBoost_BAG_L1': -0.04688006469925708, 'NeuralNetTorch_BAG_L1': -0.04457557356198216, 'LightGBMLarge_BAG_L1': -0.04638755536916923, 'WeightedEnsemble_L2': -0.043483724907054676, 'LightGBMXT_BAG_L2': -0.044422343594377876, 'LightGBM_BAG_L2': -0.04444830868581227, 'RandomForestMSE_BAG_L2': -0.04620233108828939, 'CatBoost_BAG_L2': -0.04529988632434625, 'ExtraTreesMSE_BAG_L2': -0.045731517364835744, 'NeuralNetFastAI_BAG_L2': -0.04487782825455231, 'XGBoost_BAG_L2': -0.045373362474785066, 'NeuralNetTorch_BAG_L2': -0.043858492795486856, 'LightGBMLarge_BAG_L2': -0.04527419619675821, 'WeightedEnsemble_L3': -0.04334497530147434, 'LightGBMXT_BAG_L3': -0.04586888653393829, 'LightGBM_BAG_L3': -0.04585269061985759, 'RandomForestMSE_BAG_L3': -0.04595250567135371, 'CatBoost_BAG_L3': -0.046257454709001215, 'ExtraTreesMSE_BAG_L3': -0.04628474783392646, 'NeuralNetFastAI_BAG_L3': -0.04520327136565569, 'XGBoost_BAG_L3': -0.04713385921109641, 'NeuralNetTorch_BAG_L3': -0.0439456583809934, 'LightGBMLarge_BAG_L3': -0.04708328404663551, 'WeightedEnsemble_L4': -0.04376099353771332, 'LightGBMXT_BAG_L4': -0.045292475551010535, 'LightGBM_BAG_L4': -0.04417821350493492, 'RandomForestMSE_BAG_L4': -0.04560235321066361, 'CatBoost_BAG_L4': -0.04657946407883185, 'ExtraTreesMSE_BAG_L4': -0.04612620431763965, 'NeuralNetFastAI_BAG_L4': -0.04502848984033634, 'XGBoost_BAG_L4': -0.044248585240707954, 'NeuralNetTorch_BAG_L4': -0.04379100501737489, 'LightGBMLarge_BAG_L4': -0.045010990376972815, 'WeightedEnsemble_L5': -0.04325213359372886}, 'model_best': 'WeightedEnsemble_L5', 'model_paths': {'LightGBMXT_BAG_L1': './agModels-20000_sdf/models/LightGBMXT_BAG_L1/', 'LightGBM_BAG_L1': './agModels-20000_sdf/models/LightGBM_BAG_L1/', 'RandomForestMSE_BAG_L1': './agModels-20000_sdf/models/RandomForestMSE_BAG_L1/', 'CatBoost_BAG_L1': './agModels-20000_sdf/models/CatBoost_BAG_L1/', 'ExtraTreesMSE_BAG_L1': './agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/', 'NeuralNetFastAI_BAG_L1': './agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/', 'XGBoost_BAG_L1': './agModels-20000_sdf/models/XGBoost_BAG_L1/', 'NeuralNetTorch_BAG_L1': './agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/', 'LightGBMLarge_BAG_L1': './agModels-20000_sdf/models/LightGBMLarge_BAG_L1/', 'WeightedEnsemble_L2': './agModels-20000_sdf/models/WeightedEnsemble_L2/', 'LightGBMXT_BAG_L2': './agModels-20000_sdf/models/LightGBMXT_BAG_L2/', 'LightGBM_BAG_L2': './agModels-20000_sdf/models/LightGBM_BAG_L2/', 'RandomForestMSE_BAG_L2': './agModels-20000_sdf/models/RandomForestMSE_BAG_L2/', 'CatBoost_BAG_L2': './agModels-20000_sdf/models/CatBoost_BAG_L2/', 'ExtraTreesMSE_BAG_L2': './agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/', 'NeuralNetFastAI_BAG_L2': './agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/', 'XGBoost_BAG_L2': './agModels-20000_sdf/models/XGBoost_BAG_L2/', 'NeuralNetTorch_BAG_L2': './agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/', 'LightGBMLarge_BAG_L2': './agModels-20000_sdf/models/LightGBMLarge_BAG_L2/', 'WeightedEnsemble_L3': './agModels-20000_sdf/models/WeightedEnsemble_L3/', 'LightGBMXT_BAG_L3': './agModels-20000_sdf/models/LightGBMXT_BAG_L3/', 'LightGBM_BAG_L3': './agModels-20000_sdf/models/LightGBM_BAG_L3/', 'RandomForestMSE_BAG_L3': './agModels-20000_sdf/models/RandomForestMSE_BAG_L3/', 'CatBoost_BAG_L3': './agModels-20000_sdf/models/CatBoost_BAG_L3/', 'ExtraTreesMSE_BAG_L3': './agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/', 'NeuralNetFastAI_BAG_L3': './agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/', 'XGBoost_BAG_L3': './agModels-20000_sdf/models/XGBoost_BAG_L3/', 'NeuralNetTorch_BAG_L3': './agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/', 'LightGBMLarge_BAG_L3': './agModels-20000_sdf/models/LightGBMLarge_BAG_L3/', 'WeightedEnsemble_L4': './agModels-20000_sdf/models/WeightedEnsemble_L4/', 'LightGBMXT_BAG_L4': './agModels-20000_sdf/models/LightGBMXT_BAG_L4/', 'LightGBM_BAG_L4': './agModels-20000_sdf/models/LightGBM_BAG_L4/', 'RandomForestMSE_BAG_L4': './agModels-20000_sdf/models/RandomForestMSE_BAG_L4/', 'CatBoost_BAG_L4': './agModels-20000_sdf/models/CatBoost_BAG_L4/', 'ExtraTreesMSE_BAG_L4': './agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/', 'NeuralNetFastAI_BAG_L4': './agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/', 'XGBoost_BAG_L4': './agModels-20000_sdf/models/XGBoost_BAG_L4/', 'NeuralNetTorch_BAG_L4': './agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/', 'LightGBMLarge_BAG_L4': './agModels-20000_sdf/models/LightGBMLarge_BAG_L4/', 'WeightedEnsemble_L5': './agModels-20000_sdf/models/WeightedEnsemble_L5/'}, 'model_fit_times': {'LightGBMXT_BAG_L1': 78.97316908836365, 'LightGBM_BAG_L1': 130.83208084106445, 'RandomForestMSE_BAG_L1': 38.98346710205078, 'CatBoost_BAG_L1': 5735.620719671249, 'ExtraTreesMSE_BAG_L1': 23.697811603546143, 'NeuralNetFastAI_BAG_L1': 40.44421601295471, 'XGBoost_BAG_L1': 46.63049650192261, 'NeuralNetTorch_BAG_L1': 63.82065010070801, 'LightGBMLarge_BAG_L1': 288.3918375968933, 'WeightedEnsemble_L2': 0.462322473526001, 'LightGBMXT_BAG_L2': 37.43910622596741, 'LightGBM_BAG_L2': 40.40398931503296, 'RandomForestMSE_BAG_L2': 27.91330599784851, 'CatBoost_BAG_L2': 505.71191215515137, 'ExtraTreesMSE_BAG_L2': 24.167625188827515, 'NeuralNetFastAI_BAG_L2': 59.5776743888855, 'XGBoost_BAG_L2': 59.628435373306274, 'NeuralNetTorch_BAG_L2': 72.30251026153564, 'LightGBMLarge_BAG_L2': 45.912253618240356, 'WeightedEnsemble_L3': 0.3958430290222168, 'LightGBMXT_BAG_L3': 61.12018871307373, 'LightGBM_BAG_L3': 60.33568525314331, 'RandomForestMSE_BAG_L3': 24.055482625961304, 'CatBoost_BAG_L3': 639.3619306087494, 'ExtraTreesMSE_BAG_L3': 23.23369860649109, 'NeuralNetFastAI_BAG_L3': 39.96530342102051, 'XGBoost_BAG_L3': 44.72861576080322, 'NeuralNetTorch_BAG_L3': 57.89659118652344, 'LightGBMLarge_BAG_L3': 169.132967710495, 'WeightedEnsemble_L4': 0.4074552059173584, 'LightGBMXT_BAG_L4': 58.50159406661987, 'LightGBM_BAG_L4': 26.84209966659546, 'RandomForestMSE_BAG_L4': 24.05756187438965, 'CatBoost_BAG_L4': 315.74224948883057, 'ExtraTreesMSE_BAG_L4': 23.81101107597351, 'NeuralNetFastAI_BAG_L4': 38.71884775161743, 'XGBoost_BAG_L4': 45.87100148200989, 'NeuralNetTorch_BAG_L4': 60.184515953063965, 'LightGBMLarge_BAG_L4': 42.985376834869385, 'WeightedEnsemble_L5': 0.38242602348327637}, 'model_pred_times': {'LightGBMXT_BAG_L1': 1.827815294265747, 'LightGBM_BAG_L1': 2.4842817783355713, 'RandomForestMSE_BAG_L1': 3.7941744327545166, 'CatBoost_BAG_L1': 23.573318004608154, 'ExtraTreesMSE_BAG_L1': 2.639031171798706, 'NeuralNetFastAI_BAG_L1': 1.4482324123382568, 'XGBoost_BAG_L1': 0.709320068359375, 'NeuralNetTorch_BAG_L1': 1.1250231266021729, 'LightGBMLarge_BAG_L1': 2.196350336074829, 'WeightedEnsemble_L2': 0.0007889270782470703, 'LightGBMXT_BAG_L2': 1.7929916381835938, 'LightGBM_BAG_L2': 1.8426127433776855, 'RandomForestMSE_BAG_L2': 2.867872953414917, 'CatBoost_BAG_L2': 20.95330572128296, 'ExtraTreesMSE_BAG_L2': 2.8527469635009766, 'NeuralNetFastAI_BAG_L2': 2.226508140563965, 'XGBoost_BAG_L2': 0.8137798309326172, 'NeuralNetTorch_BAG_L2': 2.1871979236602783, 'LightGBMLarge_BAG_L2': 1.357461929321289, 'WeightedEnsemble_L3': 0.0007472038269042969, 'LightGBMXT_BAG_L3': 1.4088242053985596, 'LightGBM_BAG_L3': 1.4608495235443115, 'RandomForestMSE_BAG_L3': 3.060732126235962, 'CatBoost_BAG_L3': 16.370062112808228, 'ExtraTreesMSE_BAG_L3': 2.80830979347229, 'NeuralNetFastAI_BAG_L3': 1.4548346996307373, 'XGBoost_BAG_L3': 0.8883810043334961, 'NeuralNetTorch_BAG_L3': 1.4862678050994873, 'LightGBMLarge_BAG_L3': 1.4304308891296387, 'WeightedEnsemble_L4': 0.0010581016540527344, 'LightGBMXT_BAG_L4': 1.5719773769378662, 'LightGBM_BAG_L4': 1.3380131721496582, 'RandomForestMSE_BAG_L4': 2.7258570194244385, 'CatBoost_BAG_L4': 15.30783224105835, 'ExtraTreesMSE_BAG_L4': 3.5216050148010254, 'NeuralNetFastAI_BAG_L4': 1.2797529697418213, 'XGBoost_BAG_L4': 0.85788893699646, 'NeuralNetTorch_BAG_L4': 1.5162675380706787, 'LightGBMLarge_BAG_L4': 1.3165879249572754, 'WeightedEnsemble_L5': 0.0008831024169921875}, 'num_bag_folds': 5, 'max_stack_level': 5, 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L3': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L3': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L4': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'NeuralNetFastAI_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'XGBoost_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMLarge_BAG_L4': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L5': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                      model  score_val  pred_time_val     fit_time  \\\n",
      "0      WeightedEnsemble_L5  -0.043252     112.053522  8612.280616   \n",
      "1      WeightedEnsemble_L3  -0.043345      47.847604  6657.513572   \n",
      "2      WeightedEnsemble_L2  -0.043484       2.953627   143.256142   \n",
      "3      WeightedEnsemble_L4  -0.043761      81.095035  7479.056296   \n",
      "4    NeuralNetTorch_BAG_L4  -0.043791     108.576984  8500.466241   \n",
      "5    NeuralNetTorch_BAG_L2  -0.043858      41.984745  6519.696959   \n",
      "6    NeuralNetTorch_BAG_L3  -0.043946      78.178292  7378.347852   \n",
      "7          LightGBM_BAG_L4  -0.044178     108.398730  8467.123825   \n",
      "8           XGBoost_BAG_L4  -0.044249     107.918606  8486.152726   \n",
      "9        LightGBMXT_BAG_L2  -0.044422      41.590538  6484.833555   \n",
      "10         LightGBM_BAG_L2  -0.044448      41.640159  6487.798438   \n",
      "11   NeuralNetTorch_BAG_L1  -0.044576       1.125023    63.820650   \n",
      "12       LightGBMXT_BAG_L1  -0.044580       1.827815    78.973169   \n",
      "13         LightGBM_BAG_L1  -0.044580       2.484282   130.832081   \n",
      "14  NeuralNetFastAI_BAG_L2  -0.044878      42.024055  6506.972123   \n",
      "15    LightGBMLarge_BAG_L4  -0.045011     108.377305  8483.267102   \n",
      "16  NeuralNetFastAI_BAG_L4  -0.045028     108.340470  8479.000573   \n",
      "17  NeuralNetFastAI_BAG_L3  -0.045203      78.146859  7360.416564   \n",
      "18    LightGBMLarge_BAG_L2  -0.045274      41.155009  6493.306702   \n",
      "19       LightGBMXT_BAG_L4  -0.045292     108.632694  8498.783319   \n",
      "20         CatBoost_BAG_L2  -0.045300      60.750852  6953.106361   \n",
      "21          XGBoost_BAG_L2  -0.045373      40.611326  6507.022884   \n",
      "22  RandomForestMSE_BAG_L4  -0.045602     109.786574  8464.339287   \n",
      "23    ExtraTreesMSE_BAG_L2  -0.045732      42.650294  6471.562074   \n",
      "24         LightGBM_BAG_L3  -0.045853      78.152874  7380.786946   \n",
      "25       LightGBMXT_BAG_L3  -0.045869      78.100849  7381.571450   \n",
      "26  RandomForestMSE_BAG_L3  -0.045953      79.752757  7344.506744   \n",
      "27    ExtraTreesMSE_BAG_L4  -0.046126     110.582322  8464.092736   \n",
      "28  RandomForestMSE_BAG_L2  -0.046202      42.665420  6475.307755   \n",
      "29         CatBoost_BAG_L1  -0.046246      23.573318  5735.620720   \n",
      "30         CatBoost_BAG_L3  -0.046257      93.062087  7959.813192   \n",
      "31    ExtraTreesMSE_BAG_L3  -0.046285      79.500334  7343.684960   \n",
      "32    LightGBMLarge_BAG_L1  -0.046388       2.196350   288.391838   \n",
      "33         CatBoost_BAG_L4  -0.046579     122.368549  8756.023974   \n",
      "34  NeuralNetFastAI_BAG_L1  -0.046647       1.448232    40.444216   \n",
      "35          XGBoost_BAG_L1  -0.046880       0.709320    46.630497   \n",
      "36    LightGBMLarge_BAG_L3  -0.047083      78.122455  7489.584229   \n",
      "37          XGBoost_BAG_L3  -0.047134      77.580405  7365.179877   \n",
      "38  RandomForestMSE_BAG_L1  -0.047416       3.794174    38.983467   \n",
      "39    ExtraTreesMSE_BAG_L1  -0.047448       2.639031    23.697812   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000883           0.382426            5       True   \n",
      "1                 0.000747           0.395843            3       True   \n",
      "2                 0.000789           0.462322            2       True   \n",
      "3                 0.001058           0.407455            4       True   \n",
      "4                 1.516268          60.184516            4       True   \n",
      "5                 2.187198          72.302510            2       True   \n",
      "6                 1.486268          57.896591            3       True   \n",
      "7                 1.338013          26.842100            4       True   \n",
      "8                 0.857889          45.871001            4       True   \n",
      "9                 1.792992          37.439106            2       True   \n",
      "10                1.842613          40.403989            2       True   \n",
      "11                1.125023          63.820650            1       True   \n",
      "12                1.827815          78.973169            1       True   \n",
      "13                2.484282         130.832081            1       True   \n",
      "14                2.226508          59.577674            2       True   \n",
      "15                1.316588          42.985377            4       True   \n",
      "16                1.279753          38.718848            4       True   \n",
      "17                1.454835          39.965303            3       True   \n",
      "18                1.357462          45.912254            2       True   \n",
      "19                1.571977          58.501594            4       True   \n",
      "20               20.953306         505.711912            2       True   \n",
      "21                0.813780          59.628435            2       True   \n",
      "22                2.725857          24.057562            4       True   \n",
      "23                2.852747          24.167625            2       True   \n",
      "24                1.460850          60.335685            3       True   \n",
      "25                1.408824          61.120189            3       True   \n",
      "26                3.060732          24.055483            3       True   \n",
      "27                3.521605          23.811011            4       True   \n",
      "28                2.867873          27.913306            2       True   \n",
      "29               23.573318        5735.620720            1       True   \n",
      "30               16.370062         639.361931            3       True   \n",
      "31                2.808310          23.233699            3       True   \n",
      "32                2.196350         288.391838            1       True   \n",
      "33               15.307832         315.742249            4       True   \n",
      "34                1.448232          40.444216            1       True   \n",
      "35                0.709320          46.630497            1       True   \n",
      "36                1.430431         169.132968            3       True   \n",
      "37                0.888381          44.728616            3       True   \n",
      "38                3.794174          38.983467            1       True   \n",
      "39                2.639031          23.697812            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          40  \n",
      "1          20  \n",
      "2          10  \n",
      "3          30  \n",
      "4          38  \n",
      "5          18  \n",
      "6          28  \n",
      "7          32  \n",
      "8          37  \n",
      "9          11  \n",
      "10         12  \n",
      "11          8  \n",
      "12          1  \n",
      "13          2  \n",
      "14         16  \n",
      "15         39  \n",
      "16         36  \n",
      "17         26  \n",
      "18         19  \n",
      "19         31  \n",
      "20         14  \n",
      "21         17  \n",
      "22         33  \n",
      "23         15  \n",
      "24         22  \n",
      "25         21  \n",
      "26         23  \n",
      "27         35  \n",
      "28         13  \n",
      "29          4  \n",
      "30         24  \n",
      "31         25  \n",
      "32          9  \n",
      "33         34  \n",
      "34          6  \n",
      "35          7  \n",
      "36         29  \n",
      "37         27  \n",
      "38          3  \n",
      "39          5  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate_autogluon/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': -0.0446792532223823, 'LightGBM_BAG_L1': -0.0446792547713066, 'RandomForestMSE_BAG_L1': -0.04314752124237054, 'CatBoost_BAG_L1': -0.04346584575692245, 'ExtraTreesMSE_BAG_L1': -0.043418674788397955, 'NeuralNetFastAI_BAG_L1': -0.04849957168854767, 'XGBoost_BAG_L1': -0.04360674482876362, 'NeuralNetTorch_BAG_L1': -0.04486272613571506, 'LightGBMLarge_BAG_L1': -0.04476396345264372, 'WeightedEnsemble_L2': -0.043911338349152146, 'LightGBMXT_BAG_L2': -0.044000553117623194, 'LightGBM_BAG_L2': -0.043527928979810546, 'RandomForestMSE_BAG_L2': -0.04367803749573964, 'CatBoost_BAG_L2': -0.04377390814869287, 'ExtraTreesMSE_BAG_L2': -0.043286329432074146, 'NeuralNetFastAI_BAG_L2': -0.04976788828222917, 'XGBoost_BAG_L2': -0.0438203435597352, 'NeuralNetTorch_BAG_L2': -0.044596115088348404, 'LightGBMLarge_BAG_L2': -0.04380969736538409, 'WeightedEnsemble_L3': -0.04496468922639712, 'LightGBMXT_BAG_L3': -0.04387874786992853, 'LightGBM_BAG_L3': -0.044561366827248754, 'RandomForestMSE_BAG_L3': -0.044721067777330176, 'CatBoost_BAG_L3': -0.0440059117744177, 'ExtraTreesMSE_BAG_L3': -0.04343884281664838, 'NeuralNetFastAI_BAG_L3': -0.050127662817007354, 'XGBoost_BAG_L3': -0.04601102633491045, 'NeuralNetTorch_BAG_L3': -0.044625660478742786, 'LightGBMLarge_BAG_L3': -0.044900289192249095, 'WeightedEnsemble_L4': -0.045519465604337485, 'LightGBMXT_BAG_L4': -0.04409352152622475, 'LightGBM_BAG_L4': -0.043914432051358324, 'RandomForestMSE_BAG_L4': -0.045919128587328974, 'CatBoost_BAG_L4': -0.044282060071876954, 'ExtraTreesMSE_BAG_L4': -0.04490626068513348, 'NeuralNetFastAI_BAG_L4': -0.04855379831895979, 'XGBoost_BAG_L4': -0.04650581965022856, 'NeuralNetTorch_BAG_L4': -0.04524673351638608, 'LightGBMLarge_BAG_L4': -0.046982607647022424, 'WeightedEnsemble_L5': -0.04528682111010329}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_test  score_val  pred_time_test  \\\n",
      "0   RandomForestMSE_BAG_L1   -0.043148  -0.047416        0.164077   \n",
      "1     ExtraTreesMSE_BAG_L2   -0.043286  -0.045732       28.693923   \n",
      "2     ExtraTreesMSE_BAG_L1   -0.043419  -0.047448        0.157441   \n",
      "3     ExtraTreesMSE_BAG_L3   -0.043439  -0.046285       56.150518   \n",
      "4          CatBoost_BAG_L1   -0.043466  -0.046246       14.583580   \n",
      "5          LightGBM_BAG_L2   -0.043528  -0.044448       31.004916   \n",
      "6           XGBoost_BAG_L1   -0.043607  -0.046880        1.050828   \n",
      "7   RandomForestMSE_BAG_L2   -0.043678  -0.046202       28.695130   \n",
      "8          CatBoost_BAG_L2   -0.043774  -0.045300       43.398397   \n",
      "9     LightGBMLarge_BAG_L2   -0.043810  -0.045274       31.278955   \n",
      "10          XGBoost_BAG_L2   -0.043820  -0.045373       29.739933   \n",
      "11       LightGBMXT_BAG_L3   -0.043879  -0.045869       58.289677   \n",
      "12     WeightedEnsemble_L2   -0.043911  -0.043484        4.783616   \n",
      "13         LightGBM_BAG_L4   -0.043914  -0.044178       84.007058   \n",
      "14       LightGBMXT_BAG_L2   -0.044001  -0.044422       30.884550   \n",
      "15         CatBoost_BAG_L3   -0.044006  -0.046257       70.395368   \n",
      "16       LightGBMXT_BAG_L4   -0.044094  -0.045292       83.746946   \n",
      "17         CatBoost_BAG_L4   -0.044282  -0.046579       95.723786   \n",
      "18         LightGBM_BAG_L3   -0.044561  -0.045853       58.461472   \n",
      "19   NeuralNetTorch_BAG_L2   -0.044596  -0.043858       30.388962   \n",
      "20   NeuralNetTorch_BAG_L3   -0.044626  -0.043946       58.084644   \n",
      "21       LightGBMXT_BAG_L1   -0.044679  -0.044580        2.969620   \n",
      "22         LightGBM_BAG_L1   -0.044679  -0.044580        2.789930   \n",
      "23  RandomForestMSE_BAG_L3   -0.044721  -0.045953       56.143761   \n",
      "24    LightGBMLarge_BAG_L1   -0.044764  -0.046388        3.407453   \n",
      "25   NeuralNetTorch_BAG_L1   -0.044863  -0.044576        1.807727   \n",
      "26    LightGBMLarge_BAG_L3   -0.044900  -0.047083       57.786270   \n",
      "27    ExtraTreesMSE_BAG_L4   -0.044906  -0.046126       81.997152   \n",
      "28     WeightedEnsemble_L3   -0.044965  -0.043345       36.887391   \n",
      "29   NeuralNetTorch_BAG_L4   -0.045247  -0.043791       83.711320   \n",
      "30     WeightedEnsemble_L5   -0.045287  -0.043252       88.495892   \n",
      "31     WeightedEnsemble_L4   -0.045519  -0.043761       62.000192   \n",
      "32  RandomForestMSE_BAG_L4   -0.045919  -0.045602       82.023284   \n",
      "33          XGBoost_BAG_L3   -0.046011  -0.047134       57.054723   \n",
      "34          XGBoost_BAG_L4   -0.046506  -0.044249       82.972631   \n",
      "35    LightGBMLarge_BAG_L4   -0.046983  -0.045011       83.750001   \n",
      "36  NeuralNetFastAI_BAG_L1   -0.048500  -0.046647        1.607016   \n",
      "37  NeuralNetFastAI_BAG_L4   -0.048554  -0.045028       83.343891   \n",
      "38  NeuralNetFastAI_BAG_L2   -0.049768  -0.044878       30.210700   \n",
      "39  NeuralNetFastAI_BAG_L3   -0.050128  -0.045203       57.435208   \n",
      "\n",
      "    pred_time_val     fit_time  pred_time_test_marginal  \\\n",
      "0        3.794174    38.983467                 0.164077   \n",
      "1       42.650294  6471.562074                 0.156252   \n",
      "2        2.639031    23.697812                 0.157441   \n",
      "3       79.500334  7343.684960                 0.156416   \n",
      "4       23.573318  5735.620720                14.583580   \n",
      "5       41.640159  6487.798438                 2.467246   \n",
      "6        0.709320    46.630497                 1.050828   \n",
      "7       42.665420  6475.307755                 0.157459   \n",
      "8       60.750852  6953.106361                14.860727   \n",
      "9       41.155009  6493.306702                 2.741284   \n",
      "10      40.611326  6507.022884                 1.202263   \n",
      "11      78.100849  7381.571450                 2.295575   \n",
      "12       2.953627   143.256142                 0.006269   \n",
      "13     108.398730  8467.123825                 2.158236   \n",
      "14      41.590538  6484.833555                 2.346880   \n",
      "15      93.062087  7959.813192                14.401266   \n",
      "16     108.632694  8498.783319                 1.898124   \n",
      "17     122.368549  8756.023974                13.874963   \n",
      "18      78.152874  7380.786946                 2.467369   \n",
      "19      41.984745  6519.696959                 1.851291   \n",
      "20      78.178292  7378.347852                 2.090542   \n",
      "21       1.827815    78.973169                 2.969620   \n",
      "22       2.484282   130.832081                 2.789930   \n",
      "23      79.752757  7344.506744                 0.149658   \n",
      "24       2.196350   288.391838                 3.407453   \n",
      "25       1.125023    63.820650                 1.807727   \n",
      "26      78.122455  7489.584229                 1.792168   \n",
      "27     110.582322  8464.092736                 0.148329   \n",
      "28      47.847604  6657.513572                 0.011274   \n",
      "29     108.576984  8500.466241                 1.862498   \n",
      "30     112.053522  8612.280616                 0.007458   \n",
      "31      81.095035  7479.056296                 0.007073   \n",
      "32     109.786574  8464.339287                 0.174462   \n",
      "33      77.580405  7365.179877                 1.060621   \n",
      "34     107.918606  8486.152726                 1.123809   \n",
      "35     108.377305  8483.267102                 1.901178   \n",
      "36       1.448232    40.444216                 1.607016   \n",
      "37     108.340470  8479.000573                 1.495069   \n",
      "38      42.024055  6506.972123                 1.673029   \n",
      "39      78.146859  7360.416564                 1.441106   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 3.794174          38.983467            1       True   \n",
      "1                 2.852747          24.167625            2       True   \n",
      "2                 2.639031          23.697812            1       True   \n",
      "3                 2.808310          23.233699            3       True   \n",
      "4                23.573318        5735.620720            1       True   \n",
      "5                 1.842613          40.403989            2       True   \n",
      "6                 0.709320          46.630497            1       True   \n",
      "7                 2.867873          27.913306            2       True   \n",
      "8                20.953306         505.711912            2       True   \n",
      "9                 1.357462          45.912254            2       True   \n",
      "10                0.813780          59.628435            2       True   \n",
      "11                1.408824          61.120189            3       True   \n",
      "12                0.000789           0.462322            2       True   \n",
      "13                1.338013          26.842100            4       True   \n",
      "14                1.792992          37.439106            2       True   \n",
      "15               16.370062         639.361931            3       True   \n",
      "16                1.571977          58.501594            4       True   \n",
      "17               15.307832         315.742249            4       True   \n",
      "18                1.460850          60.335685            3       True   \n",
      "19                2.187198          72.302510            2       True   \n",
      "20                1.486268          57.896591            3       True   \n",
      "21                1.827815          78.973169            1       True   \n",
      "22                2.484282         130.832081            1       True   \n",
      "23                3.060732          24.055483            3       True   \n",
      "24                2.196350         288.391838            1       True   \n",
      "25                1.125023          63.820650            1       True   \n",
      "26                1.430431         169.132968            3       True   \n",
      "27                3.521605          23.811011            4       True   \n",
      "28                0.000747           0.395843            3       True   \n",
      "29                1.516268          60.184516            4       True   \n",
      "30                0.000883           0.382426            5       True   \n",
      "31                0.001058           0.407455            4       True   \n",
      "32                2.725857          24.057562            4       True   \n",
      "33                0.888381          44.728616            3       True   \n",
      "34                0.857889          45.871001            4       True   \n",
      "35                1.316588          42.985377            4       True   \n",
      "36                1.448232          40.444216            1       True   \n",
      "37                1.279753          38.718848            4       True   \n",
      "38                2.226508          59.577674            2       True   \n",
      "39                1.454835          39.965303            3       True   \n",
      "\n",
      "    fit_order  \n",
      "0           3  \n",
      "1          15  \n",
      "2           5  \n",
      "3          25  \n",
      "4           4  \n",
      "5          12  \n",
      "6           7  \n",
      "7          13  \n",
      "8          14  \n",
      "9          19  \n",
      "10         17  \n",
      "11         21  \n",
      "12         10  \n",
      "13         32  \n",
      "14         11  \n",
      "15         24  \n",
      "16         31  \n",
      "17         34  \n",
      "18         22  \n",
      "19         18  \n",
      "20         28  \n",
      "21          1  \n",
      "22          2  \n",
      "23         23  \n",
      "24          9  \n",
      "25          8  \n",
      "26         29  \n",
      "27         35  \n",
      "28         20  \n",
      "29         38  \n",
      "30         40  \n",
      "31         30  \n",
      "32         33  \n",
      "33         27  \n",
      "34         37  \n",
      "35         39  \n",
      "36          6  \n",
      "37         36  \n",
      "38         16  \n",
      "39         26  \n"
     ]
    }
   ],
   "source": [
    "# %%capture log_output\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# %config Application.log_level = 'DEBUG'\n",
    "# %config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "# with open('./output_5040.log', 'w') as f:\n",
    "#     f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedEnsemble_L5\n"
     ]
    }
   ],
   "source": [
    "best_model = predictor.get_model_best()\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-20000_sdf/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model=best_model)\n",
    "test_data_pred = predictor.predict(test_data, model=best_model)\n",
    "\n",
    "import numpy as np\n",
    "#save np array y_train_hat to a csv file\n",
    "np.savetxt('./20000_vectors_y_test_hat_sdf.csv', test_data_pred, delimiter=',')\n",
    "np.savetxt('./20000_vectors_y_train_hat_sdf.csv', train_data_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
